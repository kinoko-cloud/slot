#!/usr/bin/env python3
"""
å°ç•ªå·æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å¤œé–“ãƒãƒƒãƒï¼ˆdaily_collect.pyï¼‰ã®å¾Œã«å®Ÿè¡Œã—ã€
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å°ç•ªå·ãƒªã‚¹ãƒˆã¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§å®Ÿéš›ã«è¦‹ã¤ã‹ã£ãŸå°ç•ªå·ã‚’ç…§åˆã™ã‚‹ã€‚

æ¤œçŸ¥ã™ã‚‹ã‚±ãƒ¼ã‚¹:
- å°æ’¤å»: configå®šç¾©ã«ã‚ã‚‹å°ç•ªå·ãŒã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã«å­˜åœ¨ã—ãªã„
- æ–°å°è¿½åŠ : ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã«configæœªå®šç¾©ã®å°ç•ªå·ãŒã‚ã‚‹
- å°æ•°å¤‰å‹•: è¨­ç½®å°æ•°ãŒå¢—æ¸›ã—ãŸ
- æ©Ÿç¨®åä¸ä¸€è‡´: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§å–ã‚ŒãŸæ©Ÿç¨®åã¨æœŸå¾…å€¤ãŒç•°ãªã‚‹

å‡ºåŠ›: data/alerts/ ã«JSONå½¢å¼ã§ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ä¿å­˜
"""

import json
import sys
from datetime import datetime, timezone, timedelta
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from config.rankings import STORES, MACHINES

JST = timezone(timedelta(hours=9))
ALERTS_DIR = PROJECT_ROOT / 'data' / 'alerts'


def verify_units_from_daily(daily_data: dict) -> list:
    """ãƒ‡ã‚¤ãƒªãƒ¼åé›†çµæœã‹ã‚‰å°ç•ªå·ã‚’æ¤œè¨¼ã™ã‚‹

    Args:
        daily_data: daily_collect.pyã®å‡ºåŠ›çµæœï¼ˆstoresè¾æ›¸ã‚’å«ã‚€ï¼‰

    Returns:
        ã‚¢ãƒ©ãƒ¼ãƒˆã®ãƒªã‚¹ãƒˆ
    """
    alerts = []
    checked_at = datetime.now(JST).isoformat()

    stores_data = daily_data.get('stores', {})

    for result_key, store_data in stores_data.items():
        # result_keyã¯ "shibuya_espass_sbj" ã®ã‚ˆã†ãªå½¢å¼
        # config/rankings.pyã®STORESã‚­ãƒ¼ã¨ç…§åˆ
        store_config = STORES.get(result_key)
        if not store_config:
            # æ—§å½¢å¼ã‚­ãƒ¼ã®å ´åˆã¯å¯¾å¿œã™ã‚‹STORESã‚­ãƒ¼ã‚’æ¢ã™
            store_config = _find_store_config(result_key, store_data.get('machine_key'))
            if not store_config:
                continue

        config_units = set(store_config.get('units', []))
        machine_key = store_config.get('machine', '')
        machine_name = MACHINES.get(machine_key, {}).get('name', '')
        store_name = store_config.get('name', result_key)

        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§å®Ÿéš›ã«å–å¾—ã—ãŸå°ç•ªå·
        scraped_units = set()
        scraped_machine_names = set()
        for unit in store_data.get('units', []):
            unit_id = str(unit.get('unit_id', ''))
            if unit_id:
                scraped_units.add(unit_id)
            m_name = unit.get('machine_name', '')
            if m_name:
                scraped_machine_names.add(m_name)

        if not scraped_units:
            # ãƒ‡ãƒ¼ã‚¿ãŒå–ã‚Œãªã‹ã£ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ã®å¯èƒ½æ€§ï¼‰
            continue

        # 1. æ¶ˆãˆãŸå°ç•ªå·ï¼ˆå°æ’¤å» or å°ç§»å‹•ï¼‰
        missing_units = config_units - scraped_units
        if missing_units:
            alerts.append({
                'type': 'unit_missing',
                'severity': 'warning',
                'store_key': result_key,
                'store_name': store_name,
                'machine_key': machine_key,
                'units': sorted(missing_units),
                'message': f'{store_name}: å°ç•ªå· {", ".join(sorted(missing_units))} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆå°æ’¤å»ã¾ãŸã¯å°ç§»å‹•ã®å¯èƒ½æ€§ï¼‰',
                'checked_at': checked_at,
            })

        # 2. æ–°ã—ã„å°ç•ªå·ï¼ˆå°è¿½åŠ  or å°ç§»å‹•å…ˆï¼‰
        new_units = scraped_units - config_units
        if new_units:
            alerts.append({
                'type': 'unit_new',
                'severity': 'info',
                'store_key': result_key,
                'store_name': store_name,
                'machine_key': machine_key,
                'units': sorted(new_units),
                'message': f'{store_name}: æ–°ã—ã„å°ç•ªå· {", ".join(sorted(new_units))} ã‚’æ¤œå‡ºï¼ˆæ–°å°è¿½åŠ ã¾ãŸã¯å°ç§»å‹•ã®å¯èƒ½æ€§ï¼‰',
                'checked_at': checked_at,
            })

        # 3. å°æ•°å¤‰å‹•
        if len(scraped_units) != len(config_units):
            diff = len(scraped_units) - len(config_units)
            direction = 'å¢—åŠ ' if diff > 0 else 'æ¸›å°‘'
            alerts.append({
                'type': 'unit_count_change',
                'severity': 'warning' if diff < 0 else 'info',
                'store_key': result_key,
                'store_name': store_name,
                'machine_key': machine_key,
                'config_count': len(config_units),
                'actual_count': len(scraped_units),
                'diff': diff,
                'message': f'{store_name}: å°æ•°{direction}ï¼ˆè¨­å®š{len(config_units)}å° â†’ å®Ÿéš›{len(scraped_units)}å°ï¼‰',
                'checked_at': checked_at,
            })

        # 4. åŒæ™‚ã«æ¶ˆãˆãŸå°ã¨æ–°ã—ã„å°ãŒã‚ã‚‹å ´åˆâ†’å°ç§»å‹•ã®å¯èƒ½æ€§
        if missing_units and new_units:
            alerts.append({
                'type': 'unit_move_suspected',
                'severity': 'warning',
                'store_key': result_key,
                'store_name': store_name,
                'machine_key': machine_key,
                'missing': sorted(missing_units),
                'new': sorted(new_units),
                'message': f'{store_name}: å°ç§»å‹•ã®å¯èƒ½æ€§ â€” æ¶ˆå¤±: {", ".join(sorted(missing_units))} / æ–°è¦: {", ".join(sorted(new_units))}',
                'checked_at': checked_at,
            })

    return alerts


def verify_units_from_availability(availability_data: dict) -> list:
    """availability.jsonï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ï¼‰ã‹ã‚‰å°ç•ªå·ã‚’æ¤œè¨¼ã™ã‚‹

    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å–å¾—æ™‚ã«ã‚‚ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚

    Args:
        availability_data: availability.jsonã®å†…å®¹

    Returns:
        ã‚¢ãƒ©ãƒ¼ãƒˆã®ãƒªã‚¹ãƒˆ
    """
    alerts = []
    checked_at = datetime.now(JST).isoformat()

    stores_data = availability_data.get('stores', {})

    for store_key, store_data in stores_data.items():
        store_config = STORES.get(store_key)
        if not store_config:
            continue

        config_units = set(store_config.get('units', []))
        store_name = store_config.get('name', store_key)

        # availability.jsonã‹ã‚‰å°ç•ªå·ã‚’å–å¾—
        scraped_units = set()
        for unit in store_data.get('units', []):
            unit_id = str(unit.get('unit_id', ''))
            if unit_id:
                scraped_units.add(unit_id)

        # empty/playing ãƒªã‚¹ãƒˆã‹ã‚‰ã‚‚å–å¾—
        for u in store_data.get('empty', []):
            scraped_units.add(str(u))
        for u in store_data.get('playing', []):
            scraped_units.add(str(u))

        if not scraped_units:
            continue

        missing = config_units - scraped_units
        new = scraped_units - config_units

        if missing:
            alerts.append({
                'type': 'unit_missing',
                'severity': 'warning',
                'store_key': store_key,
                'store_name': store_name,
                'units': sorted(missing),
                'message': f'{store_name}: å°ç•ªå· {", ".join(sorted(missing))} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“',
                'checked_at': checked_at,
            })

        if new:
            alerts.append({
                'type': 'unit_new',
                'severity': 'info',
                'store_key': store_key,
                'store_name': store_name,
                'units': sorted(new),
                'message': f'{store_name}: æ–°ã—ã„å°ç•ªå· {", ".join(sorted(new))} ã‚’æ¤œå‡º',
                'checked_at': checked_at,
            })

    return alerts


def save_alerts(alerts: list, source: str = 'daily') -> Path:
    """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹

    Args:
        alerts: ã‚¢ãƒ©ãƒ¼ãƒˆã®ãƒªã‚¹ãƒˆ
        source: ã‚¢ãƒ©ãƒ¼ãƒˆå…ƒï¼ˆ'daily' or 'availability'ï¼‰

    Returns:
        ä¿å­˜å…ˆãƒ‘ã‚¹
    """
    ALERTS_DIR.mkdir(parents=True, exist_ok=True)

    now = datetime.now(JST)
    filename = f'alerts_{source}_{now.strftime("%Y%m%d_%H%M")}.json'
    output_path = ALERTS_DIR / filename

    alert_data = {
        'generated_at': now.isoformat(),
        'source': source,
        'alert_count': len(alerts),
        'alerts': alerts,
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(alert_data, f, ensure_ascii=False, indent=2)

    return output_path


def load_latest_alerts() -> dict:
    """æœ€æ–°ã®ã‚¢ãƒ©ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

    Returns:
        ã‚¢ãƒ©ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆãªã‘ã‚Œã°ç©ºè¾æ›¸ï¼‰
    """
    if not ALERTS_DIR.exists():
        return {}

    alert_files = sorted(ALERTS_DIR.glob('alerts_*.json'), reverse=True)
    if not alert_files:
        return {}

    with open(alert_files[0], 'r', encoding='utf-8') as f:
        return json.load(f)


def get_active_alerts() -> list:
    """ç¾åœ¨æœ‰åŠ¹ãªã‚¢ãƒ©ãƒ¼ãƒˆã‚’å–å¾—ã™ã‚‹

    24æ™‚é–“ä»¥å†…ã®warningä»¥ä¸Šã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’è¿”ã™ã€‚

    Returns:
        æœ‰åŠ¹ãªã‚¢ãƒ©ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
    """
    latest = load_latest_alerts()
    if not latest:
        return []

    # 24æ™‚é–“ä»¥å†…ã®ã‚¢ãƒ©ãƒ¼ãƒˆã®ã¿
    generated_at = latest.get('generated_at', '')
    if generated_at:
        try:
            gen_time = datetime.fromisoformat(generated_at)
            now = datetime.now(JST)
            if (now - gen_time).total_seconds() > 86400:
                return []
        except:
            pass

    return [a for a in latest.get('alerts', []) if a.get('severity') in ('warning', 'critical')]


def get_unit_status(store_key: str, unit_id: str) -> dict:
    """ç‰¹å®šã®å°ã®ã‚¢ãƒ©ãƒ¼ãƒˆçŠ¶æ…‹ã‚’å–å¾—ã™ã‚‹

    Returns:
        {'status': 'normal'/'missing'/'new'/'moved', 'message': str}
    """
    active = get_active_alerts()

    for alert in active:
        if alert.get('store_key') != store_key:
            continue

        if alert.get('type') == 'unit_move_suspected':
            if unit_id in alert.get('missing', []):
                return {'status': 'moved', 'message': 'å°ç§»å‹•ï¼ˆæ¶ˆå¤±ï¼‰'}
            if unit_id in alert.get('new', []):
                return {'status': 'moved', 'message': 'å°ç§»å‹•ï¼ˆæ–°è¨­ï¼‰'}

        if alert.get('type') == 'unit_missing' and unit_id in alert.get('units', []):
            return {'status': 'missing', 'message': 'å°æ’¤å»ã®å¯èƒ½æ€§'}

        if alert.get('type') == 'unit_new' and unit_id in alert.get('units', []):
            return {'status': 'new', 'message': 'æ–°å°'}

    return {'status': 'normal', 'message': ''}


def _find_store_config(result_key: str, machine_key: str = None):
    """daily_collectã®çµæœã‚­ãƒ¼ã‹ã‚‰STORESè¨­å®šã‚’æ¢ã™"""
    # ã¾ãšç›´æ¥ãƒãƒƒãƒ
    if result_key in STORES:
        return STORES[result_key]

    # result_keyãŒ "shibuya_espass_sbj" ã®å ´åˆã¯ãã®ã¾ã¾
    # "shibuya_espass" + machine_key = "sbj" â†’ "shibuya_espass_sbj"
    if machine_key:
        combined = f"{result_key}_{machine_key}"
        if combined in STORES:
            return STORES[combined]

    return None


def print_report(alerts: list):
    """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›"""
    if not alerts:
        print('âœ“ å°ç•ªå·ã®ç•°å¸¸ãªã—')
        return

    print(f'\n{"="*50}')
    print(f'å°ç•ªå·æ¤œè¨¼çµæœ: {len(alerts)}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒˆ')
    print(f'{"="*50}')

    for alert in alerts:
        severity = alert.get('severity', 'info')
        icon = 'ğŸ”´' if severity == 'critical' else 'ğŸŸ¡' if severity == 'warning' else 'ğŸ”µ'
        print(f'\n{icon} [{alert["type"]}] {alert["message"]}')

    print()


def verify_data_integrity(availability_data: dict) -> list:
    """availability.jsonã®ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’æ¤œè¨¼ã™ã‚‹

    ãƒã‚§ãƒƒã‚¯é …ç›®:
    - å…¨æœŸå¾…åº—èˆ—ãŒãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹
    - å„å°ã®ART/total_startãŒ0ã§ãªã„ã‹ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—æ¤œçŸ¥ï¼‰
    - å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ¬ æã—ã¦ã„ãªã„ã‹
    - ãƒ‡ãƒ¼ã‚¿ã®é®®åº¦

    Returns:
        å•é¡Œã®ãƒªã‚¹ãƒˆ
    """
    issues = []
    checked_at = datetime.now(JST).isoformat()

    stores_data = availability_data.get('stores', {})

    # æœŸå¾…ã•ã‚Œã‚‹åº—èˆ—ã‚­ãƒ¼ï¼ˆavailability.jsonã«å«ã¾ã‚Œã‚‹ã¹ãï¼‰
    EXPECTED_STORES = {
        'island_akihabara_sbj': {'name': 'ã‚¢ã‚¤ãƒ©ãƒ³ãƒ‰ç§‹è‘‰åŸ', 'min_units': 14},
        'shibuya_espass_sbj': {'name': 'æ¸‹è°·ã‚¨ã‚¹ãƒ‘ã‚¹æ–°é¤¨', 'min_units': 3},
        'shinjuku_espass_sbj': {'name': 'æ–°å®¿ã‚¨ã‚¹ãƒ‘ã‚¹æ­Œèˆä¼ç”º', 'min_units': 4},
        'akiba_espass_sbj': {'name': 'ç§‹è‘‰åŸã‚¨ã‚¹ãƒ‘ã‚¹é§…å‰', 'min_units': 4},
        'seibu_shinjuku_espass_sbj': {'name': 'è¥¿æ­¦æ–°å®¿é§…å‰ã‚¨ã‚¹ãƒ‘ã‚¹', 'min_units': 7},
    }

    # 1. åº—èˆ—ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    for store_key, expected in EXPECTED_STORES.items():
        if store_key not in stores_data:
            issues.append({
                'type': 'store_missing',
                'severity': 'critical',
                'store_key': store_key,
                'store_name': expected['name'],
                'message': f'{expected["name"]}: availability.jsonã«ãƒ‡ãƒ¼ã‚¿ãªã—',
                'checked_at': checked_at,
            })
            continue

        store = stores_data[store_key]
        units = store.get('units', [])

        # 2. å°æ•°ãƒã‚§ãƒƒã‚¯
        if len(units) < expected['min_units']:
            issues.append({
                'type': 'units_insufficient',
                'severity': 'warning',
                'store_key': store_key,
                'store_name': expected['name'],
                'expected': expected['min_units'],
                'actual': len(units),
                'message': f'{expected["name"]}: å°æ•°ä¸è¶³ï¼ˆæœŸå¾…{expected["min_units"]}å°ã€å®Ÿéš›{len(units)}å°ï¼‰',
                'checked_at': checked_at,
            })

        # 3. å…¨å°ART=0ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—ã®å…†å€™ï¼‰
        art_values = [u.get('art', 0) for u in units]
        total_start_values = [u.get('total_start', 0) for u in units]

        # å–¶æ¥­ä¸­ã§å…¨å°ART=0ã¯ç•°å¸¸ï¼ˆé–‰åº—å¾Œã¯æ­£å¸¸ï¼‰
        now = datetime.now(JST)
        is_business_hours = 10 <= now.hour < 23

        if is_business_hours and now.hour >= 12:
            # 12æ™‚ä»¥é™ã§å…¨å°ART 0ã¯ç•°å¸¸
            if units and all(a == 0 for a in art_values):
                issues.append({
                    'type': 'all_art_zero',
                    'severity': 'critical',
                    'store_key': store_key,
                    'store_name': expected['name'],
                    'unit_count': len(units),
                    'message': f'{expected["name"]}: å…¨{len(units)}å°ã®ART=0ï¼ˆãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—ã®å¯èƒ½æ€§ï¼‰',
                    'checked_at': checked_at,
                })

        # 4. å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ æãƒã‚§ãƒƒã‚¯
        required_fields = ['unit_id', 'art']
        for unit in units:
            missing_fields = [f for f in required_fields if f not in unit]
            if missing_fields:
                issues.append({
                    'type': 'field_missing',
                    'severity': 'warning',
                    'store_key': store_key,
                    'store_name': expected['name'],
                    'unit_id': unit.get('unit_id', '?'),
                    'missing_fields': missing_fields,
                    'message': f'{expected["name"]} {unit.get("unit_id", "?")}ç•ª: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ æ {", ".join(missing_fields)}',
                    'checked_at': checked_at,
                })

        # 5. å€‹åˆ¥å°ã®ãƒ‡ãƒ¼ã‚¿ç•°å¸¸ãƒã‚§ãƒƒã‚¯
        for unit in units:
            uid = unit.get('unit_id', '?')
            art = unit.get('art', 0)
            total = unit.get('total_start', 0)

            # total_startãŒå¤§ãã„ã®ã«ART=0ã¯ç•°å¸¸
            if total > 2000 and art == 0:
                issues.append({
                    'type': 'art_zero_with_games',
                    'severity': 'warning',
                    'store_key': store_key,
                    'store_name': expected['name'],
                    'unit_id': uid,
                    'total_start': total,
                    'message': f'{expected["name"]} {uid}ç•ª: {total:,}Gæ¶ˆåŒ–æ¸ˆã¿ãªã®ã«ART=0',
                    'checked_at': checked_at,
                })

    # 6. ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒã‚§ãƒƒã‚¯
    fetched_at = availability_data.get('fetched_at', '')
    if fetched_at:
        try:
            fetch_time = datetime.fromisoformat(fetched_at)
            now = datetime.now(JST)
            age_minutes = (now - fetch_time).total_seconds() / 60

            if age_minutes > 60:
                issues.append({
                    'type': 'data_stale',
                    'severity': 'warning',
                    'age_minutes': int(age_minutes),
                    'fetched_at': fetched_at,
                    'message': f'ãƒ‡ãƒ¼ã‚¿ãŒ{int(age_minutes)}åˆ†å‰ã®ã‚‚ã®ï¼ˆ60åˆ†è¶…éï¼‰',
                    'checked_at': checked_at,
                })
        except Exception:
            pass

    return issues


def print_integrity_report(issues: list):
    """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›"""
    if not issues:
        print('âœ“ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§: å•é¡Œãªã—')
        return

    critical = [i for i in issues if i.get('severity') == 'critical']
    warnings = [i for i in issues if i.get('severity') == 'warning']

    print(f'\n{"="*50}')
    print(f'ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯: {len(issues)}ä»¶ã®å•é¡Œ')
    if critical:
        print(f'  ğŸ”´ é‡å¤§: {len(critical)}ä»¶')
    if warnings:
        print(f'  ğŸŸ¡ è­¦å‘Š: {len(warnings)}ä»¶')
    print(f'{"="*50}')

    for issue in issues:
        severity = issue.get('severity', 'info')
        icon = 'ğŸ”´' if severity == 'critical' else 'ğŸŸ¡' if severity == 'warning' else 'ğŸ”µ'
        print(f'{icon} [{issue["type"]}] {issue["message"]}')

    print()
    return len(critical) > 0


def main():
    """ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œ: availability.jsonã‹ã‚‰æ¤œè¨¼"""
    import argparse
    parser = argparse.ArgumentParser(description='å°ç•ªå·æ¤œè¨¼')
    parser.add_argument('--source', choices=['availability', 'daily', 'integrity'], default='availability',
                        help='æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹')
    parser.add_argument('--daily-file', type=str, help='ãƒ‡ã‚¤ãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆ--source dailyæ™‚ï¼‰')
    args = parser.parse_args()

    avail_path = PROJECT_ROOT / 'data' / 'availability.json'

    if args.source == 'integrity':
        if not avail_path.exists():
            print('availability.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
            return

        with open(avail_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        issues = verify_data_integrity(data)
        has_critical = print_integrity_report(issues)

        if has_critical:
            print('âš  é‡å¤§ãªå•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ')
            sys.exit(1)
        return

    if args.source == 'availability':
        if not avail_path.exists():
            print('availability.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
            return

        with open(avail_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        alerts = verify_units_from_availability(data)

    elif args.source == 'daily':
        if args.daily_file:
            daily_path = Path(args.daily_file)
        else:
            # æœ€æ–°ã®ãƒ‡ã‚¤ãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            daily_dir = PROJECT_ROOT / 'data' / 'daily'
            daily_files = sorted(daily_dir.glob('daily_*.json'), reverse=True)
            if not daily_files:
                print('ãƒ‡ã‚¤ãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
                return
            daily_path = daily_files[0]

        with open(daily_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        alerts = verify_units_from_daily(data)

    print_report(alerts)

    if alerts:
        save_path = save_alerts(alerts, source=args.source)
        print(f'ã‚¢ãƒ©ãƒ¼ãƒˆä¿å­˜: {save_path}')


if __name__ == '__main__':
    main()
