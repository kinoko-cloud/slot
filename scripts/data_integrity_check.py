#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ â€” daily_collect.pyå®Ÿè¡Œå¾Œã«å‘¼ã°ã‚Œã‚‹åŒ…æ‹¬ãƒã‚§ãƒƒã‚¯

ãƒã‚§ãƒƒã‚¯é …ç›®:
1. ã€ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å“è³ªã€‘
   - å–å¾—0å°ã®åº—èˆ—/æ©Ÿç¨®ãŒãªã„ã‹
   - éƒ¨åˆ†å–å¾—ï¼ˆæœŸå¾…å°æ•° vs å–å¾—å°æ•°ã®ä¹–é›¢ï¼‰
   - ART=0, games=0, historyç©º ã®å°ãŒå¤šã™ããªã„ã‹
   - null/0ã§åŸ‹ã¾ã£ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¤œå‡º
   
2. ã€å°ç•ªå·/æ©Ÿç¨®å/å°æ•°ã€‘
   - configå®šç¾© vs å®Ÿå–å¾—ã®å°ç•ªå·ç…§åˆ
   - æ¶ˆãˆãŸå°ï¼ˆæ’¤å»/ç§»å‹•ï¼‰
   - æ–°ã—ãå‡ºç¾ã—ãŸå°ï¼ˆå¢—å°/ç§»å‹•å…ˆï¼‰
   - å°æ•°ã®å¤‰å‹•
   - æ©Ÿç¨®åãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆverify_keywordsç…§åˆï¼‰

3. ã€æ—¥ä»˜æ•´åˆæ€§ã€‘
   - é–‹åº—ç›´å¾Œã®ãƒ‡ãƒ¼ã‚¿åˆ‡ã‚Šæ›¿ã‚ã‚Šï¼ˆå‰æ—¥â†’å½“æ—¥ï¼‰
   - è“„ç©DBã®æ—¥ä»˜ã‚®ãƒ£ãƒƒãƒ—ï¼ˆæ­¯æŠœã‘æ—¥ï¼‰
   - æœªæ¥æ—¥ä»˜ã®æ··å…¥

4. ã€ãƒ‡ãƒ¼ã‚¿å“è³ªã€‘
   - diff_medalsãŒç•°å¸¸å€¤ï¼ˆÂ±50,000æšè¶…ç­‰ï¼‰
   - ARTç¢ºç‡ãŒç‰©ç†çš„ã«ã‚ã‚Šãˆãªã„å€¤ï¼ˆ1/1ä»¥ä¸‹ã€1/10000ä»¥ä¸Šï¼‰
   - historyã®æ™‚ç³»åˆ—çŸ›ç›¾ï¼ˆæ™‚åˆ»ãŒé€†é †ç­‰ï¼‰

å‡ºåŠ›: ãƒã‚§ãƒƒã‚¯çµæœã‚µãƒãƒªãƒ¼ + ã‚¢ãƒ©ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
é‡å¤§ã‚¢ãƒ©ãƒ¼ãƒˆãŒã‚ã‚Œã°WhatsAppé€šçŸ¥å¯¾è±¡ï¼ˆå‘¼ã³å‡ºã—å…ƒã§åˆ¤å®šï¼‰
"""

import json
import sys
from datetime import datetime, timezone, timedelta
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from config.rankings import STORES, MACHINES, get_machine_threshold

JST = timezone(timedelta(hours=9))
HISTORY_DIR = PROJECT_ROOT / 'data' / 'history'


class Alert:
    """ã‚¢ãƒ©ãƒ¼ãƒˆå®šç¾©"""
    CRITICAL = 'critical'   # å³åº§ã«WhatsAppé€šçŸ¥
    WARNING = 'warning'     # ãƒ­ã‚° + ã‚µãƒãƒªãƒ¼ã«è¨˜è¼‰
    INFO = 'info'           # ãƒ­ã‚°ã®ã¿

    def __init__(self, level, category, store_key, message, details=None):
        self.level = level
        self.category = category
        self.store_key = store_key
        self.message = message
        self.details = details or {}
        self.timestamp = datetime.now(JST).isoformat()

    def to_dict(self):
        return {
            'level': self.level,
            'category': self.category,
            'store_key': self.store_key,
            'message': self.message,
            'details': self.details,
            'timestamp': self.timestamp,
        }

    def __repr__(self):
        icon = {'critical': 'ğŸ”´', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ'}.get(self.level, 'âšª')
        return f"{icon} [{self.category}] {self.store_key}: {self.message}"


def check_scraping_quality(daily_data: dict) -> list:
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å“è³ªãƒã‚§ãƒƒã‚¯
    
    - å–å¾—0å°ã®åº—èˆ—
    - éƒ¨åˆ†å–å¾—ï¼ˆæœŸå¾…å°æ•°ã®åŠåˆ†æœªæº€ï¼‰
    - ãƒ‡ãƒ¼ã‚¿ãŒç©º/0ã®å°ãŒå¤šã„
    - null/0ã§åŸ‹ã¾ã£ãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    """
    alerts = []
    stores = daily_data.get('stores', {})
    
    for store_key, config in STORES.items():
        # STORESã‚­ãƒ¼ã¯ "store_machine" å½¢å¼ï¼ˆä¾‹: island_akihabara_sbjï¼‰
        machine_key = config.get('machine', 'sbj')
        unit_list = config.get('units', [])
        result_key = store_key  # daily_dataã®ã‚­ãƒ¼ã¨ä¸€è‡´
        store_data = stores.get(result_key)
        expected_count = len(unit_list)
        store_name = config.get('name', store_key)
        machine_name = MACHINES.get(machine_key, {}).get('display_name', machine_key)
        
        if not store_data:
            alerts.append(Alert(
                Alert.CRITICAL, 'scrape_missing',
                result_key,
                f"{store_name}({machine_name}): ãƒ‡ãƒ¼ã‚¿å–å¾—ãªã—ï¼ˆ{expected_count}å°æœŸå¾…ï¼‰",
                {'expected': expected_count, 'actual': 0}
            ))
            continue
        
        units = store_data.get('units', [])
        actual_count = len(units)
        
        # å–å¾—0å°
        if actual_count == 0:
            alerts.append(Alert(
                Alert.CRITICAL, 'scrape_empty',
                result_key,
                f"{store_name}({machine_name}): 0å°å–å¾—ï¼ˆ{expected_count}å°æœŸå¾…ï¼‰",
                {'expected': expected_count, 'actual': 0}
            ))
            continue
        
        # éƒ¨åˆ†å–å¾—ï¼ˆåŠåˆ†æœªæº€ï¼‰
        if actual_count < expected_count * 0.5:
            alerts.append(Alert(
                Alert.WARNING, 'scrape_partial',
                result_key,
                f"{store_name}({machine_name}): {actual_count}/{expected_count}å°ã®ã¿å–å¾—",
                {'expected': expected_count, 'actual': actual_count}
            ))
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ª: å„å°ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
        empty_units = 0
        null_field_units = []
        
        for unit in units:
            unit_id = unit.get('unit_id', '?')
            days = unit.get('days', [])
            
            if not days:
                empty_units += 1
                continue
            
            # æœ€æ–°æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
            latest = days[0] if days else {}
            art = latest.get('art')
            games = latest.get('total_start') or latest.get('games')
            
            # null/0ãƒã‚§ãƒƒã‚¯
            problems = []
            if art is None:
                problems.append('art=null')
            if games is None:
                problems.append('games=null')
            if art == 0 and games and games > 500:
                problems.append(f'art=0 but games={games}')
            
            if problems:
                null_field_units.append({'unit_id': unit_id, 'problems': problems})
        
        if empty_units > expected_count * 0.3:
            alerts.append(Alert(
                Alert.WARNING, 'scrape_empty_units',
                result_key,
                f"{store_name}({machine_name}): {empty_units}/{actual_count}å°ãŒãƒ‡ãƒ¼ã‚¿ç©º",
                {'empty': empty_units, 'total': actual_count}
            ))
        
        if null_field_units:
            alerts.append(Alert(
                Alert.WARNING, 'scrape_null_fields',
                result_key,
                f"{store_name}({machine_name}): {len(null_field_units)}å°ã«null/ç•°å¸¸ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰",
                {'units': null_field_units[:5]}  # å…ˆé ­5å°ã®ã¿
            ))
    
    return alerts


def check_unit_changes(daily_data: dict) -> list:
    """å°ç•ªå·/æ©Ÿç¨®å/å°æ•°ãƒã‚§ãƒƒã‚¯
    
    - æ¶ˆãˆãŸå°ï¼ˆæ’¤å»/ç§»å‹•ï¼‰
    - æ–°ã—ã„å°ï¼ˆå¢—å°/ç§»å‹•å…ˆï¼‰
    - å°æ•°å¤‰å‹•
    - æ©Ÿç¨®åãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    """
    alerts = []
    stores = daily_data.get('stores', {})
    
    for store_key, config in STORES.items():
        machine_key = config.get('machine', 'sbj')
        unit_list = config.get('units', [])
        result_key = store_key
        store_data = stores.get(result_key)
        if not store_data:
            continue
        
        store_name = config.get('name', store_key)
        machine_name = MACHINES.get(machine_key, {}).get('display_name', machine_key)
        config_units = set(str(u) for u in unit_list)
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§å–å¾—ã—ãŸå°ç•ªå·
        scraped_units = set()
        machine_names_found = set()
        mismatched_machines = []
        
        for unit in store_data.get('units', []):
            uid = str(unit.get('unit_id', ''))
            if uid:
                scraped_units.add(uid)
            mn = unit.get('machine_name', '')
            if mn:
                machine_names_found.add(mn)
            if unit.get('machine_mismatch'):
                mismatched_machines.append({
                    'unit_id': uid,
                    'actual_machine': unit.get('actual_machine', 'ä¸æ˜'),
                })
        
        # æ¶ˆãˆãŸå°
        missing = config_units - scraped_units
        if missing:
            severity = Alert.CRITICAL if len(missing) >= 3 else Alert.WARNING
            alerts.append(Alert(
                severity, 'unit_missing',
                result_key,
                f"{store_name}({machine_name}): {len(missing)}å°ãŒæ¶ˆå¤± [{', '.join(sorted(missing))}]",
                {'missing_units': sorted(missing)}
            ))
        
        # æ–°ã—ã„å°ï¼ˆconfigã«ãªã„å°ãŒå–å¾—ã•ã‚ŒãŸï¼‰
        new_units = scraped_units - config_units
        if new_units:
            alerts.append(Alert(
                Alert.WARNING, 'unit_new',
                result_key,
                f"{store_name}({machine_name}): {len(new_units)}å°ãŒæ–°å‡ºç¾ [{', '.join(sorted(new_units))}]",
                {'new_units': sorted(new_units)}
            ))
        
        # å°æ•°å¤‰å‹•
        if len(config_units) != len(scraped_units):
            diff = len(scraped_units) - len(config_units)
            alerts.append(Alert(
                Alert.WARNING, 'unit_count_change',
                result_key,
                f"{store_name}({machine_name}): å°æ•°å¤‰å‹• {len(config_units)}â†’{len(scraped_units)} ({diff:+d}å°)",
                {'config_count': len(config_units), 'scraped_count': len(scraped_units)}
            ))
        
        # æ©Ÿç¨®åä¸ä¸€è‡´
        if mismatched_machines:
            alerts.append(Alert(
                Alert.CRITICAL, 'machine_mismatch',
                result_key,
                f"{store_name}: {len(mismatched_machines)}å°ãŒåˆ¥æ©Ÿç¨®ã«å¤‰æ›´",
                {'mismatched': mismatched_machines}
            ))
        
        # å°ç•ªå·ã®å¤§å¹…å¤‰å‹•ï¼ˆç§»å‹•ã®ç–‘ã„ï¼‰
        if missing and new_units and len(missing) == len(new_units):
            alerts.append(Alert(
                Alert.CRITICAL, 'unit_shuffle',
                result_key,
                f"{store_name}({machine_name}): å°ç§»å‹•ã®ç–‘ã„ â€” {len(missing)}å°æ¶ˆå¤±+{len(new_units)}å°æ–°å‡ºç¾",
                {'missing': sorted(missing), 'new': sorted(new_units)}
            ))
    
    return alerts


def check_date_integrity(daily_data: dict) -> list:
    """æ—¥ä»˜æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    
    - è“„ç©DBã®æ—¥ä»˜ã‚®ãƒ£ãƒƒãƒ—ï¼ˆæ­¯æŠœã‘ï¼‰
    - æœªæ¥æ—¥ä»˜
    - é–‹åº—ç›´å¾Œã®ãƒ‡ãƒ¼ã‚¿åˆ‡ã‚Šæ›¿ã‚ã‚Š
    """
    alerts = []
    now = datetime.now(JST)
    today_str = now.strftime('%Y-%m-%d')
    
    stores = daily_data.get('stores', {})
    
    for result_key, store_data in stores.items():
        for unit in store_data.get('units', []):
            unit_id = str(unit.get('unit_id', '?'))
            days = unit.get('days', [])
            
            for day in days:
                date = day.get('date', '')
                if not date:
                    continue
                
                # æœªæ¥æ—¥ä»˜
                if date > today_str:
                    alerts.append(Alert(
                        Alert.CRITICAL, 'future_date',
                        result_key,
                        f"å°{unit_id}: æœªæ¥æ—¥ä»˜ {date} ãŒæ··å…¥",
                        {'unit_id': unit_id, 'date': date}
                    ))
    
    # è“„ç©DBã®æ­¯æŠœã‘æ—¥ãƒã‚§ãƒƒã‚¯
    if HISTORY_DIR.exists():
        for store_dir in HISTORY_DIR.iterdir():
            if not store_dir.is_dir():
                continue
            store_key = store_dir.name
            
            for unit_file in store_dir.glob('*.json'):
                try:
                    with open(unit_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    unit_id = data.get('unit_id', unit_file.stem)
                    days = data.get('days', [])
                    if len(days) < 3:
                        continue
                    
                    # å–¶æ¥­æ—¥ï¼ˆå®šä¼‘æ—¥é™¤ãï¼‰ã®æ­¯æŠœã‘ã‚’æ¤œå‡º
                    dates = sorted(d.get('date', '') for d in days if d.get('date'))
                    if len(dates) >= 2:
                        gaps = []
                        for i in range(1, len(dates)):
                            d1 = datetime.strptime(dates[i-1], '%Y-%m-%d')
                            d2 = datetime.strptime(dates[i], '%Y-%m-%d')
                            gap = (d2 - d1).days
                            if gap > 2:  # 2æ—¥ä»¥ä¸Šã®ã‚®ãƒ£ãƒƒãƒ—ï¼ˆ1æ—¥ä¼‘ã¿ã¯è¨±å®¹ï¼‰
                                gaps.append(f"{dates[i-1]}â†’{dates[i]}({gap}æ—¥)")
                        
                        if gaps:
                            alerts.append(Alert(
                                Alert.INFO, 'date_gap',
                                store_key,
                                f"å°{unit_id}: æ—¥ä»˜ã‚®ãƒ£ãƒƒãƒ— {', '.join(gaps[:3])}",
                                {'unit_id': unit_id, 'gaps': gaps}
                            ))
                except (json.JSONDecodeError, IOError):
                    continue
    
    return alerts


def check_data_quality(daily_data: dict) -> list:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
    
    - ç•°å¸¸ãªå·®æšå€¤
    - ã‚ã‚Šãˆãªã„ARTç¢ºç‡
    - historyã®æ™‚ç³»åˆ—çŸ›ç›¾
    """
    alerts = []
    stores = daily_data.get('stores', {})
    
    for result_key, store_data in stores.items():
        machine_key = store_data.get('machine_key', 'sbj')
        
        for unit in store_data.get('units', []):
            unit_id = str(unit.get('unit_id', '?'))
            days = unit.get('days', [])
            
            for day in days:
                art = day.get('art', 0) or 0
                games = day.get('total_start', 0) or day.get('games', 0) or 0
                date = day.get('date', '?')
                diff = day.get('diff_medals')
                
                # ARTç¢ºç‡ãƒã‚§ãƒƒã‚¯
                if art > 0 and games > 0:
                    prob = games / art
                    if prob < 1:
                        alerts.append(Alert(
                            Alert.CRITICAL, 'impossible_prob',
                            result_key,
                            f"å°{unit_id} {date}: ARTç¢ºç‡ 1/{prob:.1f} â€” ç‰©ç†çš„ã«ã‚ã‚Šãˆãªã„",
                            {'unit_id': unit_id, 'date': date, 'art': art, 'games': games}
                        ))
                    elif prob > 5000:
                        alerts.append(Alert(
                            Alert.WARNING, 'extreme_prob',
                            result_key,
                            f"å°{unit_id} {date}: ARTç¢ºç‡ 1/{prob:.0f} â€” ç•°å¸¸ã«æ‚ªã„",
                            {'unit_id': unit_id, 'date': date, 'art': art, 'games': games}
                        ))
                
                # å·®æšãƒã‚§ãƒƒã‚¯
                if diff is not None and abs(diff) > 50000:
                    alerts.append(Alert(
                        Alert.WARNING, 'extreme_diff',
                        result_key,
                        f"å°{unit_id} {date}: å·®æš{diff:+,}æš â€” ç•°å¸¸å€¤ã®å¯èƒ½æ€§",
                        {'unit_id': unit_id, 'date': date, 'diff': diff}
                    ))
                
                # historyã®æ™‚ç³»åˆ—ãƒã‚§ãƒƒã‚¯
                history = day.get('history', [])
                if len(history) >= 2:
                    times = [h.get('time', '') for h in history if h.get('time')]
                    if times and all(t for t in times):
                        # æ–°ã—ã„é †â†’å¤ã„é †ã®ã¯ãšãŒã€æ˜‡é †ã«ãªã£ã¦ãªã„ã‹ãƒã‚§ãƒƒã‚¯
                        # (daidataã¯æ–°ã—ã„é †ã€papimoã‚‚æ–°ã—ã„é †)
                        pass  # é †åºã¯å–å¾—å…ƒä¾å­˜ãªã®ã§è»½ããƒã‚§ãƒƒã‚¯
    
    return alerts


def check_opening_data_transition(daily_data: dict) -> list:
    """é–‹åº—æ™‚ã®ãƒ‡ãƒ¼ã‚¿åˆ‡ã‚Šæ›¿ã‚ã‚Šãƒã‚§ãƒƒã‚¯
    
    æ—¥ä»˜ãŒå¤‰ã‚ã£ãŸç›´å¾Œï¼ˆ10:00é–‹åº—ï¼‰ã«å–å¾—ã—ãŸå ´åˆã€
    ã‚µã‚¤ãƒˆå´ãŒå‰æ—¥ãƒ‡ãƒ¼ã‚¿â†’å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã«åˆ‡ã‚Šæ›¿ã‚ã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§
    å¤ã„ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
    """
    alerts = []
    now = datetime.now(JST)
    
    # 10:00-11:00ã®é–“ã«å–å¾—ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯æ³¨æ„
    collected_at_str = daily_data.get('collected_at', '')
    if collected_at_str:
        try:
            collected_at = datetime.fromisoformat(collected_at_str)
            if collected_at.tzinfo is None:
                collected_at = collected_at.replace(tzinfo=JST)
            hour = collected_at.hour
            if 10 <= hour <= 11:
                alerts.append(Alert(
                    Alert.WARNING, 'early_collection',
                    'system',
                    f"ãƒ‡ãƒ¼ã‚¿åé›†ãŒé–‹åº—ç›´å¾Œï¼ˆ{hour}æ™‚å°ï¼‰ã€‚ã‚µã‚¤ãƒˆå´ã®æ—¥ä»˜åˆ‡æ›¿å‰ã®å¯èƒ½æ€§ã‚ã‚Š",
                    {'collected_at': collected_at_str}
                ))
        except (ValueError, TypeError):
            pass
    
    return alerts


def run_all_checks(daily_data: dict) -> list:
    """å…¨ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
    all_alerts = []
    
    print('\n' + '=' * 60)
    print('ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯')
    print('=' * 60)
    
    # 1. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å“è³ª
    print('\n[1/5] ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å“è³ªãƒã‚§ãƒƒã‚¯...')
    alerts = check_scraping_quality(daily_data)
    all_alerts.extend(alerts)
    _print_section_result(alerts)
    
    # 2. å°ç•ªå·/æ©Ÿç¨®å/å°æ•°
    print('\n[2/5] å°ç•ªå·/æ©Ÿç¨®å/å°æ•°ãƒã‚§ãƒƒã‚¯...')
    alerts = check_unit_changes(daily_data)
    all_alerts.extend(alerts)
    _print_section_result(alerts)
    
    # 3. æ—¥ä»˜æ•´åˆæ€§
    print('\n[3/5] æ—¥ä»˜æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯...')
    alerts = check_date_integrity(daily_data)
    all_alerts.extend(alerts)
    _print_section_result(alerts)
    
    # 4. ãƒ‡ãƒ¼ã‚¿å“è³ª
    print('\n[4/5] ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯...')
    alerts = check_data_quality(daily_data)
    all_alerts.extend(alerts)
    _print_section_result(alerts)
    
    # 5. é–‹åº—æ™‚ãƒ‡ãƒ¼ã‚¿åˆ‡ã‚Šæ›¿ã‚ã‚Š
    print('\n[5/5] é–‹åº—æ™‚ãƒ‡ãƒ¼ã‚¿åˆ‡æ›¿ãƒã‚§ãƒƒã‚¯...')
    alerts = check_opening_data_transition(daily_data)
    all_alerts.extend(alerts)
    _print_section_result(alerts)
    
    # ã‚µãƒãƒªãƒ¼
    _print_summary(all_alerts)
    
    return all_alerts


def _print_section_result(alerts):
    if not alerts:
        print('  âœ… å•é¡Œãªã—')
    else:
        for a in alerts:
            print(f'  {a}')


def _print_summary(alerts):
    critical = [a for a in alerts if a.level == Alert.CRITICAL]
    warnings = [a for a in alerts if a.level == Alert.WARNING]
    info = [a for a in alerts if a.level == Alert.INFO]
    
    print(f'\n{"=" * 60}')
    print(f'ğŸ“Š ãƒã‚§ãƒƒã‚¯çµæœã‚µãƒãƒªãƒ¼')
    print(f'  ğŸ”´ é‡å¤§: {len(critical)}ä»¶')
    print(f'  ğŸŸ¡ è­¦å‘Š: {len(warnings)}ä»¶')
    print(f'  ğŸ”µ æƒ…å ±: {len(info)}ä»¶')
    
    if critical:
        print(f'\nâš ï¸ é‡å¤§ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆWhatsAppé€šçŸ¥å¯¾è±¡ï¼‰:')
        for a in critical:
            print(f'  {a}')
    
    print('=' * 60)


def save_check_result(alerts: list, source: str = 'daily') -> Path:
    """ãƒã‚§ãƒƒã‚¯çµæœã‚’ä¿å­˜"""
    alerts_dir = PROJECT_ROOT / 'data' / 'alerts'
    alerts_dir.mkdir(parents=True, exist_ok=True)
    
    now = datetime.now(JST)
    filename = f"integrity_{source}_{now.strftime('%Y%m%d_%H%M%S')}.json"
    filepath = alerts_dir / filename
    
    result = {
        'checked_at': now.isoformat(),
        'source': source,
        'summary': {
            'critical': len([a for a in alerts if a.level == Alert.CRITICAL]),
            'warning': len([a for a in alerts if a.level == Alert.WARNING]),
            'info': len([a for a in alerts if a.level == Alert.INFO]),
        },
        'alerts': [a.to_dict() for a in alerts],
    }
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    return filepath


def format_notification(alerts: list) -> str:
    """WhatsAppé€šçŸ¥ç”¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆé‡å¤§ã‚¢ãƒ©ãƒ¼ãƒˆã®ã¿ï¼‰"""
    critical = [a for a in alerts if a.level == Alert.CRITICAL]
    if not critical:
        return ''
    
    lines = [f'âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ â€” é‡å¤§ã‚¢ãƒ©ãƒ¼ãƒˆ {len(critical)}ä»¶']
    lines.append('')
    
    for a in critical:
        lines.append(f'ğŸ”´ {a.message}')
    
    lines.append('')
    lines.append('ç¢ºèªã—ã¦ãã ã•ã„ã€‚')
    
    return '\n'.join(lines)


def main():
    """ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œ"""
    import argparse
    parser = argparse.ArgumentParser(description='ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯')
    parser.add_argument('--file', type=str, help='ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®JSONãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--latest', action='store_true', help='æœ€æ–°ã®dailyãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•é¸æŠ')
    args = parser.parse_args()
    
    if args.file:
        filepath = Path(args.file)
    elif args.latest:
        daily_dir = PROJECT_ROOT / 'data' / 'daily'
        files = sorted(daily_dir.glob('daily_sbj_hokuto_tensei2_*.json'), reverse=True)
        if not files:
            files = sorted(daily_dir.glob('daily_*.json'), reverse=True)
        if not files:
            print('ãƒ‡ã‚¤ãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
            sys.exit(1)
        filepath = files[0]
    else:
        print('--file ã¾ãŸã¯ --latest ã‚’æŒ‡å®šã—ã¦ãã ã•ã„')
        sys.exit(1)
    
    print(f'ãƒã‚§ãƒƒã‚¯å¯¾è±¡: {filepath.name}')
    
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    alerts = run_all_checks(data)
    
    if alerts:
        save_path = save_check_result(alerts)
        print(f'\nçµæœä¿å­˜: {save_path}')
    
    # é‡å¤§ã‚¢ãƒ©ãƒ¼ãƒˆãŒã‚ã‚Œã°éã‚¼ãƒ­çµ‚äº†
    critical = [a for a in alerts if a.level == Alert.CRITICAL]
    if critical:
        notification = format_notification(alerts)
        print(f'\nğŸ“± é€šçŸ¥ãƒ†ã‚­ã‚¹ãƒˆ:\n{notification}')
        sys.exit(1)


if __name__ == '__main__':
    main()
