#!/usr/bin/env python3
"""
é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Cloudflare Pagesç”¨ã«é™çš„HTMLã‚’ç”Ÿæˆã™ã‚‹
GitHub Actionsã§å®šæœŸå®Ÿè¡Œã—ã€ç”Ÿæˆã—ãŸHTMLã‚’ãƒ‡ãƒ—ãƒ­ã‚¤
"""

import glob
import json
import os
import sys
from datetime import datetime, timezone, timedelta
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# === ãƒ“ãƒ«ãƒ‰å‰ã®ä»•æ§˜æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ ===
from scripts.pre_build_check import run_all as _pre_build_check
_pre_build_errors = _pre_build_check()
if _pre_build_errors > 0:
    print(f'\nğŸ›‘ ä»•æ§˜æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼ {_pre_build_errors}ä»¶ â€” CLAUDE.md / config/rankings.py ã‚’ç¢ºèªã—ã¦ãã ã•ã„')
    sys.exit(1)

from jinja2 import Environment, FileSystemLoader
from analysis.verdict import get_result_level, get_verdict, is_hit as v_is_hit, RESULT_MARKS
from config.rankings import STORES, MACHINES, get_stores_by_machine, get_machine_info
from analysis.recommender import recommend_units, load_daily_data, generate_store_analysis, calculate_expected_profit, analyze_today_graph, calculate_at_intervals, get_machine_from_store_key
from analysis.analyzer import calculate_first_hits, mark_first_hits
from scrapers.availability_checker import get_availability, get_realtime_data
from scripts.verify_units import get_active_alerts, get_unit_status

JST = timezone(timedelta(hours=9))
WEEKDAY_NAMES = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUTPUT_DIR = PROJECT_ROOT / 'docs'  # GitHub Pagesäº’æ›


def get_display_mode():
    """ç¾åœ¨æ™‚åˆ»ã‹ã‚‰è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ã‚’æ±ºå®š
    - before_open: 0:00-9:59ï¼ˆå–¶æ¥­å‰ï¼‰
    - after_close: 22:50-23:59ï¼ˆé–‰åº—å¾Œï¼‰
    - realtime: 10:00-22:49ï¼ˆå–¶æ¥­ä¸­ï¼‰
    """
    now = datetime.now(JST)
    hour = now.hour
    minute = now.minute

    if hour < 10:
        return 'before_open'
    elif hour >= 23 or (hour == 22 and minute >= 50):
        return 'after_close'
    else:
        return 'realtime'


def format_date_with_weekday(dt):
    """æ—¥ä»˜ã‚’æ›œæ—¥ä»˜ãã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    weekday = WEEKDAY_NAMES[dt.weekday()]
    return f"{dt.month}æœˆ{dt.day}æ—¥({weekday})"


def is_business_hours():
    """å–¶æ¥­æ™‚é–“å†…ã‹ã©ã†ã‹"""
    return get_display_mode() == 'realtime'


def rank_color(rank):
    """ãƒ©ãƒ³ã‚¯è‰²ã‚’è¿”ã™"""
    colors = {
        'S': '#ff6b6b',
        'A': '#ffa502',
        'B': '#2ed573',
        'C': '#70a1ff',
        'D': '#747d8c',
    }
    return colors.get(rank, '#747d8c')


def signed_number(value):
    """ç¬¦å·ä»˜ãã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ•°å€¤"""
    try:
        num = int(value)
        if num >= 0:
            return f'+{num:,}'
        else:
            return f'{num:,}'
    except (ValueError, TypeError):
        return str(value)


def medals_badge(value):
    """æœ€å¤§ç²å¾—æšæ•°ãƒãƒƒã‚¸"""
    try:
        num = int(value)
        if num >= 10000:
            return {'class': 'medals-10k', 'icon': 'ğŸ”¥', 'label': '1ä¸‡æšOVER'}
        elif num >= 5000:
            return {'class': 'medals-5k', 'icon': 'ğŸ’°', 'label': '5åƒæšOVER'}
        elif num >= 3000:
            return {'class': 'medals-3k', 'icon': 'âœ¨', 'label': '3åƒæšOVER'}
        elif num >= 2000:
            return {'class': 'medals-2k', 'icon': 'â­', 'label': '2åƒæšOVER'}
        elif num >= 1000:
            return {'class': 'medals-1k', 'icon': 'ğŸ‘', 'label': '1åƒæšOVER'}
        return None
    except (ValueError, TypeError):
        return None


def setup_jinja():
    """Jinja2ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    template_dir = PROJECT_ROOT / 'web' / 'templates'
    env = Environment(loader=FileSystemLoader(str(template_dir)))

    # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ«ã‚¿ãƒ»é–¢æ•°ã‚’è¿½åŠ 
    env.globals['rank_color'] = rank_color
    env.globals['signed_number'] = signed_number
    env.globals['medals_badge'] = medals_badge
    env.globals['url_for'] = lambda endpoint, **kwargs: generate_url(endpoint, **kwargs)

    def pad_unit_id(uid):
        """å°ç•ªå·ã‚’4æ¡ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆ1â†’0001, 23â†’0023, 0752â†’0752ï¼‰"""
        s = str(uid)
        if s.isdigit() and len(s) < 4:
            return s.zfill(4)
        return s
    env.filters['pad_id'] = pad_unit_id
    env.globals['pad_id'] = pad_unit_id
    env.globals['build_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    env.globals['cache_bust'] = datetime.now().strftime('%Y%m%d%H%M%S')

    def generate_sparkline(history, width=120, height=40, diff_medals=None):
        """å½“ãŸã‚Šå±¥æ­´ã‹ã‚‰å·®æšæ¨ç§»ã®SVGã‚¹ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆ

        Args:
            history: å½“ãŸã‚Šå±¥æ­´ãƒªã‚¹ãƒˆ
            diff_medals: æ—¢çŸ¥ã®æœ€çµ‚å·®æšï¼ˆæ­£è¦åŒ–ã«ä½¿ç”¨ï¼‰
        """
        if not history or len(history) < 2:
            return ''
        # hit_numé™é †ï¼ˆå¤§ãã„=å¤ã„ï¼‰ã§ã‚½ãƒ¼ãƒˆ
        sorted_hist = sorted(history, key=lambda x: (-x.get('hit_num', 0), x.get('time', '00:00')))
        # å„å½“ãŸã‚Šã®ãƒ¡ãƒ€ãƒ«ç²å¾—æ•°ã§ç›¸å¯¾æ¨ç§»ã‚’è¨ˆç®—
        # medals: ãƒœãƒ¼ãƒŠã‚¹/ATç²å¾—æšæ•°ã€start: å½“ãŸã‚Šé–“ã®æ¶ˆåŒ–Gæ•°
        cumulative = [0]
        total = 0
        for h in sorted_hist:
            medals = h.get('medals', 0)
            start = h.get('start', 0)
            total -= start * 3  # å½“ãŸã‚Šé–“ã®æŠ•å…¥
            total += medals      # ç²å¾—
            cumulative.append(total)

        # æ—¢çŸ¥ã®å·®æšãŒã‚ã‚Œã°æ­£è¦åŒ–ï¼ˆæ¨ç§»ã®å½¢ã¯ä¿ã¡ã€æœ€çµ‚å€¤ã‚’åˆã‚ã›ã‚‹ï¼‰
        if diff_medals is not None and total != 0:
            scale = diff_medals / total
            cumulative = [v * scale for v in cumulative]
        elif diff_medals is not None and total == 0:
            # ç´¯ç©0ã ãŒå·®æšãŒã‚ã‚‹å ´åˆã€æ¨ç§»ãŒæã‘ãªã„ã®ã§ã‚¹ã‚­ãƒƒãƒ—
            pass
        if len(cumulative) < 2:
            return ''
        min_v = min(cumulative)
        max_v = max(cumulative)
        v_range = max_v - min_v if max_v != min_v else 1
        # SVGãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ
        points = []
        for i, v in enumerate(cumulative):
            x = i / (len(cumulative) - 1) * width
            y = height - ((v - min_v) / v_range * (height - 4)) - 2
            points.append(f'{x:.1f},{y:.1f}')
        polyline = ' '.join(points)
        # ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³
        zero_y = height - ((0 - min_v) / v_range * (height - 4)) - 2
        # è‰²: æœ€çµ‚å€¤ãŒãƒ—ãƒ©ã‚¹ãªã‚‰ç·‘ã€ãƒã‚¤ãƒŠã‚¹ãªã‚‰èµ¤ï¼ˆæ­£è¦åŒ–å¾Œã®å€¤ã§åˆ¤å®šï¼‰
        final_val = cumulative[-1] if cumulative else total
        color = '#2ed573' if final_val >= 0 else '#ff6b6b'
        return f'<svg class="sparkline" viewBox="0 0 {width} {height}" preserveAspectRatio="xMidYMid meet"><line x1="0" y1="{zero_y:.1f}" x2="{width}" y2="{zero_y:.1f}" stroke="#555" stroke-width="0.5" stroke-dasharray="2,2"/><polyline points="{polyline}" fill="none" stroke="{color}" stroke-width="1.5"/></svg>'
    env.globals['sparkline'] = generate_sparkline

    def format_short_date(date_str):
        """'2026-01-26' â†’ '1/26(æœˆ)'"""
        if not date_str:
            return ''
        try:
            dt = datetime.strptime(str(date_str), '%Y-%m-%d')
            return f"{dt.month}/{dt.day}({WEEKDAY_NAMES[dt.weekday()]})"
        except:
            return str(date_str)
    env.globals['short_date'] = format_short_date

    return env


def generate_url(endpoint, **kwargs):
    """é™çš„ã‚µã‚¤ãƒˆç”¨ã®URLç”Ÿæˆï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ï¼‰"""
    if endpoint == 'index':
        return '/index.html'
    elif endpoint == 'static':
        return f"/static/{kwargs.get('filename', '')}"
    elif endpoint == 'recommend':
        return f"/recommend/{kwargs.get('store_key', '')}.html"
    elif endpoint == 'machine_stores':
        return f"/machine/{kwargs.get('machine_key', '')}.html"
    elif endpoint == 'ranking':
        return f"/ranking/{kwargs.get('machine_key', '')}.html"
    elif endpoint == 'rules':
        return '/rules.html'
    elif endpoint == 'unit_history':
        return f"/history/{kwargs.get('store_key', '')}_{kwargs.get('unit_id', '')}.html"
    elif endpoint == 'api_status':
        return f"https://autogmail.pythonanywhere.com/api/status/{kwargs.get('store_key', '')}"
    elif endpoint == 'verify':
        return '/verify.html'
    return '#'


def generate_index(env):
    """ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating index.html...")

    template = env.get_template('index.html')

    now = datetime.now(JST)
    display_mode = get_display_mode()
    is_open = is_business_hours()
    # æ›œæ—¥å‚¾å‘ã¯å¸¸ã«ã€Œæ¬¡ã«é–‹åº—ã™ã‚‹æ—¥ã€ã®æ›œæ—¥
    # 22:45ã€œ23:59ã¯ç¿Œæ—¥ã€0:00ã€œ09:59ã¯ãã®æ—¥ï¼ˆæ—¢ã«æ—¥ä»˜ãŒå¤‰ã‚ã£ã¦ã„ã‚‹ï¼‰
    if is_open:
        today_weekday = WEEKDAY_NAMES[now.weekday()]
    elif now.hour >= 22:
        # 22:45ã€œ23:59 â†’ ç¿Œæ—¥ã®æ›œæ—¥
        tomorrow_dt = now + timedelta(days=1)
        today_weekday = WEEKDAY_NAMES[tomorrow_dt.weekday()]
    else:
        # 0:00ã€œ09:59 â†’ ä»Šæ—¥ã®æ›œæ—¥ï¼ˆæ—¥ä»˜ã¯æ—¢ã«å¤‰ã‚ã£ã¦ã„ã‚‹ï¼‰
        today_weekday = WEEKDAY_NAMES[now.weekday()]
    today_date = now.strftime('%Y/%m/%d')
    today_date_formatted = format_date_with_weekday(now)

    # ç†ç”±æ–‡ã®æ—¥ä»˜ãƒ©ãƒ™ãƒ«
    reason_data_label, reason_prev_label = get_reason_date_labels()

    # åº—èˆ—æ›œæ—¥å‚¾å‘ï¼ˆç‰©ç†åº—èˆ—ãƒ™ãƒ¼ã‚¹ï¼‰
    store_day_ratings = {
        'island_akihabara': {
            'name': 'ã‚¢ã‚¤ãƒ©ãƒ³ãƒ‰ç§‹è‘‰åŸ',
            'short_name': 'ã‚¢ã‚¤ãƒ©ãƒ³ãƒ‰ç§‹è‘‰åŸ',
            'day_ratings': {'æœˆ': 4, 'ç«': 3, 'æ°´': 5, 'æœ¨': 3, 'é‡‘': 3, 'åœŸ': 1, 'æ—¥': 4},
            'best_note': 'æ°´æ›œãŒæœ€å¼·ã€æ—¥æœˆã‚‚ç‹™ã„ç›®',
            'worst_note': 'åœŸæ›œã¯é¿ã‘ã‚‹ã¹ã',
            'overall_rating': 4,
            'machine_links': [
                {'store_key': 'island_akihabara_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'island_akihabara_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'shibuya_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“æ¸‹è°·æ–°é¤¨',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ¸‹è°·æ–°é¤¨',
            'day_ratings': {'æœˆ': 3, 'ç«': 4, 'æ°´': 4, 'æœ¨': 5, 'é‡‘': 3, 'åœŸ': 3, 'æ—¥': 1},
            'best_note': 'æœ¨æ›œãŒæœ€å¼·ã€ç«æ°´ã‚‚ç‹™ã„ç›®',
            'worst_note': 'æ—¥æ›œã¯é¿ã‘ã‚‹ã¹ã',
            'overall_rating': 3,
            'machine_links': [
                {'store_key': 'shibuya_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'shibuya_espass_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'shibuya_honkan_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“æ¸‹è°·æœ¬é¤¨',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ¸‹è°·æœ¬é¤¨',
            'day_ratings': {'æœˆ': 3, 'ç«': 3, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 3, 'åœŸ': 3, 'æ—¥': 3},
            'best_note': 'æ–°è¦è¿½åŠ ã€‚ãƒ‡ãƒ¼ã‚¿åé›†ä¸­',
            'worst_note': '',
            'overall_rating': 3,
            'machine_links': [
                {'store_key': 'shibuya_honkan_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'shibuya_honkan_espass_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'shinjuku_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“æ–°å®¿æ­Œèˆä¼ç”ºåº—',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ­Œèˆä¼ç”º',
            'day_ratings': {'æœˆ': 2, 'ç«': 3, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 5, 'æ—¥': 3},
            'best_note': 'åœŸæ›œãŒæœ€å¼·ã€é‡‘æ›œã‚‚ç‹™ã„ç›®',
            'worst_note': 'æœˆæ›œã¯æ§ãˆã‚',
            'overall_rating': 3,
            'machine_links': [
                {'store_key': 'shinjuku_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'shinjuku_espass_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'akiba_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“ç§‹è‘‰åŸé§…å‰åº—',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹ç§‹è‘‰åŸ',
            'day_ratings': {'æœˆ': 2, 'ç«': 3, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 5, 'æ—¥': 4},
            'best_note': 'åœŸæ—¥ãŒç‹™ã„ç›®ã€é‡‘æ›œã‚‚å¯',
            'worst_note': 'æœˆæ›œã¯æ§ãˆã‚',
            'overall_rating': 3,
            'machine_links': [
                {'store_key': 'akiba_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'akiba_espass_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'seibu_shinjuku_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“è¥¿æ­¦æ–°å®¿é§…å‰åº—',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹è¥¿æ­¦æ–°å®¿',
            'day_ratings': {'æœˆ': 2, 'ç«': 2, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 4, 'æ—¥': 3},
            'best_note': 'é‡‘åœŸãŒç‹™ã„ç›®',
            'worst_note': 'æœˆç«ã¯æ§ãˆã‚',
            'overall_rating': 2,
            'machine_links': [
                {'store_key': 'seibu_shinjuku_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
            ],
        },
    }

    # å‰æ—¥ã®ç­”ãˆåˆã‚ã›ãƒ‡ãƒ¼ã‚¿ï¼ˆäºˆæ¸¬ãƒ©ãƒ³ã‚¯ã®å‚ç…§ç”¨ï¼‰
    verify_lookup = {}  # {store_key: {unit_id: {predicted_rank, predicted_score, ...}}}
    try:
        import datetime as _dt_mod
        _yesterday_str = (_dt_mod.datetime.now() - _dt_mod.timedelta(days=1)).strftime('%Y%m%d')
        _verify_path = Path(f'data/verify/verify_{_yesterday_str}.json')
        if _verify_path.exists():
            import json as _json_mod
            _verify_data = _json_mod.loads(_verify_path.read_text())
            for _vsk, _vunits in _verify_data.items():
                if isinstance(_vunits, list):
                    verify_lookup[_vsk] = {str(u['unit_id']): u for u in _vunits}
            print(f"  verify ãƒ‡ãƒ¼ã‚¿èª­è¾¼: {len(verify_lookup)}åº—èˆ—åˆ†")
    except Exception as e:
        print(f"  verify ãƒ‡ãƒ¼ã‚¿èª­è¾¼ã‚¨ãƒ©ãƒ¼ï¼ˆç¶šè¡Œï¼‰: {e}")

    # æ©Ÿç¨®ä¸€è¦§ã¨ãƒˆãƒƒãƒ—å°ã‚’åé›†
    machines = []
    top3_all = []
    yesterday_top10 = []
    today_top10 = []

    for key, machine in MACHINES.items():
        stores = get_stores_by_machine(key)
        total_units = sum(len(s['units']) for s in stores.values())
        machines.append({
            'key': key,
            'name': machine['name'],
            'short_name': machine['short_name'],
            'icon': machine['icon'],
            'store_count': len(stores),
            'unit_count': total_units,
        })

        for store_key, store in stores.items():
            try:
                availability = {}
                try:
                    availability = get_availability(store_key)
                except:
                    pass

                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæœ¬æ—¥ã®ART/RBç­‰ï¼‰
                # å–¶æ¥­ä¸­ã®ã¿ä½¿ç”¨ã€‚é–‹åº—å‰/é–‰åº—å¾Œã¯staleãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã‚ãªã„
                realtime = None
                if is_open:
                    try:
                        realtime = get_realtime_data(store_key)
                    except:
                        pass

                recs = recommend_units(store_key, realtime_data=realtime, availability=availability,
                                      data_date_label=reason_data_label, prev_date_label=reason_prev_label)
                
                # availability.jsonã‹ã‚‰ç›´æ¥today_historyã‚’å–å¾—ã—ã¦ã‚»ãƒƒãƒˆ
                # ï¼ˆrecommenderãŒè¨­å®šã—ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                if realtime and 'units' in realtime:
                    for r in recs:
                        if not r.get('today_history'):
                            for ru in realtime.get('units', []):
                                if str(ru.get('unit_id')) == str(r.get('unit_id')):
                                    if ru.get('today_history'):
                                        r['today_history'] = ru.get('today_history')
                                    break
                
                # recommenderãŒè¿”ã™todayé–¢é€£ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
                # today_historyã‹ã‚‰art/rensa/diff_medalsã‚’å†è¨ˆç®—ã—ã¦ä¸€è²«æ€§ã‚’ä¿ã¤
                from analysis.analyzer import calculate_max_rensa as _calc_rensa
                for r in recs:
                    _art = r.get('art_count', 0)
                    _games = r.get('total_games', 0)
                    _rensa = r.get('today_max_rensa', 0)
                    _hist = r.get('today_history', [])
                    
                    # today_historyã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
                    # recommenderã®art_countï¼ˆdaidataã‚½ãƒ¼ã‚¹ï¼‰ã¨today_historyï¼ˆJSONã‚½ãƒ¼ã‚¹ï¼‰ãŒ
                    # ç•°ãªã‚‹æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã—ã¦ã‚‹å ´åˆãŒã‚ã‚‹
                    if _hist:
                        _hist_art = sum(1 for h in _hist if h.get('type', '') in ('ART', 'AT', 'BB'))
                        _hist_rb = sum(1 for h in _hist if h.get('type', '') == 'RB')
                        _mk = r.get('machine_key', '') or get_machine_from_store_key(store_key)
                        _hist_rensa = _calc_rensa(_hist, machine_key=_mk)
                        
                        # art_countã¨history ARTæ•°ãŒè¿‘ã‘ã‚Œã°åŒã˜æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã¨ã¿ãªã™
                        # ï¼ˆãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®ã‚ºãƒ¬ã§æ•°å›ã®å·®ãŒå‡ºã‚‹ï¼‰
                        if _art > 0 and abs(_art - _hist_art) <= 5:
                            # ã»ã¼ä¸€è‡´ â†’ historyã‹ã‚‰rensaã‚’å†è¨ˆç®—
                            r['today_max_rensa'] = _hist_rensa
                        elif _art > 0 and _hist_art > 0 and _art >= _hist_art:
                            # art_countã®æ–¹ãŒå¤šã„ â†’ ãƒ‡ãƒ¼ã‚¿å–å¾—å¾Œã«å¢—ãˆãŸã ã‘ã€historyã¯æœ‰åŠ¹
                            r['today_max_rensa'] = _hist_rensa
                        elif _art > 0 and _hist_art > _art + 10:
                            # historyã®æ–¹ãŒå¤§å¹…ã«å¤šã„ â†’ åˆ¥æ—¥ã®stale
                            r['today_history'] = []
                            r['today_max_rensa'] = 0
                        elif _art == 0 and _hist_art > 0:
                            # art_countæœªè¨­å®šã ãŒhistoryã‚ã‚Š â†’ historyãƒ™ãƒ¼ã‚¹ã§è¡¨ç¤º
                            r['art_count'] = _hist_art
                            r['rb_count'] = _hist_rb
                            r['today_max_rensa'] = _hist_rensa
                        # else: ä¸¡æ–¹0 â†’ ä½•ã‚‚ã—ãªã„
                    
                    # historyãŒãªã„å ´åˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    elif _art == 0:
                        r['today_max_rensa'] = 0
                        r['diff_medals'] = 0
                        # ã€Œæœ¬æ—¥ã€ã‚’å«ã‚€ç†ç”±ãƒ†ã‚­ã‚¹ãƒˆã‚‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                        for key in ('today_reasons', 'reasons'):
                            if key in r and r[key]:
                                r[key] = [reason for reason in r[key] 
                                          if 'æœ¬æ—¥' not in reason]
                    
                    # ç¨¼åƒé–‹å§‹å¾Œï¼ˆART > 0ï¼‰ã¯æ˜¨æ—¥ãƒ™ãƒ¼ã‚¹ã®ç†ç”±ã‚’ã‚¯ãƒªã‚¢
                    if _art > 0:
                        stale_patterns = ['é€”ä¸­æ”¾æ£„', 'æœ€çµ‚', 'ã‚„ã‚', 'ç‹™ã„ä½™åœ°']
                        for key in ('today_reasons', 'reasons'):
                            if key in r and r[key]:
                                r[key] = [reason for reason in r[key] 
                                          if not any(p in reason for p in stale_patterns)]

                # å…¨recsã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä»˜ä¸
                for rec in recs:
                    rec['store_name'] = store.get('short_name', store['name'])
                    rec['store_key'] = store_key
                    rec['machine_key'] = key
                    rec['machine_icon'] = machine['icon']
                    rec['machine_name'] = machine.get('display_name', machine['short_name'])
                    if 'availability' not in rec or rec['availability'] is None:
                        rec['availability'] = availability.get(rec['unit_id'], '')
                    # å·®æšè¨ˆç®—ã¯recommend_unitså†…ã§çµ±åˆæ¸ˆã¿
                    # åˆå½“ãŸã‚Šå›æ•°ã‚’è¨ˆç®—ï¼ˆTOP3è¡¨ç¤ºç”¨ï¼‰
                    _y_hist = rec.get('yesterday_history', [])
                    if _y_hist:
                        rec['first_hit_count'] = calculate_first_hits(_y_hist)['first_hit_count']
                    else:
                        rec['first_hit_count'] = 0

                # TOP3å€™è£œï¼ˆä¸Šä½3å°/åº—èˆ—ï¼‰
                for rec in recs[:3]:
                    top3_all.append(rec)

                # å‰æ—¥ã®çˆ†ç™ºå°ï¼ˆå…¨å°ã‹ã‚‰åé›†ã€yesterday_art > 0ï¼‰
                for rec in recs:
                    y_art = rec.get('yesterday_art', 0)
                    if y_art and y_art > 0:
                        y_games = rec.get('yesterday_games', 0)
                        y_prob = int(y_games / y_art) if y_art > 0 and y_games > 0 else 0
                        # å·®æšè¨ˆç®—ï¼ˆmedalsãƒ™ãƒ¼ã‚¹å„ªå…ˆ â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§æ©Ÿæ¢°å‰²ãƒ™ãƒ¼ã‚¹ï¼‰
                        y_diff_medals = 0
                        y_setting = ''
                        y_setting_num = 0
                        if y_art > 0 and y_games > 0:
                            # è¨­å®šæ¨å®šï¼ˆè¡¨ç¤ºç”¨ï¼‰
                            y_profit = calculate_expected_profit(y_games, y_art, key)
                            y_si = y_profit.get('setting_info', {})
                            y_setting = y_si.get('estimated_setting', '')
                            y_setting_num = y_si.get('setting_num', 0)
                            # å·®æš: historyã®medalsåˆè¨ˆã‹ã‚‰å®Ÿæ¸¬ãƒ™ãƒ¼ã‚¹ã§æ¨å®š
                            try:
                                from analysis.history_accumulator import load_unit_history
                                from analysis.diff_medals_estimator import estimate_diff_medals
                                acc = load_unit_history(store_key, rec['unit_id'])
                                y_date = rec.get('yesterday_date', '')
                                for ad in acc.get('days', []):
                                    if ad.get('date') == y_date:
                                        ad_hist = ad.get('history', [])
                                        ad_games = ad.get('games', ad.get('total_start', 0))
                                        if ad_hist and ad_games > 0:
                                            medals_total = sum(h.get('medals', 0) for h in ad_hist)
                                            y_diff_medals = estimate_diff_medals(medals_total, ad_games, key)
                                        break
                            except Exception:
                                pass
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: medalsãŒå–ã‚Œãªã‘ã‚Œã°æ©Ÿæ¢°å‰²ãƒ™ãƒ¼ã‚¹
                            if y_diff_medals == 0:
                                y_diff_medals = y_profit.get('current_estimate', 0)
                        # é€£ãƒãƒ£ãƒ³ãƒ»å¤©äº•ãƒ»æœ€å¤§ãƒ¡ãƒ€ãƒ«ã‚’è¨ˆç®—
                        y_max_rensa = rec.get('yesterday_max_rensa', 0) or rec.get('today_max_rensa', 0)
                        y_max_medals = rec.get('yesterday_max_medals', 0)
                        y_ceilings = 0
                        hist = rec.get('today_history', [])
                        if hist:
                            try:
                                graph = analyze_today_graph(hist)
                                y_max_rensa = max(y_max_rensa, graph.get('max_rensa', 0))
                                intervals = calculate_at_intervals(hist)
                                y_ceilings = sum(1 for g in intervals if g >= 999)
                                if not y_max_medals:
                                    from analysis.analyzer import calculate_max_chain_medals
                                    y_max_medals = calculate_max_chain_medals(hist)
                            except:
                                pass
                        # è“„ç©DBã‹ã‚‰ã‚‚è£œå®Œ
                        if not y_max_rensa or not y_max_medals:
                            try:
                                from analysis.history_accumulator import load_unit_history
                                from analysis.analyzer import calculate_max_chain_medals as _calc_chain
                                acc_hist = load_unit_history(store_key, rec['unit_id'])
                                y_date = rec.get('yesterday_date', '')
                                for ad in acc_hist.get('days', []):
                                    if ad.get('date') == y_date or (not y_date and ad == acc_hist['days'][-1]):
                                        if not y_max_rensa:
                                            y_max_rensa = ad.get('max_rensa', 0)
                                        if not y_max_medals:
                                            # historyãŒã‚ã‚Œã°é€£ãƒãƒ£ãƒ³ç´¯è¨ˆã§å†è¨ˆç®—
                                            ad_hist = ad.get('history', [])
                                            if ad_hist:
                                                y_max_medals = _calc_chain(ad_hist)
                                            else:
                                                y_max_medals = ad.get('max_medals', 0)
                                        break
                            except:
                                pass
                        # å‰æ—¥ã®äºˆæƒ³ãƒ©ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆverifyãƒ‡ãƒ¼ã‚¿å„ªå…ˆã€ãªã‘ã‚Œã°ç¾åœ¨ã®ãƒ©ãƒ³ã‚¯ï¼‰
                        unit_str = str(rec['unit_id'])
                        _vunit = verify_lookup.get(store_key, {}).get(unit_str, {})
                        predicted_rank = _vunit.get('predicted_rank', rec.get('final_rank', 'C'))
                        predicted_score = _vunit.get('predicted_score', rec.get('final_score', 50))
                        was_predicted_good = predicted_rank in ('S', 'A')
                        # çš„ä¸­åˆ¤å®šï¼ˆverdict.pyå…±é€šãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                        _y_diff = rec.get('yesterday_diff_medals', rec.get('diff_medals', 0))
                        _y_max = rec.get('yesterday_max_medals', rec.get('max_medals', 0))
                        _y_rl = get_result_level(y_prob, _y_diff, key, max_medals=_y_max)
                        _y_vtext, _y_vcls = get_verdict(predicted_rank, _y_rl)
                        if v_is_hit(predicted_rank, _y_rl):
                            prediction_result = 'hit'
                        elif _y_vcls == 'surprise':
                            prediction_result = 'missed'
                        elif _y_vcls == 'miss':
                            prediction_result = 'miss'
                        else:
                            prediction_result = 'correct'

                        # åˆå½“ãŸã‚Šè¨ˆç®— & å±¥æ­´ãƒãƒ¼ã‚­ãƒ³ã‚°
                        y_hist_raw = rec.get('yesterday_history', [])
                        t_hist_raw = rec.get('today_history', [])
                        y_first_hits = calculate_first_hits(y_hist_raw)
                        y_first_hit_count = y_first_hits['first_hit_count']
                        y_hist_marked = mark_first_hits(y_hist_raw)
                        t_hist_marked = mark_first_hits(t_hist_raw)

                        yesterday_top10.append({
                            'unit_id': rec['unit_id'],
                            'store_name': rec['store_name'],
                            'store_key': store_key,
                            'machine_icon': machine['icon'],
                            'machine_name': machine.get('display_name', machine['short_name']),
                            'yesterday_art': y_art,
                            'yesterday_rb': rec.get('yesterday_rb', 0),
                            'yesterday_games': y_games,
                            'yesterday_max_rensa': y_max_rensa,
                            'yesterday_max_medals': y_max_medals,
                            'yesterday_ceilings': y_ceilings,
                            'yesterday_prob': y_prob,
                            'diff_medals': y_diff_medals,
                            'yesterday_diff_medals': y_diff_medals,
                            'estimated_setting': y_setting,
                            'setting_num': y_setting_num,
                            'payout_estimate': y_si.get('payout_estimate', 100.0) if y_si else 100.0,
                            'predicted_rank': predicted_rank,
                            'predicted_score': predicted_score,
                            'prediction_result': prediction_result,
                            'yesterday_history': y_hist_marked,
                            'today_history': t_hist_marked,
                            'recent_days': rec.get('recent_days', []),
                            'first_hit_count': y_first_hit_count,
                            # å‰ã€…æ—¥ãƒ»3æ—¥å‰ãƒ‡ãƒ¼ã‚¿
                            'day_before_art': rec.get('day_before_art', 0),
                            'day_before_rb': rec.get('day_before_rb', 0),
                            'day_before_games': rec.get('day_before_games', 0),
                            'day_before_date': rec.get('day_before_date', ''),
                            'day_before_diff_medals': rec.get('day_before_diff_medals', 0),
                            'day_before_max_rensa': rec.get('day_before_max_rensa', 0),
                            'day_before_max_medals': rec.get('day_before_max_medals', 0),
                            'three_days_ago_art': rec.get('three_days_ago_art', 0),
                            'three_days_ago_rb': rec.get('three_days_ago_rb', 0),
                            'three_days_ago_games': rec.get('three_days_ago_games', 0),
                            'three_days_ago_date': rec.get('three_days_ago_date', ''),
                            'three_days_ago_diff_medals': rec.get('three_days_ago_diff_medals', 0),
                            'three_days_ago_max_rensa': rec.get('three_days_ago_max_rensa', 0),
                            'three_days_ago_max_medals': rec.get('three_days_ago_max_medals', 0),
                        })

                # æœ¬æ—¥ã®çˆ†ç™ºå°ï¼ˆå…¨å°ã‹ã‚‰åé›†ã€art_count > 0ï¼‰
                for rec in recs:
                    t_art = rec.get('art_count', 0)
                    t_medals = rec.get('max_medals', 0)
                    t_games = rec.get('total_games', 0)
                    if t_art > 0 or t_medals > 0:
                        # å·®æšè¨ˆç®—
                        diff_medals = 0
                        if t_art > 0 and t_games > 0:
                            profit = calculate_expected_profit(t_games, t_art, key)
                            diff_medals = profit.get('current_estimate', 0)
                        # åˆå½“ãŸã‚Šè¨ˆç®—
                        t_hist_raw2 = rec.get('today_history', [])
                        t_first_hits = calculate_first_hits(t_hist_raw2)
                        t_first_hit_count = t_first_hits['first_hit_count']
                        t_hist_marked2 = mark_first_hits(t_hist_raw2)

                        today_top10.append({
                            'unit_id': rec['unit_id'],
                            'store_name': rec['store_name'],
                            'store_key': store_key,
                            'machine_icon': machine['icon'],
                            'machine_name': machine.get('display_name', machine['short_name']),
                            'art_count': t_art,
                            'rb_count': rec.get('rb_count', 0),
                            'total_games': t_games,
                            'max_medals': t_medals,
                            'art_prob': rec.get('art_prob', 0),
                            'availability': rec.get('availability', ''),
                            'estimated_setting': rec.get('estimated_setting', ''),
                            'setting_num': rec.get('setting_num', 0),
                            'payout_estimate': rec.get('payout_estimate', ''),
                            'today_max_rensa': rec.get('today_max_rensa', 0),
                            'diff_medals': diff_medals,
                            'today_history': t_hist_marked2,
                            'first_hit_count': t_first_hit_count,
                        })
            except Exception as e:
                print(f"Error processing {store_key}: {e}")

    # ã‚½ãƒ¼ãƒˆ
    # TOP3: å„æ©Ÿç¨®ã®æœ€å¼·å°ã‚’1å°ãšã¤ + æ®‹ã‚Šæ ã¯å·®æšé †
    # æ©Ÿç¨®é–¢ä¿‚ãªãã€Œå‰æ—¥æœ€ã‚‚ç¨¼ã„ã S/Aå°ã€= é«˜è¨­å®šã®æ®ãˆç½®ãæœŸå¾…
    top3_candidates = [r for r in top3_all if r.get('final_rank') in ('S', 'A')]
    # ã‚¹ã‚³ã‚¢é †ï¼ˆä¿¡é ¼åº¦ãƒ»è©¦è¡Œå›æ•°ã‚’è€ƒæ…®ã—ãŸç·åˆã‚¹ã‚³ã‚¢ï¼‰
    top3_candidates.sort(key=lambda r: -r.get('final_score', 0))

    # å„æ©Ÿç¨®ã‹ã‚‰1å°ãšã¤ç¢ºä¿ + é‡è¤‡å°æ’é™¤ï¼ˆæœ€å¤§30å°ï¼‰
    top3 = []
    seen_machines = set()
    seen_units = set()
    for r in top3_candidates:
        mk = r.get('machine_key', '')
        uid = str(r.get('unit_id', ''))
        if mk not in seen_machines and uid not in seen_units:
            top3.append(r)
            seen_machines.add(mk)
            seen_units.add(uid)
        if len(top3) >= len(MACHINES):
            break
    # æ®‹ã‚Šæ ã‚’ã‚¹ã‚³ã‚¢é †ã§åŸ‹ã‚ã‚‹ï¼ˆ30å°ã¾ã§ï¼‰
    for r in top3_candidates:
        uid = str(r.get('unit_id', ''))
        if uid not in seen_units:
            top3.append(r)
            seen_units.add(uid)
        if len(top3) >= 30:
            break
    if not top3:
        top3 = top3_candidates[:30]

    # TOP3 + å…¨S/Aå€™è£œ + çˆ†ç™ºå°: è“„ç©DBã‹ã‚‰å‰æ—¥/å‰ã€…æ—¥/3æ—¥å‰ + recent_daysã‚’ä¸€æ‹¬è£œå®Œ
    # å…¨recã®è“„ç©DBè£œå®Œã‚’ä¸€æ‹¬å®Ÿè¡Œï¼ˆenrich_rec.py: 1ç®‡æ‰€ã§å…¨ãƒ‘ã‚¹ã‚’å‡¦ç†ï¼‰
    from scripts.enrich_rec import enrich_recs
    all_recs_to_enrich = list({id(r): r for r in top3 + top3_candidates + yesterday_top10 + today_top10}.values())
    enrich_recs(all_recs_to_enrich)

    # é–‰åº—å¾Œ/å½“æ—¥ãƒ‡ãƒ¼ã‚¿ãªã—ã®å ´åˆã€payout_estimateã‚’yesterdayãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å†è¨ˆç®—
    for rec in top3 + top3_candidates + yesterday_top10 + today_top10:
        if rec.get('payout_estimate', 100.0) == 100.0 or rec.get('art_count', 0) == 0:
            y_art = rec.get('yesterday_art', 0)
            y_games = rec.get('yesterday_games', 0)
            if y_art > 0 and y_games > 0:
                _mk = _get_machine_key(rec.get('store_key', ''))
                y_profit = calculate_expected_profit(y_games, y_art, _mk)
                y_si = y_profit.get('setting_info', {})
                rec['payout_estimate'] = y_si.get('payout_estimate', 100.0)
                rec['setting_num'] = y_si.get('setting_num', 0)
                rec['estimated_setting'] = y_si.get('estimated_setting', '')
    
    # æ—¥ä»˜ã‚’å›ºå®šåŒ–ï¼ˆå‰æ—¥ã€2æ—¥å‰ã€3æ—¥å‰ã€...7æ—¥å‰ï¼‰
    # ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ãŒæ­£ã—ããªã‘ã‚Œã°ã‚¯ãƒªã‚¢
    fixed_dates = [(now - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(1, 8)]
    fixed_yesterday = fixed_dates[0]
    fixed_day_before = fixed_dates[1]
    fixed_three_days = fixed_dates[2]
    
    for rec in top3 + top3_candidates + yesterday_top10 + today_top10:
        # å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
        if rec.get('yesterday_date', '') != fixed_yesterday:
            rec['yesterday_art'] = 0
            rec['yesterday_rb'] = 0
            rec['yesterday_games'] = 0
            rec['yesterday_diff_medals'] = 0
            rec['yesterday_max_rensa'] = 0
            rec['yesterday_max_medals'] = 0
            rec['yesterday_history'] = []
        rec['yesterday_date'] = fixed_yesterday
        
        # 2æ—¥å‰ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
        if rec.get('day_before_date', '') != fixed_day_before:
            rec['day_before_art'] = 0
            rec['day_before_rb'] = 0
            rec['day_before_games'] = 0
            rec['day_before_diff_medals'] = 0
            rec['day_before_max_rensa'] = 0
            rec['day_before_max_medals'] = 0
            rec['day_before_history'] = []
        rec['day_before_date'] = fixed_day_before
        
        # 3æ—¥å‰ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
        if rec.get('three_days_ago_date', '') != fixed_three_days:
            rec['three_days_ago_art'] = 0
            rec['three_days_ago_rb'] = 0
            rec['three_days_ago_games'] = 0
            rec['three_days_ago_diff_medals'] = 0
            rec['three_days_ago_max_rensa'] = 0
            rec['three_days_ago_max_medals'] = 0
            rec['three_days_ago_history'] = []
        rec['three_days_ago_date'] = fixed_three_days
        
        # recent_daysã‚‚æ—¥ä»˜å›ºå®šåŒ–
        if rec.get('recent_days'):
            new_recent_days = []
            for i, fixed_date in enumerate(fixed_dates[:7]):
                # è©²å½“æ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
                matching_day = None
                for day in rec.get('recent_days', []):
                    if day.get('date') == fixed_date:
                        matching_day = day
                        break
                if matching_day:
                    new_recent_days.append(matching_day)
                else:
                    # ãƒ‡ãƒ¼ã‚¿ãªã—ã®å ´åˆã¯ç©ºã‚¨ãƒ³ãƒˆãƒª
                    new_recent_days.append({'date': fixed_date, 'art': 0, 'games': 0})
            rec['recent_days'] = new_recent_days

    # TOP3 + å…¨S/Aå€™è£œ + çˆ†ç™ºå°ã®éå»3æ—¥åˆ†+å½“æ—¥ã®å½“ãŸã‚Šå±¥æ­´ã‚’åŠ å·¥
    for rec in top3 + top3_candidates + yesterday_top10 + today_top10:
        _mk = _get_machine_key(rec.get('store_key', ''))
        for hist_key in ('yesterday_history', 'day_before_history', 'three_days_ago_history', 'today_history'):
            raw_hist = rec.get(hist_key, [])
            proc_key = f'{hist_key}_processed'
            summ_key = f'{hist_key}_summary'
            if proc_key not in rec:  # é‡è¤‡åŠ å·¥é˜²æ­¢
                if raw_hist:
                    processed, summary = _process_history_for_verify(raw_hist, machine_key=_mk)
                    rec[proc_key] = processed
                    rec[summ_key] = summary
                    # today_historyã¯åŠ å·¥æ¸ˆã¿ã§ä¸Šæ›¸ãï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ç›´æ¥ä½¿ç”¨ï¼‰
                    if hist_key == 'today_history':
                        rec['today_history'] = processed
                else:
                    rec[proc_key] = []
                    rec[summ_key] = {}

        # recent_daysã®å„æ—¥ã®historyã‚‚åŠ å·¥ï¼ˆé€£ãƒãƒ£ãƒ³è¡¨è¨˜ãƒ»å¤©äº•åˆ¤å®šç”¨ï¼‰
        for day in rec.get('recent_days', []):
            raw_hist = day.get('history', [])
            if raw_hist and 'history_processed' not in day:
                processed, summary = _process_history_for_verify(raw_hist, machine_key=_mk)
                day['history_processed'] = processed
                day['history_summary'] = summary

    # å‰æ—¥ã®çˆ†ç™ºå°: æœ€å¤§é€£ãƒãƒ£ãƒ³æšæ•°ã§ã‚½ãƒ¼ãƒˆ
    # å·®æšã ã¨ã€Œä¸‡æšå‡ºã—ã¦é£²ã¾ã‚ŒãŸå°ã€ãŒä½ãå‡ºã‚‹ã€‚
    # max_chainï¼ˆ1å›ã®é€£ãƒãƒ£ãƒ³åŒºé–“ã®ç´¯è¨ˆæšæ•°ï¼‰ãªã‚‰çˆ†ç™ºã®ç¬é–“ã‚’æ­£ã—ãè©•ä¾¡ã€‚
    # å‰æ—¥ã®çˆ†ç™ºå°ã‚‚å·®æšå„ªå…ˆ
    yesterday_top10.sort(key=lambda x: (-x.get('yesterday_diff_medals', x.get('diff_medals', 0)), -x.get('yesterday_max_medals', 0)))
    yesterday_top10 = yesterday_top10[:10]

    # æœ¬æ—¥ã®çˆ†ç™ºå°: æœ€å¤§é€£ãƒãƒ£ãƒ³æšæ•°ã§ã‚½ãƒ¼ãƒˆ
    # çˆ†ç™ºå°ã¯å·®æšå„ªå…ˆï¼ˆæœã‹ã‚‰åº§ã£ã¦ãŸã‚‰ã„ãã‚‰å‹ã¦ãŸã‹ï¼‰
    today_top10.sort(key=lambda x: (-x.get('diff_medals', 0), -x.get('max_medals', 0)))
    today_top10 = today_top10[:10]

    # æ›œæ—¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    today_store_ranking = []
    for store_key, info in store_day_ratings.items():
        today_rating = info['day_ratings'].get(today_weekday, 3)
        today_store_ranking.append({
            'store_key': store_key,
            'name': info['name'],
            'short_name': info['short_name'],
            'today_rating': today_rating,
            'best_note': info['best_note'],
            'worst_note': info['worst_note'],
            'overall_rating': info['overall_rating'],
            'day_ratings': info['day_ratings'],
            'machine_links': info.get('machine_links', []),
        })
    today_store_ranking.sort(key=lambda x: -x['today_rating'])

    today_recommended_stores = [s for s in today_store_ranking if s['today_rating'] >= 4]
    today_avoid_stores = [s for s in today_store_ranking if s['today_rating'] <= 2]

    result_date_str = None
    date_prefix = ''  # ã€Œæ˜¨æ—¥ã€orã€Œæœ¬æ—¥ã€
    if display_mode in ('before_open', 'after_close'):
        if now.hour >= 23:
            result_date = now
            date_prefix = 'æœ¬æ—¥'
        elif now.hour < 10:
            result_date = now - timedelta(days=1)
            date_prefix = ''  # æ—¥ä»˜ã ã‘ã§ååˆ†ï¼ˆã€Œæ˜¨æ—¥ã€ã¯å†—é•·ï¼‰
        else:
            result_date = now - timedelta(days=1)
            date_prefix = ''
        result_date_str = format_date_with_weekday(result_date)
    elif is_open:
        date_prefix = 'æœ¬æ—¥'

    # æ¬¡ã®å–¶æ¥­æ—¥ï¼ˆãŠã™ã™ã‚å°ã®å¯¾è±¡æ—¥ï¼‰
    if now.hour >= 22:
        # 22:45ã€œ23:59 â†’ ç¿Œæ—¥
        next_day_dt = now + timedelta(days=1)
        next_day_prefix = 'æ˜æ—¥'
    elif now.hour < 10:
        # 0:00ã€œ9:59 â†’ ä»Šæ—¥
        next_day_dt = now
        next_day_prefix = 'æœ¬æ—¥'
    else:
        # å–¶æ¥­ä¸­ â†’ ä»Šæ—¥
        next_day_dt = now
        next_day_prefix = 'æœ¬æ—¥'
    next_day_str = format_date_with_weekday(next_day_dt)

    # å…¨åº—èˆ—ä¸€è¦§ï¼ˆåº—èˆ—å°ç·šç”¨ï¼‰
    all_stores = []
    for store_key, info in store_day_ratings.items():
        today_rating = info['day_ratings'].get(today_weekday, 3)
        all_stores.append({
            'store_key': store_key,
            'name': info['name'],
            'short_name': info['short_name'],
            'today_rating': today_rating,
            'overall_rating': info['overall_rating'],
            'machine_links': info.get('machine_links', []),
        })
    # ä»Šæ—¥ã®è©•ä¾¡é †ã§ã‚½ãƒ¼ãƒˆ
    all_stores.sort(key=lambda x: (-x['today_rating'], -x['overall_rating']))

    # å…¨åº—èˆ—ãŠã™ã™ã‚ãƒªãƒ³ã‚¯
    recommend_links = []
    for store_key, info in store_day_ratings.items():
        for ml in info.get('machine_links', []):
            link_store_key = ml.get('store_key', store_key)
            _mk = STORES.get(link_store_key, {}).get('machine', 'sbj')
            _machine_display = MACHINES.get(_mk, {}).get('display_name', ml.get('short_name', ''))
            recommend_links.append({
                'store_key': link_store_key,
                'name': info['short_name'],
                'icon': ml.get('icon', ''),
                'machine_name': _machine_display,
            })
    recommend_links.sort(key=lambda x: next(
        (-s['today_rating'] for s in all_stores if any(
            ml.get('store_key') == x['store_key'] for ml in s.get('machine_links', [])
        )), 0
    ))

    # åº—èˆ—ãƒŠãƒ“ï¼ˆåº—åã§é‡è¤‡æ’é™¤ã€æœ€åˆã®æ©Ÿç¨®ãƒªãƒ³ã‚¯ã‚’ä½¿ã†ï¼‰
    seen_stores = set()
    store_nav_links = []
    for info in sorted(store_day_ratings.values(), key=lambda x: -x.get('today_rating', 0)):
        sname = info['short_name']
        if sname in seen_stores:
            continue
        seen_stores.add(sname)
        mls = info.get('machine_links', [])
        if mls:
            store_nav_links.append({
                'name': sname,
                'store_key': mls[0].get('store_key', ''),
                'machine_links': [{'store_key': ml.get('store_key', ''), 'icon': ml.get('icon', ''), 'machine_name': MACHINES.get(STORES.get(ml.get('store_key', ''), {}).get('machine', 'sbj'), {}).get('short_name', '')} for ml in mls],
            })

    night_mode = is_night_mode()
    tomorrow = now + timedelta(days=1)
    tomorrow_str = format_date_with_weekday(tomorrow)
    yesterday = now - timedelta(days=1)
    yesterday_str = format_date_with_weekday(yesterday)

    # ã€Œæœ¬æ—¥ã€ã€Œå‰æ—¥ã€ã‚’æ—¥ä»˜ä»˜ãã«
    # ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ã¯å¸¸ã«ã€Œå‰æ—¥ã€ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡ã«é–¢ä¿‚ãªãï¼‰
    # ä»Šæ—¥ãŒ2/2ãªã‚‰ã€Œ2/1ã®çš„ä¸­ç‡ã€ã€Œ2/1ã®çˆ†ç™ºå°ã€ã¨è¡¨ç¤º
    data_date_str = format_date_with_weekday(yesterday)  # å‰æ—¥
    prev_date_str = format_date_with_weekday(yesterday - timedelta(days=1))  # å‰ã€…æ—¥

    # æ©Ÿç¨®åˆ¥çš„ä¸­ç‡ï¼ˆãƒ’ãƒ¼ãƒ­ãƒ¼è¡¨ç¤ºç”¨: verifyãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ï¼‰
    accuracy_hero = []
    verify_data = _get_latest_valid_verify()
    if verify_data and verify_data.get('units'):
        # store_key â†’ machine_key ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’äº‹å‰ã«æ§‹ç¯‰
        _store_to_machine = {}
        for _mk in MACHINES:
            for _sk in get_stores_by_machine(_mk):
                _store_to_machine[_sk] = _mk

        # æ©Ÿç¨®åˆ¥ã«é›†è¨ˆ
        machine_stats = {}  # {machine_key: {total, hit, stores: {store_key: {total, hit}}}}
        for store_key, units in verify_data['units'].items():
            mk = _store_to_machine.get(store_key)
            if not mk:
                continue
            if mk not in machine_stats:
                machine_stats[mk] = {'total': 0, 'hit': 0, 'stores': {}}
            ms = machine_stats[mk]
            if store_key not in ms['stores']:
                ms['stores'][store_key] = {'total': 0, 'hit': 0}
            ss = ms['stores'][store_key]
            for u in units:
                if u.get('predicted_rank') in ('S', 'A') and u.get('actual_prob', 0) > 0:
                    ms['total'] += 1
                    ss['total'] += 1
                    # çš„ä¸­åˆ¤å®š: verdict_class/result_level/prediction_resultã®é †ã§ç¢ºèª
                    vc = u.get('verdict_class', '')
                    rl = u.get('result_level', '')
                    pr = u.get('prediction_result', '')
                    if vc == 'hit' or pr in ('hit', 'excellent') or rl == 'good':
                        ms['hit'] += 1
                        ss['hit'] += 1
                    elif not vc and not pr and not rl:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ©Ÿç¨®åˆ¥good_probé–¾å€¤ã§åˆ¤å®š
                        _good = get_machine_threshold(mk, 'good_prob') or 130
                        if u.get('actual_prob', 999) <= _good:
                            ms['hit'] += 1
                            ss['hit'] += 1

        for machine_key, machine in MACHINES.items():
            ms = machine_stats.get(machine_key, {'total': 0, 'hit': 0, 'stores': {}})
            rate = (ms['hit'] / ms['total'] * 100) if ms['total'] > 0 else 0

            # åº—èˆ—åˆ¥ã®çµæœ
            store_results = []
            for sk, ss in ms['stores'].items():
                if ss['total'] > 0:
                    s_rate = ss['hit'] / ss['total'] * 100
                    stores_config = get_stores_by_machine(machine_key)
                    store_info = stores_config.get(sk, {})
                    short_name = store_info.get('name', sk).replace('ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“', '').replace('åº—', '')
                    store_results.append({'name': short_name, 'rate': s_rate, 'hit': ss['hit'], 'total': ss['total']})
            store_results.sort(key=lambda x: -x['rate'])
            top_parts = []
            for sr in store_results[:3]:
                if sr['rate'] >= 100:
                    top_parts.append(f"{sr['name']}å…¨çš„ä¸­")
                elif sr['rate'] >= 50:
                    top_parts.append(f"{sr['name']}{sr['hit']}/{sr['total']}")
            top_stores = ' / '.join(top_parts) if top_parts else ''

            accuracy_hero.append({
                'name': machine['short_name'],
                'icon': machine['icon'],
                'rate': rate,
                'hit': ms['hit'],
                'total': ms['total'],
                'top_stores': top_stores,
            })
    # é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
    accuracy_hero.sort(key=lambda x: -x['rate'])

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”¨: S/Aå°ã‚’ã‚¹ã‚³ã‚¢é †ã§æœ€å¤§20å°ï¼ˆTOP3ä»¥å¤–ã‚‚å«ã‚€ï¼‰
    all_sa_recs = []
    seen_sa = set()
    for r in top3:
        key = f"{r.get('store_key')}_{r.get('unit_id')}"
        seen_sa.add(key)
    for r in top3_candidates:
        key = f"{r.get('store_key')}_{r.get('unit_id')}"
        if key not in seen_sa:
            all_sa_recs.append(r)
            seen_sa.add(key)
        if len(all_sa_recs) >= 17:  # TOP3 + 17 = 20å°
            break

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”¨ã®æ©Ÿç¨®ãƒ»åº—èˆ—ãƒªã‚¹ãƒˆ
    filter_machines = []
    filter_machine_keys = set()
    filter_stores_by_name = {}  # è¡¨ç¤ºåã§ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ï¼ˆåŒã˜åº—èˆ—ã®SBJ/åŒ—æ–—ã‚’1ã¤ã«ï¼‰
    for r in top3 + all_sa_recs:
        mk = r.get('machine_key', '')
        mn = r.get('machine_name', '')
        sk = r.get('store_key', '')
        sn = r.get('store_name', '')
        if mk and mk not in filter_machine_keys:
            filter_machines.append({'key': mk, 'name': mn, 'icon': r.get('machine_icon', 'ğŸ°')})
            filter_machine_keys.add(mk)
        if sn and sn not in filter_stores_by_name:
            filter_stores_by_name[sn] = []
        if sn and sk:
            if sk not in [x['key'] for x in filter_stores_by_name.get(sn, [])]:
                filter_stores_by_name[sn].append({'key': sk, 'name': sn})
    filter_stores = [{'name': name, 'store_keys': [x['key'] for x in stores]} for name, stores in filter_stores_by_name.items()]

    # ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚åˆ»ã‚’å–å¾—
    data_fetched_at = ''
    try:
        from scrapers.availability_checker import get_daidata_availability
        avail_data = get_daidata_availability()
        fetched_at_str = avail_data.get('fetched_at', '')
        if fetched_at_str:
            fetched_dt = datetime.fromisoformat(fetched_at_str)
            data_fetched_at = f"{fetched_dt.month}/{fetched_dt.day} {fetched_dt.strftime('%H:%M')}"
    except:
        pass

    html = template.render(
        machines=machines,
        top3=top3,
        all_sa_recs=all_sa_recs,
        filter_stores=filter_stores,
        filter_machines=filter_machines,
        yesterday_top10=yesterday_top10,
        today_top10=today_top10,
        today_weekday=today_weekday,
        today_date=today_date,
        today_date_formatted=today_date_formatted,
        now_time=now.strftime('%H:%M'),
        data_fetched_at=data_fetched_at,
        now_short=now.strftime('%m%d_%H:%M'),
        store_recommendations={},
        today_recommended_stores=today_recommended_stores,
        today_store_ranking=today_store_ranking,
        today_avoid_stores=today_avoid_stores,
        store_day_ratings=store_day_ratings,
        display_mode=display_mode,
        result_date_str=result_date_str,
        is_open=is_open,
        all_stores=all_stores,
        night_mode=night_mode,
        tomorrow_str=tomorrow_str,
        yesterday_str=yesterday_str,
        data_date_str=data_date_str,
        prev_date_str=prev_date_str,
        accuracy_hero=accuracy_hero,
        verify_date_str=_get_verify_date_str(),
        verify_accuracy=_get_verify_accuracy(),
        verify_highlights=_get_verify_highlights(),
        verify_categories=_get_verify_by_category(),
        date_prefix=date_prefix,
        next_day_prefix=next_day_prefix,
        next_day_str=next_day_str,
        recommend_links=recommend_links,
        store_nav_links=store_nav_links,
    )

    output_path = OUTPUT_DIR / 'index.html'
    output_path.write_text(html, encoding='utf-8')
    print(f"  -> {output_path}")


def generate_machine_pages(env):
    """æ©Ÿç¨®åˆ¥åº—èˆ—ä¸€è¦§ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating machine pages...")

    template = env.get_template('stores.html')
    output_subdir = OUTPUT_DIR / 'machine'
    output_subdir.mkdir(parents=True, exist_ok=True)

    for machine_key, machine in MACHINES.items():
        stores = get_stores_by_machine(machine_key)
        store_list = [
            {'key': key, 'name': store['name'], 'unit_count': len(store['units'])}
            for key, store in stores.items()
        ]

        now = datetime.now(JST)
        html = template.render(
            machine=machine,
            machine_key=machine_key,
            stores=store_list,
            now_short=now.strftime('%m%d_%H:%M'),
        )

        output_path = output_subdir / f'{machine_key}.html'
        output_path.write_text(html, encoding='utf-8')
        print(f"  -> {output_path}")


def get_reason_date_labels():
    """ç†ç”±æ–‡ã®æ—¥ä»˜ãƒ©ãƒ™ãƒ«ã‚’å–å¾—ï¼ˆé–‰åº—å¾Œã®ã¿æ—¥ä»˜ã«ç½®æ›ï¼‰"""
    if is_business_hours():
        return None, None
    try:
        from scrapers.availability_checker import get_daidata_availability
        avail_data = get_daidata_availability()
        fetched_at = avail_data.get('fetched_at', '')
        if fetched_at:
            data_dt = datetime.fromisoformat(fetched_at)
            data_label = f"{data_dt.month}/{data_dt.day}({WEEKDAY_NAMES[data_dt.weekday()]})"
            prev_dt = data_dt - timedelta(days=1)
            prev_label = f"{prev_dt.month}/{prev_dt.day}({WEEKDAY_NAMES[prev_dt.weekday()]})"
            return data_label, prev_label
    except:
        pass
    return None, None


def is_night_mode():
    """22:45ä»¥é™ã¯ç¿Œæ—¥äºˆæƒ³ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ"""
    now = datetime.now(JST)
    return now.hour > 22 or (now.hour == 22 and now.minute >= 45)


def get_next_day_prefix():
    """æ¬¡ã®å–¶æ¥­æ—¥ã®è¡¨è¨˜ï¼ˆæœ¬æ—¥/æ˜æ—¥ï¼‰ã‚’è¿”ã™"""
    now = datetime.now(JST)
    if now.hour >= 22 and now.minute >= 45:
        # 22:45ã€œ23:59 â†’ ã€Œæ˜æ—¥ã€
        return 'æ˜æ—¥'
    else:
        # 0:00ã€œ22:44 â†’ ã€Œæœ¬æ—¥ã€
        return 'æœ¬æ—¥'


def generate_ranking_pages(env):
    """æ©Ÿç¨®åˆ¥ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating ranking pages...")

    template = env.get_template('ranking.html')
    output_subdir = OUTPUT_DIR / 'ranking'
    output_subdir.mkdir(parents=True, exist_ok=True)

    night_mode = is_night_mode()
    now = datetime.now(JST)
    tomorrow = now + timedelta(days=1)
    tomorrow_str = format_date_with_weekday(tomorrow)
    yesterday = now - timedelta(days=1)
    data_date_str = format_date_with_weekday(now)
    prev_date_str = format_date_with_weekday(yesterday)
    reason_data_label, reason_prev_label = get_reason_date_labels()

    for machine_key, machine in MACHINES.items():
        stores = get_stores_by_machine(machine_key)
        all_recommendations = []

        for store_key, store in stores.items():
            availability = {}
            try:
                availability = get_availability(store_key)
            except:
                pass

            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚‚å–å¾—ï¼ˆè¨­å®šæ¨æ¸¬ã‚„max_medalsç­‰ã«å¿…è¦ï¼‰
            realtime = None
            try:
                realtime = get_realtime_data(store_key)
            except:
                pass

            recommendations = recommend_units(store_key, realtime_data=realtime, availability=availability,
                                              data_date_label=reason_data_label, prev_date_label=reason_prev_label)
            for rec in recommendations:
                rec['store_name'] = store.get('short_name', store['name'])
                rec['store_key'] = store_key
                # å·®æšè¨ˆç®—ã¯recommend_unitså†…ã§çµ±åˆæ¸ˆã¿
                all_recommendations.append(rec)

        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        def sort_key(r):
            score = r['final_score']
            if r['is_running']:
                score -= 30
            return -score

        all_recommendations.sort(key=sort_key)
        # è“„ç©DBè£œå®Œï¼ˆå…±é€šé–¢æ•°ï¼‰
        from scripts.enrich_rec import enrich_recs as _enrich
        _enrich(all_recommendations)
        top_recs = [r for r in all_recommendations if r['final_rank'] in ('S', 'A') and not r['is_running']][:10]
        other_recs = [r for r in all_recommendations if r not in top_recs][:20]

        next_day_prefix = get_next_day_prefix()
        html = template.render(
            machine=machine,
            machine_key=machine_key,
            top_recs=top_recs,
            other_recs=other_recs,
            total_count=len(all_recommendations),
            night_mode=night_mode,
            next_day_prefix=next_day_prefix,
            tomorrow_str=tomorrow_str,
            data_date_str=data_date_str,
            prev_date_str=prev_date_str,
            now_short=now.strftime('%m%d_%H:%M'),
        )

        output_path = output_subdir / f'{machine_key}.html'
        output_path.write_text(html, encoding='utf-8')
        print(f"  -> {output_path}")


def generate_recommend_pages(env):
    """å„åº—èˆ—ã®æ¨å¥¨ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating recommend pages...")

    template = env.get_template('recommend.html')
    output_subdir = OUTPUT_DIR / 'recommend'
    output_subdir.mkdir(parents=True, exist_ok=True)

    is_open = is_business_hours()
    display_mode = get_display_mode()
    reason_data_label, reason_prev_label = get_reason_date_labels()

    # æ—§å½¢å¼ã‚­ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
    old_keys = {'island_akihabara', 'shibuya_espass', 'shinjuku_espass'}

    for store_key, store in STORES.items():
        if store_key in old_keys:
            continue
        print(f"  Processing {store_key}...")

        machine_key = store.get('machine', 'sbj')
        machine = get_machine_info(machine_key)

        # ç©ºãçŠ¶æ³ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        availability = {}
        realtime_data = None
        cache_info = None

        try:
            availability = get_availability(store_key)
        except:
            pass

        try:
            rt_data = get_realtime_data(store_key)
            if rt_data and rt_data.get('units'):
                realtime_data = rt_data
                fetched_at_str = rt_data.get('fetched_at', '')
                if fetched_at_str:
                    try:
                        fetched_time = datetime.fromisoformat(fetched_at_str.replace('Z', '+00:00'))
                        fetched_time_jst = fetched_time.astimezone(JST)
                        now_jst = datetime.now(JST)
                        cache_info = {
                            'fetched_at': fetched_time_jst.strftime('%H:%M'),
                            'age_seconds': int((now_jst - fetched_time_jst).total_seconds()),
                            'source': rt_data.get('source', 'unknown'),
                        }
                    except:
                        pass
        except:
            pass

        recommendations = recommend_units(store_key, realtime_data, availability,
                                          data_date_label=reason_data_label, prev_date_label=reason_prev_label)

        # å·®æšè¨ˆç®—ã¯recommend_unitså†…ã§çµ±åˆæ¸ˆã¿

        # åˆ†é¡
        sa_recs = [r for r in recommendations if r['final_rank'] in ('S', 'A') and not r['is_running']]
        if sa_recs:
            top_recs = sa_recs
        else:
            top_recs = [r for r in recommendations if not r['is_running']][:3]

        other_recs = [r for r in recommendations if r not in top_recs]

        availability_info = None
        if availability:
            availability_info = {
                'fetched_at': datetime.now(JST).strftime('%H:%M'),
                'empty_count': sum(1 for v in availability.values() if v == 'ç©ºã'),
                'playing_count': sum(1 for v in availability.values() if v == 'éŠæŠ€ä¸­'),
            }

        # åº—èˆ—åˆ†æï¼ˆrecommend_unitsã®è¨ˆç®—çµæœã‹ã‚‰ãƒ©ãƒ³ã‚¯åˆ†å¸ƒã‚’ç”Ÿæˆï¼‰
        daily_data = load_daily_data(machine_key=machine_key)
        store_analysis = generate_store_analysis(store_key, daily_data)

        # ãƒ©ãƒ³ã‚¯åˆ†å¸ƒã‚’recommend_unitsã®çµæœã§ä¸Šæ›¸ãï¼ˆç›¸å¯¾è©•ä¾¡ã®çµæœã‚’æ­£ç¢ºã«åæ˜ ï¼‰
        all_recs_for_analysis = top_recs + other_recs
        if all_recs_for_analysis:
            from collections import Counter
            rank_counts = Counter(r['final_rank'] for r in all_recs_for_analysis)
            rank_parts = []
            for rank in ['S', 'A', 'B', 'C', 'D']:
                count = rank_counts.get(rank, 0)
                if count > 0:
                    rank_parts.append(f"{rank}:{count}å°")
            store_analysis['rank_dist'] = " / ".join(rank_parts)
            high_count = rank_counts.get('S', 0) + rank_counts.get('A', 0)
            total = len(all_recs_for_analysis)
            store_analysis['high_count'] = high_count
            store_analysis['total_units'] = total
            high_ratio = high_count / total * 100 if total > 0 else 0
            if high_ratio >= 70:
                store_analysis['overall'] = f"å¥½èª¿å°ãŒéå¸¸ã«å¤šã„ï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
            elif high_ratio >= 50:
                store_analysis['overall'] = f"å¥½èª¿å°ãŒå¤šã„ï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
            elif high_ratio >= 30:
                store_analysis['overall'] = f"å¥½èª¿å°ã‚ã‚Šï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
            else:
                store_analysis['overall'] = f"å¥½èª¿å°ãŒå°‘ãªã„ï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"

        # è“„ç©DBè£œå®Œï¼ˆå…±é€šé–¢æ•°ï¼‰
        from scripts.enrich_rec import enrich_recs as _enrich_recs
        _enrich_recs(recommendations)

        # å„å°ã®éå»3æ—¥åˆ†ã®å½“ãŸã‚Šå±¥æ­´ã‚’ç­”ãˆåˆã‚ã›å½¢å¼ã«åŠ å·¥
        _rec_mk = _get_machine_key(store_key)
        for rec in recommendations:
            for hist_key in ('yesterday_history', 'day_before_history', 'three_days_ago_history'):
                raw_hist = rec.get(hist_key, [])
                if raw_hist:
                    processed, summary = _process_history_for_verify(raw_hist, machine_key=_rec_mk)
                    rec[f'{hist_key}_processed'] = processed
                    rec[f'{hist_key}_summary'] = summary
                else:
                    rec[f'{hist_key}_processed'] = []
                    rec[f'{hist_key}_summary'] = {}

        # å°ç•ªå·ã‚¢ãƒ©ãƒ¼ãƒˆ
        store_alerts = [a for a in get_active_alerts() if a.get('store_key') == store_key]

        # ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜ãƒ©ãƒ™ãƒ«ï¼ˆè“„ç©DBã®æœ€æ–°æ—¥ä»˜ã‚’å–å¾—ï¼‰
        data_date_str = None
        try:
            from analysis.history_accumulator import load_unit_history
            _units = store.get('units', [])
            if _units:
                _hist = load_unit_history(store_key, str(_units[0]))
                if _hist and _hist.get('days'):
                    _latest = max(d.get('date', '') for d in _hist['days'])
                    if _latest:
                        _dt = datetime.strptime(_latest, '%Y-%m-%d')
                        data_date_str = f"{_dt.month}/{_dt.day}({WEEKDAY_NAMES[_dt.weekday()]})"
        except Exception:
            pass

        now = datetime.now(JST)
        html = template.render(
            store=store,
            store_key=store_key,
            machine=machine,
            machine_key=machine_key,
            top_recs=top_recs,
            other_recs=other_recs,
            updated_at=now.strftime('%H:%M'),
            now_short=now.strftime('%m%d_%H:%M'),
            cache_info=cache_info,
            availability_info=availability_info,
            is_open=is_open,
            display_mode=display_mode,
            store_analysis=store_analysis,
            unit_alerts=store_alerts,
            data_date_str=data_date_str,
        )

        output_path = output_subdir / f'{store_key}.html'
        output_path.write_text(html, encoding='utf-8')

    print(f"  -> {output_subdir}/")


def _get_machine_key(store_key):
    """store_keyã‹ã‚‰æ©Ÿç¨®ã‚­ãƒ¼ã‚’å–å¾—"""
    if not store_key:
        return None
    if store_key.endswith('_sbj') or '_sbj_' in store_key:
        return 'sbj'
    if store_key.endswith('_hokuto') or '_hokuto_' in store_key:
        return 'hokuto_tensei2'
    if 'sbj' in store_key:
        return 'sbj'
    if 'hokuto' in store_key:
        return 'hokuto_tensei2'
    return None


def _process_history_for_verify(history, machine_key=None):
    """å½“ãŸã‚Šå±¥æ­´ã‚’ç­”ãˆåˆã‚ã›è¡¨ç¤ºç”¨ã«åŠ å·¥ã™ã‚‹

    - æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
    - ãƒã‚§ãƒ¼ãƒ³ï¼ˆé€£ãƒãƒ£ãƒ³ï¼‰ã‚’è¨ˆç®—
    - æ·±ã„ãƒãƒã‚Šãƒ»æµ…ã„å½“ãŸã‚Šã®ãƒ•ãƒ©ã‚°ã‚’ä»˜ä¸
    - å¤©äº•åˆ¤å®šã¯æ©Ÿç¨®åˆ¥ï¼ˆconfig/rankings.pyã®normal_ceilingã‚’å‚ç…§ï¼‰
    
    Args:
        history: å½“ãŸã‚Šå±¥æ­´ãƒªã‚¹ãƒˆ
        machine_key: æ©Ÿç¨®ã‚­ãƒ¼ï¼ˆ'sbj', 'hokuto_tensei2'ç­‰ï¼‰ã€‚å¤©äº•é–¾å€¤ã®æ±ºå®šã«ä½¿ç”¨
    """
    from analysis.analyzer import is_big_hit, RENCHAIN_THRESHOLD
    from config.rankings import MACHINES, MACHINE_DEFAULTS, get_machine_threshold

    if not history:
        return [], {}

    # é€£ãƒãƒ£ãƒ³é–¾å€¤: æ©Ÿç¨®åˆ¥ã«config/rankings.pyã‹ã‚‰å–å¾—
    renchain_th = get_machine_threshold(machine_key, 'renchain_threshold') if machine_key else RENCHAIN_THRESHOLD
    if not renchain_th:
        renchain_th = RENCHAIN_THRESHOLD

    # ãƒã‚§ãƒ¼ãƒ³è¨ˆç®—ã¯æ™‚é–“æ˜‡é †ã§è¡Œã†ï¼ˆé€£ãƒãƒ£ãƒ³åˆ¤å®šã®ãŸã‚ï¼‰
    sorted_hist = sorted(history, key=lambda x: x.get('time', '00:00'))

    # ãƒã‚§ãƒ¼ãƒ³è¨ˆç®—: ATé–“ã®Gæ•°ã‚’è“„ç©ã—ã€é–¾å€¤ä»¥ä¸‹ãªã‚‰é€£ãƒãƒ£ãƒ³
    processed = []
    chain_id = 0
    chain_hits = []  # ç¾åœ¨ã®ãƒã‚§ãƒ¼ãƒ³å†…ã®ãƒ’ãƒƒãƒˆ
    accumulated_games = 0  # RBã‚’è·¨ã„ã ATé–“Gæ•°

    for i, hit in enumerate(sorted_hist):
        start = hit.get('start', 0)
        hit_type = hit.get('type', 'ART')
        medals = hit.get('medals', 0)
        time_str = hit.get('time', '')

        accumulated_games += start

        # å¤©äº•åˆ¤å®š: æ©Ÿç¨®åˆ¥ã«config/rankings.pyã®normal_ceilingã‚’å‚ç…§
        # SBJ: 999G+Î±ï¼ˆRBã§ã¯ãƒªã‚»ãƒƒãƒˆã•ã‚Œãªã„ã€‚è¡¨ç¤ºGæ•°ã¨å†…éƒ¨Gæ•°ã«ã‚ºãƒ¬ã‚ã‚Šï¼‰
        # åŒ—æ–—: ã‚ã¹ã—ã‚·ã‚¹ãƒ†ãƒ ï¼ˆGæ•°ãƒ™ãƒ¼ã‚¹ã®å¤©äº•åˆ¤å®šã¯å‚è€ƒå€¤ã€‚normal_ceiling=1100ï¼‰
        from config.rankings import MACHINES, MACHINE_DEFAULTS
        machine_config = MACHINES.get(machine_key, MACHINE_DEFAULTS) if machine_key else MACHINE_DEFAULTS
        TENJOU_THRESHOLD = machine_config.get('normal_ceiling', 999)
        entry = {
            'index': i + 1,
            'time': time_str,
            'start': start,
            'type': hit_type,
            'medals': medals,
            'is_deep': accumulated_games >= 500 if not is_big_hit(hit_type) else start >= 500,
            'is_shallow': start <= 10 and i > 0,
            'is_tenjou': accumulated_games >= TENJOU_THRESHOLD if is_big_hit(hit_type) else False,
            'accumulated_games': accumulated_games,  # RBã‚’è·¨ã„ã ç´¯è¨ˆGæ•°
        }

        if is_big_hit(hit_type):
            if i == 0 or accumulated_games > renchain_th:
                # æ–°ã—ã„ãƒã‚§ãƒ¼ãƒ³é–‹å§‹
                if chain_hits:
                    chain_len = len(chain_hits)
                    for ch in chain_hits:
                        ch['chain_len'] = chain_len
                chain_id += 1
                chain_hits = [entry]
            else:
                # é€£ãƒãƒ£ãƒ³ç¶™ç¶š
                chain_hits.append(entry)

            entry['chain_id'] = chain_id
            entry['is_hot_chain'] = False  # å¾Œã§æ›´æ–°
            accumulated_games = 0  # ATé–“ãƒªã‚»ãƒƒãƒˆ
        else:
            # RB: ãƒã‚§ãƒ¼ãƒ³ã«å«ã‚ãªã„ï¼ˆATé–“ã¯ç¶™ç¶šï¼‰
            entry['chain_id'] = 0
            entry['chain_len'] = 0
            entry['is_hot_chain'] = False

        processed.append(entry)

    # æœ€å¾Œã®ãƒã‚§ãƒ¼ãƒ³ã‚’å‡¦ç†
    if chain_hits:
        chain_len = len(chain_hits)
        for idx, ch in enumerate(chain_hits):
            ch['chain_len'] = chain_len
            ch['chain_pos'] = idx + 1  # 1é€£ç›®, 2é€£ç›®, ...

    # å…¨ã¦ã®ãƒã‚§ãƒ¼ãƒ³ã«chain_posã‚’ä»˜ä¸ï¼ˆæœ€å¾Œã®ãƒã‚§ãƒ¼ãƒ³ä»¥å¤–ã¯æ—¢ã«ãƒ«ãƒ¼ãƒ—å†…ã§å‡¦ç†æ¸ˆã¿ï¼‰
    # â†’ ä¸Šã®ãƒ«ãƒ¼ãƒ—å†…ã§å‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ä¿®æ­£:
    # chain_hitsã®å‡¦ç†ã‚’å†èµ°æŸ»ã—ã¦å…¨ãƒã‚§ãƒ¼ãƒ³ã«chain_posã‚’ä»˜ä¸
    current_chain_id = 0
    pos = 0
    for entry in processed:
        cid = entry.get('chain_id', 0)
        if cid > 0:
            if cid != current_chain_id:
                current_chain_id = cid
                pos = 1
            else:
                pos += 1
            entry['chain_pos'] = pos
        else:
            entry['chain_pos'] = 0

    # ãƒ›ãƒƒãƒˆãƒã‚§ãƒ¼ãƒ³(5é€£ä»¥ä¸Š)ã«ãƒ•ãƒ©ã‚°ä»˜ä¸
    for entry in processed:
        if entry.get('chain_len', 0) >= 5:
            entry['is_hot_chain'] = True

    # ã‚µãƒãƒªãƒ¼è¨ˆç®—
    starts = [h.get('start', 0) for h in sorted_hist]
    big_hit_starts = []
    acc = 0
    for hit in sorted_hist:
        acc += hit.get('start', 0)
        if is_big_hit(hit.get('type', '')):
            big_hit_starts.append(acc)
            acc = 0

    total_games = sum(starts)
    total_hits = len(sorted_hist)
    total_medals = sum(h.get('medals', 0) for h in sorted_hist)

    # ATé–“ãƒ™ãƒ¼ã‚¹ã®è°·
    valleys = big_hit_starts if big_hit_starts else starts
    max_valley = max(valleys) if valleys else 0
    avg_valley = int(sum(valleys) / len(valleys)) if valleys else 0
    tenjou_count = sum(1 for v in valleys if v >= TENJOU_THRESHOLD)

    # æœ€å¤§ãƒã‚§ãƒ¼ãƒ³
    chain_lengths = [e.get('chain_len', 0) for e in processed if e.get('chain_id', 0) > 0]
    # å„ãƒã‚§ãƒ¼ãƒ³ã®é•·ã•ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«å–å¾—
    seen_chains = {}
    for e in processed:
        cid = e.get('chain_id', 0)
        clen = e.get('chain_len', 0)
        if cid > 0 and cid not in seen_chains:
            seen_chains[cid] = clen
    max_chain = max(seen_chains.values()) if seen_chains else 0

    summary = {
        'total_games': total_games,
        'total_hits': total_hits,
        'total_medals': total_medals,
        'max_valley': max_valley,
        'avg_valley': avg_valley,
        'tenjou_count': tenjou_count,
        'max_chain': max_chain,
    }

    # è¡¨ç¤ºç”¨ã«é™é †ï¼ˆæœ€æ–°ãŒä¸Šï¼‰ã«ä¸¦ã³æ›¿ãˆ + indexã‚’æŒ¯ã‚Šç›´ã™
    processed.reverse()
    for i, entry in enumerate(processed):
        entry['index'] = i + 1

    return processed, summary


def _try_load_backtest_results():
    """æœ‰åŠ¹ãªå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹æœ€æ–°ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’èª­ã¿è¾¼ã‚€ï¼ˆå½“æ—¥ã¯æœªç¢ºå®šãªã®ã§ã‚¹ã‚­ãƒƒãƒ—ï¼‰"""
    import glob
    from datetime import datetime
    today_str = datetime.now().strftime('%Y%m%d')
    results_files = sorted(glob.glob(str(PROJECT_ROOT / 'data' / 'verify' / 'verify_*_results.json')), reverse=True)
    for f in results_files:
        if today_str in Path(f).name:
            continue
        try:
            data = json.loads(Path(f).read_text())
            # S/Aäºˆæ¸¬å°ã®ã†ã¡actual_prob>0ãŒ1å°ã§ã‚‚ã‚ã‚Œã°æœ‰åŠ¹
            has_valid = False
            for sk, units in data.get('units', {}).items():
                for u in units:
                    if u.get('predicted_rank') in ('S', 'A') and u.get('actual_prob', 0) > 0:
                        has_valid = True
                        break
                if has_valid:
                    break
            if has_valid:
                print(f"  ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’ä½¿ç”¨: {Path(f).name}")
                return data
        except:
            pass
    return None


def _get_latest_valid_verify():
    """æœ‰åŠ¹ãªå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹verifyãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™ï¼ˆnodataã®ã¿ãƒ»å½“æ—¥ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰"""
    from datetime import datetime
    today_str = datetime.now().strftime('%Y%m%d')
    files = sorted(glob.glob('data/verify/verify_*_results.json'), reverse=True)
    for f in files:
        # å½“æ—¥ã®verifyã¯æœªç¢ºå®šãªã®ã§ã‚¹ã‚­ãƒƒãƒ—
        fname = Path(f).name
        if today_str in fname:
            continue
        try:
            data = json.load(open(f))
            # S/Aäºˆæ¸¬å°ã®ã†ã¡actual_prob>0ãŒ1å°ã§ã‚‚ã‚ã‚Œã°æœ‰åŠ¹
            has_data = False
            for sk, units in data.get('units', {}).items():
                for u in units:
                    if u.get('predicted_rank') in ('S', 'A') and u.get('actual_prob', 0) > 0:
                        has_data = True
                        break
                if has_data:
                    break
            if has_data:
                return data
        except:
            pass
    return None


def _get_verify_date_str():
    """çš„ä¸­ç‡ã®æ—¥ä»˜ã‚’å–å¾—ï¼ˆå¸¸ã«å‰æ—¥ã‚’è¡¨ç¤ºï¼‰"""
    # ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡ã«é–¢ä¿‚ãªãã€å¸¸ã«ã€Œå‰æ—¥ã€ã‚’è¡¨ç¤º
    yesterday = datetime.now() - timedelta(days=1)
    weekdays = ['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥']
    return f'{yesterday.month}/{yesterday.day}({weekdays[yesterday.weekday()]})'

def _get_verify_accuracy():
    """verifyãƒšãƒ¼ã‚¸ã¨å®Œå…¨ã«åŒã˜çš„ä¸­ç‡ã‚’è¿”ã™ï¼ˆverifyçµæœJSONã‹ã‚‰ç›´æ¥èª­ã‚€ï¼‰"""
    data = _get_latest_valid_verify()
    if not data:
        return 0
    try:
        # generate_verify.pyã§è¨ˆç®—æ¸ˆã¿ã®overall_rateã‚’ä½¿ã†
        rate = data.get('overall_rate', 0)
        if rate > 0:
            return int(rate)
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: verifyãƒšãƒ¼ã‚¸ç”Ÿæˆæ™‚ã¨åŒã˜è¨ˆç®—
        # nodataé™¤å¤– + games>=500 ãƒ•ã‚£ãƒ«ã‚¿
        total_sa = 0
        total_hit = 0
        for sk, units in data.get('units', {}).items():
            for u in units:
                prob = u.get('actual_prob', 0)
                games = u.get('actual_games', 0)
                if prob <= 0 or games < 500:
                    continue
                if u.get('predicted_rank') in ('S', 'A'):
                    total_sa += 1
                    if u.get('verdict_class') in ('perfect', 'hit'):
                        total_hit += 1
        if total_sa > 0:
            return int(total_hit / total_sa * 100)
    except:
        pass
    return 0


def _get_verify_by_category():
    """åº—èˆ—Ã—æ©Ÿç¨®åˆ¥ã®çš„ä¸­ç‡ã‚’è¿”ã™ï¼ˆãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸è¡¨ç¤ºç”¨ã€ä¸Šä½2ä»¶ï¼‰"""
    data = _get_latest_valid_verify()
    if not data:
        return []
    try:
        by_store = {}
        for sk, units in data.get('units', {}).items():
            mk = data['stores'][sk].get('machine_key', 'sbj')
            sn = data['stores'][sk].get('name', sk)
            mk_short = 'SBJ' if mk == 'sbj' else 'åŒ—æ–—è»¢ç”Ÿ2'
            mk_icon = 'ğŸ°' if mk == 'sbj' else 'âš”ï¸'
            key = f"{sn}|{mk_short}"
            if key not in by_store:
                by_store[key] = {'sa': 0, 'hit': 0, 'icon': mk_icon, 'store': sn, 'mk': mk_short}
            for u in units:
                prob = u.get('actual_prob', 0)
                games = u.get('actual_games', 0)
                if prob <= 0 or games < 500:
                    continue
                if u.get('predicted_rank') in ('S', 'A'):
                    by_store[key]['sa'] += 1
                    if u.get('verdict_class') in ('perfect', 'hit'):
                        by_store[key]['hit'] += 1
        
        # S/Aå°ãŒ2å°ä»¥ä¸Šã‚ã‚‹åº—ã‹ã‚‰çš„ä¸­ç‡ã®é«˜ã„é †ã«2ã¤ï¼ˆåŒç‡ã¯å°æ•°å¤šã„æ–¹å„ªå…ˆï¼‰
        candidates = [d for d in by_store.values() if d['sa'] >= 2]
        candidates.sort(key=lambda x: (-x['hit'] / x['sa'], -x['sa']))
        
        result = []
        for d in candidates[:2]:
            rate = int(d['hit'] / d['sa'] * 100)
            result.append({
                'mk_name': f"{d['icon']}{d['mk']}",
                'store_name': d['store'],
                'rate': rate,
                'hit': d['hit'],
                'total': d['sa'],
            })
        return result
    except:
        return []


def _get_verify_highlights():
    """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‹ã‚‰ç‰¹ç­†äº‹é …ã‚’å–å¾—ï¼ˆæœ€å¤§2ä»¶ï¼‰"""
    highlights = []
    data = _get_latest_valid_verify()
    if not data:
        return highlights
    try:
        
        # å¤§çš„ä¸­ï¼ˆS/Aäºˆæ¸¬ Ã— ç¢ºç‡1/100ä»¥ä¸‹ Ã— å·®æš+3000ä»¥ä¸Šï¼‰ã‚’æ¢ã™
        big_hits = []
        normal_hits = []
        for sk, units in data.get('units', {}).items():
            for u in units:
                rank = u.get('predicted_rank', 'C')
                prob = u.get('actual_prob', 999)
                diff = u.get('diff_medals', 0)
                if rank in ('S', 'A') and u.get('verdict_class') in ('perfect', 'hit'):
                    if prob <= 100 and diff >= 3000:
                        big_hits.append({
                            'unit_id': u.get('unit_id'),
                            'prob': prob,
                            'diff': diff,
                            'store': sk
                        })
                    elif diff >= 5000:
                        normal_hits.append({
                            'unit_id': u.get('unit_id'),
                            'diff': diff,
                            'store': sk
                        })
        
        # å¤§çš„ä¸­ãŒã‚ã‚Œã°æœ€å„ªå…ˆ
        if big_hits:
            best = max(big_hits, key=lambda x: x['diff'])
            highlights.append(f"ğŸ¯ å¤§çš„ä¸­ï¼å·®æš+{best['diff']:,}æš")
        
        # çš„ä¸­å°æ•°
        total_hit = sum(1 for sk, units in data.get('units', {}).items() 
                       for u in units 
                       if u.get('predicted_rank') in ('S', 'A') and u.get('verdict_class') in ('perfect', 'hit'))
        if total_hit > 0:
            highlights.append(f"ğŸ“Š ãŠã™ã™ã‚å° {total_hit}å°ãŒçš„ä¸­")
        
        # å…¨åº—èˆ—çš„ä¸­ãªã©ãŒã‚ã‚Œã°è¿½åŠ 
        if not highlights and normal_hits:
            best = max(normal_hits, key=lambda x: x['diff'])
            highlights.append(f"âœ¨ å·®æš+{best['diff']:,}æšã®å°ã‚’äºˆæ¸¬")
            
    except Exception as e:
        pass
    
    return highlights[:2]  # æœ€å¤§2ä»¶


def _is_unit_hit(u):
    """äºˆæƒ³ã¨çµæœãŒä¸€è‡´=çš„ä¸­ï¼ˆverdict.pyãƒ™ãƒ¼ã‚¹ï¼‰"""
    # verdict_class ãŒæ—¢ã«è¨ˆç®—æ¸ˆã¿ã®å ´åˆã¯ãã‚Œã‚’ä½¿ã†
    vc = u.get('verdict_class')
    if vc:
        return vc in ('perfect', 'hit')
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: result_levelã‹ã‚‰åˆ¤å®š
    rank = u.get('pre_open_rank', u.get('predicted_rank', 'C'))
    rl = u.get('result_level', 'nodata')
    return v_is_hit(rank, rl)


def _generate_verify_from_backtest(env, results):
    """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‹ã‚‰verifyãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    from analysis.feedback import analyze_prediction_errors
    
    STORE_TO_MACHINE = {}
    for sk, sv in STORES.items():
        STORE_TO_MACHINE[sk] = sv.get('machine', sv.get('machine_key', 'sbj'))
    
    # availability.jsonã‹ã‚‰diff_medals/max_medalsã‚’å–å¾—
    # availability.jsonã¯å½“æ—¥æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ï¼ˆhistoryã‹ã‚‰diffæ¨å®šå¯èƒ½ï¼‰
    avail_lookup = {}
    try:
        from analysis.diff_medals_estimator import estimate_diff_medals
        avail_data = json.load(open(str(PROJECT_ROOT / 'data' / 'availability.json')))
        for sk, sdata in avail_data.get('stores', {}).items():
            mk = STORE_TO_MACHINE.get(sk, 'sbj')
            for u in sdata.get('units', []):
                uid = str(u.get('unit_id', ''))
                hist = u.get('today_history', [])
                medals_total = sum(h.get('medals', 0) for h in hist)
                games = u.get('total_start', 0)
                max_medals = u.get('max_medals', 0)
                diff = estimate_diff_medals(medals_total, games, mk) if games > 0 else 0
                info = {'max_medals': max_medals, 'diff_medals': diff}
                avail_lookup[(sk, uid)] = info
                # ã‚¨ã‚¤ãƒªã‚¢ã‚¹: akihabaraâ†”akiba ã®å·®ç•°å¯¾å¿œ
                if 'akihabara' in sk:
                    avail_lookup[(sk.replace('akihabara', 'akiba'), uid)] = info
                elif 'akiba' in sk:
                    avail_lookup[(sk.replace('akiba', 'akihabara'), uid)] = info
    except Exception as e:
        print(f"  âš  availability.jsonèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    machine_groups = {}
    for store_key, store_data in results.get('stores', {}).items():
        mk = STORE_TO_MACHINE.get(store_key, 'sbj')
        if mk not in machine_groups:
            machine_groups[mk] = {'stores': []}
        
        units = results.get('units', {}).get(store_key, [])
        formatted_units = []
        for u in sorted(units, key=lambda x: -x.get('predicted_score', 0)):
            rank = u.get('predicted_rank', 'C')
            prob = u.get('actual_prob', 0)
            games = u.get('actual_games', 0)
            
            uid = str(u.get('unit_id', ''))
            avail_info = avail_lookup.get((store_key, uid), {})
            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆï¼ˆavailability.jsonã¯å½“æ—¥ãƒ‡ãƒ¼ã‚¿ãªã®ã§æ··åœ¨ã•ã›ãªã„ï¼‰
            max_medals = u.get('max_medals', 0)
            diff_medals = u.get('diff_medals', 0)
            # è“„ç©DBã‹ã‚‰å·®æšãƒ»æœ€å¤§æšæ•°ã‚’è£œå®Œ
            if max_medals == 0 or diff_medals == 0:
                try:
                    from analysis.history_accumulator import load_unit_history
                    _hd = load_unit_history(store_key, uid)
                    if _hd:
                        pred_date = results.get('prediction_date', '')
                        if pred_date:
                            from datetime import datetime as _dt2, timedelta as _td2
                            _adate = (_dt2.strptime(pred_date, '%Y-%m-%d') + _td2(days=1)).strftime('%Y-%m-%d')
                            for _dd in _hd.get('days', []):
                                if _dd.get('date') == _adate:
                                    if max_medals == 0:
                                        max_medals = _dd.get('max_medals', 0)
                                    if diff_medals == 0:
                                        diff_medals = _dd.get('diff_medals', 0)
                                    break
                except:
                    pass
            
            # verdict.pyå…±é€šãƒ­ã‚¸ãƒƒã‚¯ã§åˆ¤å®š
            if games < 500 or prob <= 0:
                result_level = 'nodata'
                result_mark, result_mark_class = '-', 'nodata'
                verdict_text, verdict_class = 'â€”', 'nodata'
            else:
                result_level = get_result_level(prob, diff_medals, mk, max_medals=max_medals)
                result_mark, result_mark_class = RESULT_MARKS.get(result_level, ('-', 'nodata'))
                verdict_text, verdict_class = get_verdict(rank, result_level)
            
            # è“„ç©DBã‹ã‚‰å½“ãŸã‚Šå±¥æ­´ã‚’å–å¾—
            raw_hist = []
            try:
                from analysis.history_accumulator import load_unit_history
                hist_data = load_unit_history(store_key, uid)
                if hist_data and hist_data.get('days'):
                    # actual_date = prediction_date + 1æ—¥
                    pred_date = results.get('prediction_date', '')
                    if pred_date:
                        from datetime import datetime as _dt, timedelta as _td
                        actual_date = (_dt.strptime(pred_date, '%Y-%m-%d') + _td(days=1)).strftime('%Y-%m-%d')
                    else:
                        actual_date = results.get('actual_date', '')
                    for d in hist_data['days']:
                        if d.get('date') == actual_date:
                            raw_hist = d.get('history', [])
                            break
            except:
                pass
            processed_history, history_summary = _process_history_for_verify(raw_hist, machine_key=_get_machine_key(store_key))
            
            formatted_units.append({
                'unit_id': u.get('unit_id', ''),
                'pre_open_rank': rank,
                'pre_open_score': u.get('predicted_score', 50),
                'predicted_rank': rank,
                'predicted_score': u.get('predicted_score', 50),
                'actual_art': u.get('actual_art', 0),
                'actual_prob': prob,
                'actual_games': games,
                'max_medals': max_medals,
                'diff_medals': diff_medals,
                'result_level': result_level,
                'result_mark': result_mark,
                'result_mark_class': result_mark_class,
                'verdict_text': verdict_text,
                'verdict_class': verdict_class,
                'history': processed_history,
                'history_summary': history_summary,
            })
        
        # S/Aäºˆæ¸¬å°ãƒ™ãƒ¼ã‚¹ã®çš„ä¸­ç‡
        valid_units = [u for u in formatted_units if u['verdict_class'] != 'nodata']
        sa_valid = [u for u in valid_units if u['predicted_rank'] in ('S', 'A')]
        sa_hit = sum(1 for u in sa_valid if _is_unit_hit(u))
        
        machine_groups[mk]['stores'].append({
            'name': store_data.get('name', store_key),
            'units': formatted_units,
            'sa_total': len(sa_valid),
            'sa_hit': sa_hit,
            'sa_rate': (sa_hit / len(sa_valid) * 100) if sa_valid else 0,
        })
    
    verify_data = {}
    for mk, mg in machine_groups.items():
        m = MACHINES.get(mk, {})
        verify_data[mk] = {
            'name': m.get('short_name', mk),
            'icon': m.get('icon', 'ğŸ°'),
            'stores': mg['stores'],
        }
    
    # nodataå°ã‚’é™¤å¤–ã—ãŸæ­£ç¢ºãªçš„ä¸­ç‡ã‚’å†è¨ˆç®—
    total_sa = sum(s['sa_total'] for mg in machine_groups.values() for s in mg['stores'])
    total_hit = sum(s['sa_hit'] for mg in machine_groups.values() for s in mg['stores'])
    total_surprise = sum(
        sum(1 for u in s['units'] if u['verdict_class'] == 'surprise')
        for mg in machine_groups.values() for s in mg['stores']
    )
    accuracy = (total_hit / total_sa * 100) if total_sa > 0 else 0
    
    machine_accuracy = []
    for mk, md in verify_data.items():
        m_predicted = sum(s['sa_total'] for s in md['stores'])
        m_actual = sum(s['sa_hit'] for s in md['stores'])
        m_surprise = sum(sum(1 for u in s['units'] if u['verdict_class'] == 'surprise') for s in md['stores'])
        m_all = sum(len(s['units']) for s in md['stores'])
        m_rate = (m_actual / m_predicted * 100) if m_predicted > 0 else 0
        machine_accuracy.append({
            'name': md['name'], 'icon': md['icon'],
            'total': m_predicted, 'hit': m_actual,
            'surprise': m_surprise, 'all_units': m_all,
            'total_good': m_actual + m_surprise, 'rate': m_rate,
        })
    
    # åº—Ã—æ©Ÿç¨®åˆ¥ã®çš„ä¸­ç‡ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆæœ€ä¸Šéƒ¨ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºç”¨ï¼‰
    store_accuracy_header = []
    for mk, md in verify_data.items():
        for si, sd in enumerate(md['stores']):
            _units = sd.get('units', [])
            _valid = [u for u in _units if u.get('actual_prob', 0) > 0 and u.get('actual_games', 0) >= 500]
            _sa = [u for u in _valid if u.get('predicted_rank') in ('S', 'A')]
            if len(_sa) >= 2:
                _hit = sum(1 for u in _sa if u.get('verdict_class') in ('perfect', 'hit'))
                _rate = int(_hit / len(_sa) * 100)
                store_accuracy_header.append({
                    'rate': _rate,
                    'machine_name': md['name'],
                    'store_name': sd.get('store_name', sd.get('name', '')),
                    'hit': _hit,
                    'total': len(_sa),
                })
    store_accuracy_header.sort(key=lambda x: (-x['rate'], -x['total']))
    # è‰¯ã„çµæœã®ã¿è¡¨ç¤ºï¼ˆ80%ä»¥ä¸Šï¼‰
    store_accuracy_header = [s for s in store_accuracy_header if s['rate'] >= 80]

    perfect_stores = []
    for mk, md in verify_data.items():
        for si, sd in enumerate(md['stores']):
            units = sd.get('units', [])
            valid_units = [u for u in units if u.get('actual_prob', 0) > 0 and u.get('actual_games', 0) >= 500]
            if not valid_units:
                continue
            hit_count = sum(1 for u in valid_units if _is_unit_hit(u))
            total = len(valid_units)
            rate = hit_count / total * 100 if total > 0 else 0
            store_id = f"store-{mk}-{si}"
            if rate >= 80 and total >= 3:
                perfect_stores.append({
                    'store_name': sd.get('store_name', sd.get('name', '')),
                    'machine_name': md['name'],
                    'machine_icon': md['icon'],
                    'hit_count': hit_count,
                    'total_units': total,
                    'rate': rate,
                    'store_id': store_id,
                })
    # çš„ä¸­ç‡é™é †â†’å°æ•°é †ã€æœ€å¤§5ä»¶
    perfect_stores.sort(key=lambda x: (-x['rate'], -x['total_units']))
    perfect_stores = perfect_stores[:5]

    # ãƒˆãƒ”ãƒƒã‚¯è‡ªå‹•ç”Ÿæˆ
    topics = []
    for mk, md in verify_data.items():
        machine_name = md['name']
        for sd in md['stores']:
            store_name = sd.get('store_name', sd.get('name', ''))
            units = sd.get('units', [])
            valid = [u for u in units if u.get('actual_prob', 0) > 0 and u.get('actual_games', 0) >= 500]
            if not valid:
                continue
            
            def _unit_stats(u):
                parts = []
                art = u.get('actual_art', 0)
                if art > 0:
                    parts.append(f'<span class="td-art">ART {art}å›</span>')
                prob = u.get('actual_prob', 0)
                if prob > 0:
                    parts.append(f'<span class="td-prob">1/{prob:.0f}</span>')
                diff = u.get('diff_medals', 0)
                if diff:
                    cls = 'plus' if diff > 0 else 'minus'
                    parts.append(f'<span class="td-diff {cls}">å·®æš{diff:+,}</span>')
                mx = u.get('max_medals', 0)
                if mx > 0:
                    parts.append(f'<span class="td-max">æœ€å¤§{mx:,}æš</span>')
                return ' / '.join(parts)
            
            sa_units = [u for u in valid if u.get('pre_open_rank', u.get('predicted_rank', 'C')) in ('S', 'A')]
            
            # 1. å¤§çš„ä¸­ï¼ˆS/Aäºˆæ¸¬ Ã— ç¢ºç‡1/100ä»¥ä¸‹ Ã— å·®æš+3,000ä»¥ä¸Šï¼‰
            for u in sa_units:
                diff = u.get('diff_medals', 0)
                mx = u.get('max_medals', 0)
                if u.get('actual_prob', 999) <= 100 and diff >= 3000:
                    topics.append({
                        'icon': 'ğŸ’¥',
                        'type': 'explosion',
                        'machine': machine_name,
                        'title': f'å¤§çš„ä¸­ï¼{store_name} {u["unit_id"]}ç•ª',
                        'detail': _unit_stats(u),
                        'sort_diff': diff,
                        'sort_max': mx,
                    })
            
            # 2. çš„ä¸­ï¼ˆS/Aäºˆæ¸¬ Ã— å·®æš+5,000ä»¥ä¸Šï¼‰â€” å¤§çš„ä¸­ã¨é‡è¤‡ã—ãªã„å°
            explosion_ids = {u.get('unit_id') for u in sa_units if u.get('actual_prob', 999) <= 100 and u.get('diff_medals', 0) >= 3000}
            for u in sa_units:
                diff = u.get('diff_medals', 0)
                mx = u.get('max_medals', 0)
                uid = u.get('unit_id')
                if diff >= 5000 and uid not in explosion_ids:
                    topics.append({
                        'icon': 'ğŸ¯',
                        'type': 'hit',
                        'machine': machine_name,
                        'title': f'çš„ä¸­ï¼{store_name} {u["unit_id"]}ç•ª',
                        'detail': _unit_stats(u),
                        'sort_diff': diff,
                        'sort_max': mx,
                    })
    
    # å·®æšé † â†’ æœ€å¤§æšæ•°é †ã§ã‚½ãƒ¼ãƒˆã€æœ€å¤§10ä»¶
    topics.sort(key=lambda x: (-x.get('sort_diff', 0), -x.get('sort_max', 0)))
    topics = topics[:10]
    
    # æ—¥ä»˜æƒ…å ±ï¼ˆèª­ã¿ã‚„ã™ã„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
    weekdays = ['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥']
    def _fmt_date(date_str):
        try:
            dt = datetime.strptime(date_str, '%Y-%m-%d')
            return f'{dt.month}/{dt.day}({weekdays[dt.weekday()]})'
        except:
            return date_str
    
    actual_date = results.get('date', '')        # å®Ÿç¸¾æ—¥ï¼ˆ1/28ï¼‰
    pred_base_date = results.get('prediction_date', '')  # äºˆæ¸¬ã«ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿ã®æœ€æ–°æ—¥ï¼ˆ1/27ï¼‰
    generated_at = results.get('generated_at', '')
    
    # äºˆæ¸¬ã®èª¬æ˜: ã€Œ1/27ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã€
    predict_time_info = f'{_fmt_date(pred_base_date)}ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬'
    
    # å…¨å°æ•°è¨ˆç®—
    _total_all_units = sum(len(s['units']) for mg in machine_groups.values() for s in mg['stores'])
    _total_good_all = total_hit + total_surprise

    template = env.get_template('verify.html')
    now = datetime.now(JST)
    html = template.render(
        verify_data=verify_data,
        accuracy=accuracy,
        predicted_good=total_sa,
        actual_good=total_hit,
        surprise_good=total_surprise,
        total_all_units=_total_all_units,
        total_good_all=_total_good_all,
        machine_accuracy=machine_accuracy,
        topics=topics,
        perfect_stores=perfect_stores,
        store_accuracy_header=store_accuracy_header,
        version=f'backtest_{actual_date}',
        result_date_str=f'{_fmt_date(actual_date)}ã®å®Ÿç¸¾',
        predict_base=predict_time_info,
        now_short=now.strftime('%m%d_%H:%M'),
    )
    
    output_path = OUTPUT_DIR / 'verify.html'
    output_path.write_text(html, encoding='utf-8')
    print(f"  -> {output_path} (ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ: çš„ä¸­ç‡{accuracy:.0f}%)")


def generate_verify_page(env):
    """ç­”ãˆåˆã‚ã›ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ - äºˆæ¸¬ vs å®Ÿç¸¾ã®æ¯”è¼ƒ
    
    ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ(data/verify/verify_*_results.json)ãŒã‚ã‚Œã°
    æœ€æ–°ã®ã‚‚ã®ã‚’ä½¿ã£ã¦ç”Ÿæˆã™ã‚‹ã€‚ãªã‘ã‚Œã°é€šå¸¸ã®äºˆæ¸¬vså‰æ—¥å®Ÿç¸¾ã§ç”Ÿæˆã€‚
    """
    print("Generating verify page...")
    
    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãŒã‚ã‚Œã°ãã¡ã‚‰ã‚’ä½¿ã†
    backtest_result = _try_load_backtest_results()
    if backtest_result:
        _generate_verify_from_backtest(env, backtest_result)
        return

    template = env.get_template('verify.html')
    old_keys = {'island_akihabara', 'shibuya_espass', 'shinjuku_espass'}

    verify_data = {}
    total_predicted_good = 0  # äºˆæ¸¬S/Aå°æ•°
    total_actual_good = 0     # äºˆæ¸¬S/Aã®ã†ã¡å®Ÿéš›ã«å¥½èª¿ã ã£ãŸå°æ•°
    total_surprise = 0        # äºˆæ¸¬Bä»¥ä¸‹ã ãŒå®Ÿéš›ã«å¥½èª¿ã ã£ãŸå°æ•°

    for machine_key, machine in MACHINES.items():
        stores_data = []
        stores = get_stores_by_machine(machine_key)

        # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆå½“ãŸã‚Šå±¥æ­´å–å¾—ç”¨ï¼‰
        daily_data = load_daily_data(machine_key=machine_key)
        daily_stores = daily_data.get('stores', {}) if daily_data else {}

        for store_key, store in stores.items():
            if store_key in old_keys:
                continue

            # 2ç¨®é¡ã®äºˆæ¸¬ã‚’å–å¾—
            # (1) é–‹åº—å‰äºˆæ¸¬: éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªã—ï¼‰
            # (2) ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬: å½“æ—¥ãƒ‡ãƒ¼ã‚¿è¾¼ã¿
            availability = {}
            realtime = None
            try:
                availability = get_availability(store_key)
                realtime = get_realtime_data(store_key)
            except:
                pass

            # é–‹åº—å‰äºˆæ¸¬ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
            pre_open_recs = recommend_units(store_key, availability=availability)
            pre_open_map = {}
            for r in pre_open_recs:
                pre_open_map[str(r.get('unit_id', ''))] = {
                    'rank': r.get('final_rank', 'C'),
                    'score': r.get('final_score', 50),
                }

            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ï¼ˆå½“æ—¥ãƒ‡ãƒ¼ã‚¿è¾¼ã¿ï¼‰
            recommendations = recommend_units(store_key, realtime_data=realtime, availability=availability)
            
            # verifyç”¨: è“„ç©DBã‹ã‚‰diff_medalsç­‰ã‚’è£œå®Œ
            from scripts.enrich_rec import enrich_recs as _verify_enrich
            _verify_enrich(recommendations)
            
            units_data = []

            # ã“ã®åº—èˆ—ã®æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¦ãƒ‹ãƒƒãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆ
            store_daily = daily_stores.get(store_key, {})
            daily_units_map = {}
            for u in store_daily.get('units', []):
                daily_units_map[str(u.get('unit_id', ''))] = u

            for rec in recommendations:
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ï¼ˆå½“æ—¥ãƒ‡ãƒ¼ã‚¿è¾¼ã¿ï¼‰
                predicted_rank = rec.get('final_rank', 'C')
                predicted_score = rec.get('final_score', 50)

                # é–‰åº—å¾Œã¯å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿç¸¾ã¨ã—ã¦ä½¿ã†
                actual_art = rec.get('art_count', 0)
                actual_games = rec.get('total_games', 0)
                actual_prob = rec.get('art_prob', 0)
                if actual_art == 0 and not is_business_hours():
                    actual_art = rec.get('yesterday_art', 0)
                    actual_games = rec.get('yesterday_games', 0)
                    if actual_art > 0 and actual_games > 0:
                        actual_prob = int(actual_games / actual_art)
                    else:
                        actual_prob = 0

                # é–‹åº—å‰äºˆæ¸¬ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
                uid = str(rec.get('unit_id', ''))
                pre_open = pre_open_map.get(uid, {})
                pre_open_rank = pre_open.get('rank', 'C')
                pre_open_score = pre_open.get('score', 50)

                # çµæœåˆ¤å®šï¼ˆverdict.pyå…±é€šãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                is_predicted_good = predicted_rank in ('S', 'A')
                # diff_medals: è“„ç©DBç›´æ¥å‚ç…§ â†’ rec â†’ 0
                diff_medals = rec.get('yesterday_diff_medals', 0) or rec.get('diff_medals', 0)
                max_medals_val = rec.get('yesterday_max_medals', 0) or rec.get('max_medals', 0)
                # è“„ç©DBã‹ã‚‰ç›´æ¥å–å¾—ï¼ˆrecã«ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                if diff_medals == 0 or max_medals_val == 0:
                    _verify_date = results.get('date', '') or results.get('actual_date', '')
                    _unit_hist = daily_units_map.get(uid, {})
                    if not _unit_hist:
                        # è“„ç©DBãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç›´æ¥èª­ã‚€
                        from analysis.history_accumulator import load_unit_history
                        _uhist = load_unit_history(store_key, uid)
                        if _uhist:
                            for _dd in _uhist.get('days', []):
                                if _dd.get('date') == _verify_date:
                                    if diff_medals == 0:
                                        diff_medals = _dd.get('diff_medals', 0) or 0
                                    if max_medals_val == 0:
                                        max_medals_val = _dd.get('max_medals', 0) or 0
                                    break
                result_level = get_result_level(actual_prob, diff_medals, machine_key, max_medals=max_medals_val)
                result_mark, result_mark_class = RESULT_MARKS.get(result_level, ('-', 'nodata'))
                verdict_text, verdict_class = get_verdict(pre_open_rank, result_level)
                
                if actual_games < 500 and actual_art == 0:
                    result_level = 'nodata'
                    result_mark, result_mark_class = '-', 'nodata'
                    verdict_text, verdict_class = 'â€”', 'nodata'
                
                if is_predicted_good:
                    total_predicted_good += 1
                    if v_is_hit(pre_open_rank, result_level):
                        total_actual_good += 1
                elif verdict_class == 'surprise':
                    total_surprise += 1

                # å½“ãŸã‚Šå±¥æ­´ã‚’å–å¾—
                unit_daily = daily_units_map.get(str(rec.get('unit_id', '')), {})
                days = unit_daily.get('days', [])
                today_history_raw = []
                history_date = ''
                if days:
                    # æœ€æ–°ã®æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                    today_data = days[0]
                    today_history_raw = today_data.get('history', [])
                    history_date = today_data.get('date', '')

                processed_history, history_summary = _process_history_for_verify(today_history_raw, machine_key=machine_key)

                units_data.append({
                    'unit_id': rec.get('unit_id', ''),
                    'predicted_rank': predicted_rank,
                    'predicted_score': predicted_score,
                    'pre_open_rank': pre_open_rank,
                    'pre_open_score': pre_open_score,
                    'actual_art': actual_art,
                    'actual_prob': actual_prob,
                    'actual_games': actual_games,
                    'diff_medals': diff_medals,
                    'max_medals': rec.get('max_medals', 0),
                    'result_level': result_level,
                    'result_mark': result_mark,
                    'result_mark_class': result_mark_class,
                    'verdict_text': verdict_text,
                    'verdict_class': verdict_class,
                    'history': processed_history,
                    'history_summary': history_summary,
                    'history_date': history_date,
                })

            if units_data:
                # åº—èˆ—åˆ¥çš„ä¸­ç‡ï¼ˆé–‹åº—å‰äºˆæ¸¬ãƒ™ãƒ¼ã‚¹ï¼‰
                store_sa_total = sum(1 for u in units_data if u['pre_open_rank'] in ('S', 'A'))
                store_sa_hit = sum(1 for u in units_data if u['pre_open_rank'] in ('S', 'A') and v_is_hit(u['pre_open_rank'], u.get('result_level', 'nodata')))
                store_sa_rate = (store_sa_hit / store_sa_total * 100) if store_sa_total > 0 else 0
                stores_data.append({
                    'name': store.get('name', store_key),
                    'units': units_data,
                    'sa_total': store_sa_total,
                    'sa_hit': store_sa_hit,
                    'sa_rate': store_sa_rate,
                })

        if stores_data:
            verify_data[machine_key] = {
                'name': machine['short_name'],
                'icon': machine['icon'],
                'stores': stores_data,
            }

            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿å­˜ï¼ˆç­”ãˆåˆã‚ã›çµæœã‚’æ¬¡å›äºˆæ¸¬ã«åæ˜ ï¼‰
            try:
                from analysis.feedback import analyze_prediction_errors, save_feedback
                for sd in stores_data:
                    store_name = sd.get('name', '')
                    # store_keyã‚’é€†å¼•ã
                    _sk = ''
                    for _skey, _sval in get_stores_by_machine(machine_key).items():
                        if _sval.get('name', '') == store_name:
                            _sk = _skey
                            break
                    if _sk and sd.get('units'):
                        analysis = analyze_prediction_errors(sd['units'], _sk, machine_key)
                        if analysis['hits'] + analysis['misses'] + analysis['surprises'] > 0:
                            save_feedback(analysis)
            except Exception as e:
                print(f"  âš  ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    # çš„ä¸­ç‡è¨ˆç®—
    accuracy = 0
    if total_predicted_good > 0:
        accuracy = (total_actual_good / total_predicted_good) * 100

    # æ©Ÿç¨®åˆ¥ã®çš„ä¸­ç‡ï¼ˆé–‹åº—å‰äºˆæ¸¬ãƒ™ãƒ¼ã‚¹ï¼‰
    machine_accuracy = []
    for machine_key, machine_data in verify_data.items():
        m_all = 0
        m_predicted = 0
        m_actual = 0
        m_surprise = 0
        for store in machine_data.get('stores', []):
            for unit in store.get('units', []):
                m_all += 1
                is_sa = unit['pre_open_rank'] in ('S', 'A')
                prob = unit.get('actual_prob', 0)
                if is_sa:
                    m_predicted += 1
                    if _is_unit_hit(unit):
                        m_actual += 1
                elif unit.get('verdict_class') == 'surprise':
                    m_surprise += 1
        rate = (m_actual / m_predicted * 100) if m_predicted > 0 else 0
        machine_accuracy.append({
            'name': machine_data['name'],
            'icon': machine_data['icon'],
            'all_units': m_all,
            'total': m_predicted,
            'hit': m_actual,
            'rate': rate,
            'surprise': m_surprise,
            'total_good': m_actual + m_surprise,
        })

    # å…¨å°æ•°ã‚’è¨ˆç®—
    total_all_units = 0
    for mk, md in verify_data.items():
        for s in md.get('stores', []):
            total_all_units += len(s.get('units', []))

    # å…¨å°ä¸­ã®å¥½èª¿å°æ•°
    total_good_all = total_actual_good + total_surprise

    # æ—¥ä»˜æƒ…å ±
    now = datetime.now(JST)
    reason_data_label, reason_prev_label = get_reason_date_labels()
    generated_time = now.strftime('%Y/%m/%d %H:%M')
    # å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ï¼ˆé–‰åº—å¾Œã¯å‰æ—¥ã€å–¶æ¥­ä¸­ã¯å½“æ—¥ï¼‰
    if is_business_hours():
        result_date_str = format_date_with_weekday(now) + 'ã®å®Ÿç¸¾'
        predict_base = f'{format_date_with_weekday(now - timedelta(days=1))}ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ï¼ˆ{generated_time}ç”Ÿæˆï¼‰'
    else:
        result_date_str = format_date_with_weekday(now - timedelta(days=1)) + 'ã®å®Ÿç¸¾'
        predict_base = f'{format_date_with_weekday(now - timedelta(days=2))}ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ï¼ˆ{generated_time}ç”Ÿæˆï¼‰'

    # ä»®èª¬ç”Ÿæˆ
    hypotheses = []
    try:
        from analysis.feedback import generate_hypotheses, load_feedback_history
        import glob
        all_fbs = []
        for fp in sorted(glob.glob('data/feedback/*_2026-*.json')):
            try:
                with open(fp) as fh:
                    all_fbs.append(json.load(fh))
            except Exception:
                pass
        # ä»Šæ—¥ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ã¿ã§ä»®èª¬ç”Ÿæˆ
        today_str = now.strftime('%Y-%m-%d')
        today_fbs = [fb for fb in all_fbs if fb.get('date') == today_str]
        if today_fbs:
            hypotheses = generate_hypotheses(today_fbs)
    except Exception as e:
        print(f"  âš  ä»®èª¬ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    # çš„ä¸­ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆå…¨å°ãƒ™ãƒ¼ã‚¹ï¼‰
    perfect_stores = []
    for mk, md in verify_data.items():
        for si, sd in enumerate(md['stores']):
            units = sd.get('units', [])
            valid_units = [u for u in units if u.get('actual_prob', 0) > 0 and u.get('actual_games', 0) >= 500]
            if not valid_units:
                continue
            hit_count = sum(1 for u in valid_units if _is_unit_hit(u))
            total = len(valid_units)
            rate = hit_count / total * 100 if total > 0 else 0
            store_id = f"store-{mk}-{si}"
            if rate >= 80 and total >= 3:
                perfect_stores.append({
                    'store_name': sd.get('store_name', sd.get('name', '')),
                    'machine_name': md['name'],
                    'machine_icon': md['icon'],
                    'hit_count': hit_count,
                    'total_units': total,
                    'rate': rate,
                    'store_id': store_id,
                })
    perfect_stores.sort(key=lambda x: (-x['rate'], -x['total_units']))
    perfect_stores = perfect_stores[:5]

    # åº—Ã—æ©Ÿç¨®åˆ¥ã®çš„ä¸­ç‡ãƒ˜ãƒƒãƒ€ãƒ¼
    store_accuracy_header = []
    for mk, md in verify_data.items():
        for si, sd in enumerate(md['stores']):
            units = sd.get('units', [])
            _valid = [u for u in units if u.get('actual_prob', 0) > 0 and u.get('actual_games', 0) >= 500]
            _sa = [u for u in _valid if u.get('pre_open_rank', u.get('predicted_rank', '')) in ('S', 'A')]
            if len(_sa) >= 2:
                _hit = sum(1 for u in _sa if _is_unit_hit(u))
                _rate = int(_hit / len(_sa) * 100)
                store_accuracy_header.append({
                    'rate': _rate,
                    'machine_name': md['name'],
                    'store_name': sd.get('store_name', sd.get('name', '')),
                    'hit': _hit,
                    'total': len(_sa),
                })
    store_accuracy_header.sort(key=lambda x: (-x['rate'], -x['total']))

    now = datetime.now(JST)
    html = template.render(
        verify_data=verify_data,
        accuracy=accuracy,
        predicted_good=total_predicted_good,
        actual_good=total_actual_good,
        surprise_good=total_surprise,
        machine_accuracy=machine_accuracy,
        total_all_units=total_all_units,
        total_good_all=total_good_all,
        result_date_str=result_date_str,
        predict_base=predict_base,
        topics=[],
        perfect_stores=perfect_stores,
        store_accuracy_header=store_accuracy_header,
        now_short=now.strftime('%m%d_%H:%M'),
    )

    output_path = OUTPUT_DIR / 'verify.html'
    output_path.write_text(html, encoding='utf-8')
    print(f"  -> {output_path}")


def generate_history_pages(env):
    """å„å°ã®è©³ç´°å±¥æ­´ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating history pages...")

    template = env.get_template('unit_history.html')
    output_subdir = OUTPUT_DIR / 'history'
    output_subdir.mkdir(parents=True, exist_ok=True)

    from analysis.history_accumulator import load_unit_history

    old_keys = {'island_akihabara', 'shibuya_espass', 'shinjuku_espass'}
    page_count = 0

    for store_key, store in STORES.items():
        if store_key in old_keys:
            continue

        machine_key = store.get('machine', 'sbj')
        machine = get_machine_info(machine_key)
        units = store.get('units', [])

        for unit_id in units:
            unit_id_str = str(unit_id)

            # è“„ç©ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            acc_hist = load_unit_history(store_key, unit_id_str)
            acc_days = acc_hist.get('days', [])

            if not acc_days:
                # ãƒ‡ãƒ¼ã‚¿ãŒç„¡ã„å°ã‚‚ãƒšãƒ¼ã‚¸ã ã‘ã¯ä½œæˆï¼ˆç©ºè¡¨ç¤ºï¼‰
                now = datetime.now(JST)
                html = template.render(
                    store=store,
                    store_key=store_key,
                    unit_id=unit_id_str,
                    machine=machine,
                    machine_key=machine_key,
                    days=[],
                    total_summary=None,
                    now_short=now.strftime('%m%d_%H:%M'),
                )
                output_path = output_subdir / f'{store_key}_{unit_id_str}.html'
                output_path.write_text(html, encoding='utf-8')
                page_count += 1
                continue

            # æ—¥ä»˜ã‚’æ–°ã—ã„é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_days = sorted(acc_days, key=lambda x: x.get('date', ''), reverse=True)

            # å„æ—¥ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
            template_days = []
            total_art = 0
            total_games = 0
            good_count = 0
            total_diff = 0

            for d in sorted_days:
                date_str = d.get('date', '')
                art = d.get('art', 0) or 0
                rb = d.get('rb', 0) or 0
                games = d.get('games', 0) or 0
                prob = d.get('prob', 0) or 0
                max_rensa = d.get('max_rensa', 0) or 0
                history = d.get('history', [])
                # historyãŒã‚ã‚Œã°æ©Ÿç¨®åˆ¥é–¾å€¤ã§å†è¨ˆç®—ï¼ˆè“„ç©DBã®max_rensaã¯æ—§é–¾å€¤ã®å¯èƒ½æ€§ï¼‰
                if history:
                    from analysis.analyzer import calculate_max_rensa, calculate_max_chain_medals
                    max_rensa = calculate_max_rensa(history, machine_key=machine_key)
                    max_medals = calculate_max_chain_medals(history, machine_key=machine_key)
                else:
                    max_medals = d.get('max_medals', 0) or 0
                _day_rl = get_result_level(prob, d.get('diff_medals', 0), machine_key, max_medals=max_medals)
                is_good = _day_rl in ('excellent', 'good')

                # å·®æšè¨ˆç®—
                diff_medals = 0
                if art > 0 and games > 0:
                    try:
                        profit = calculate_expected_profit(games, art, machine_key)
                        diff_medals = profit.get('current_estimate', 0)
                    except Exception:
                        pass

                # æ—¥ä»˜è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                date_display = date_str
                try:
                    dt = datetime.strptime(date_str, '%Y-%m-%d')
                    wd = WEEKDAY_NAMES[dt.weekday()]
                    date_display = f"{dt.month}/{dt.day}({wd})"
                except Exception:
                    pass

                # å½“ãŸã‚Šå±¥æ­´ã‚’æ™‚åˆ»é™é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°ãŒä¸Šï¼‰
                history_sorted = []
                if history:
                    history_sorted = sorted(history, key=lambda x: x.get('time', '00:00'), reverse=True)

                template_days.append({
                    'date': date_str,
                    'date_display': date_display,
                    'art': art,
                    'rb': rb,
                    'games': games,
                    'prob': prob,
                    'is_good': is_good,
                    'max_rensa': max_rensa,
                    'max_medals': max_medals,
                    'diff_medals': diff_medals,
                    'history': history,
                    'history_sorted': history_sorted,
                })

                # å…¨æœŸé–“ã‚µãƒãƒªãƒ¼ç”¨
                total_art += art
                total_games += games
                if is_good:
                    good_count += 1
                total_diff += diff_medals

            # å…¨æœŸé–“ã‚µãƒãƒªãƒ¼
            total_days = len(sorted_days)
            avg_prob = int(total_games / total_art) if total_art > 0 else 0
            good_rate = round(good_count / total_days * 100) if total_days > 0 else 0

            total_summary = {
                'total_days': total_days,
                'good_days': good_count,
                'good_rate': good_rate,
                'avg_prob': round(avg_prob, 1) if avg_prob > 0 else 0,
                'total_diff_medals': total_diff,
            }

            now = datetime.now(JST)
            html = template.render(
                store=store,
                store_key=store_key,
                unit_id=unit_id_str,
                machine=machine,
                machine_key=machine_key,
                days=template_days,
                total_summary=total_summary,
                now_short=now.strftime('%m%d_%H:%M'),
            )

            output_path = output_subdir / f'{store_key}_{unit_id_str}.html'
            output_path.write_text(html, encoding='utf-8')
            page_count += 1

    print(f"  -> {output_subdir}/ ({page_count} pages)")


def copy_static_files():
    """é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼"""
    print("Copying static files...")

    import shutil

    static_src = PROJECT_ROOT / 'web' / 'static'
    static_dst = OUTPUT_DIR / 'static'

    if static_dst.exists():
        shutil.rmtree(static_dst)

    shutil.copytree(static_src, static_dst)
    print(f"  -> {static_dst}/")


def generate_metadata():
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    print("Generating metadata...")

    metadata = {
        'generated_at': datetime.now(JST).isoformat(),
        'version': '2026-01-27-static',
    }

    output_path = OUTPUT_DIR / 'metadata.json'
    output_path.write_text(json.dumps(metadata, ensure_ascii=False, indent=2), encoding='utf-8')
    print(f"  -> {output_path}")


def run_unit_verification():
    """å°ç•ªå·æ¤œè¨¼ã‚’å®Ÿè¡Œã—ã€ã‚¢ãƒ©ãƒ¼ãƒˆãŒã‚ã‚Œã°ä¿å­˜"""
    print("Running unit verification...")
    try:
        from scripts.verify_units import verify_units_from_availability, save_alerts, print_report
        avail_path = PROJECT_ROOT / 'data' / 'availability.json'
        if avail_path.exists():
            with open(avail_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            alerts = verify_units_from_availability(data)
            print_report(alerts)
            if alerts:
                save_alerts(alerts, source='availability')
        else:
            print("  availability.json not found, skipping")
    except Exception as e:
        print(f"  Verification error: {e}")


def run_data_integrity_check():
    """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå…¨åº—èˆ—ã®ART/ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ æç­‰ï¼‰"""
    print("Running data integrity check...")
    try:
        from scripts.verify_units import verify_data_integrity, print_integrity_report
        avail_path = PROJECT_ROOT / 'data' / 'availability.json'
        if avail_path.exists():
            with open(avail_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            issues = verify_data_integrity(data)
            print_integrity_report(issues)
        else:
            print("  availability.json not found, skipping")
    except Exception as e:
        print(f"  Integrity check error: {e}")


def main():
    print("=" * 50)
    print("é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆé–‹å§‹")
    print(f"å‡ºåŠ›å…ˆ: {OUTPUT_DIR}")
    print("=" * 50)
    print()

    # å°ç•ªå·æ¤œè¨¼ï¼ˆã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆï¼‰
    run_unit_verification()

    # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    run_data_integrity_check()

    # æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿è“„ç©ï¼ˆhistory DBæ›´æ–°ï¼‰
    try:
        from analysis.history_accumulator import accumulate_from_daily
        for mk in MACHINES:
            daily = load_daily_data(machine_key=mk)
            if daily:
                result = accumulate_from_daily(daily, mk)
                if result['new_entries'] > 0:
                    print(f"  ğŸ“¦ {mk}: {result['new_entries']}ä»¶è“„ç© ({result['updated_units']}å°)")
    except Exception as e:
        print(f"  âš  è“„ç©ã‚¨ãƒ©ãƒ¼: {e}")

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿è¨˜éŒ²ï¼ˆè“„ç©æ¸ˆã¿historyã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼‰
    try:
        from analysis.pattern_detector import record_from_history
        import os
        for store_dir in os.listdir('data/history'):
            if not os.path.isdir(f'data/history/{store_dir}'):
                continue
            if '_sbj' in store_dir:
                mk = 'sbj'
            elif '_hokuto' in store_dir:
                mk = 'hokuto_tensei2'
            else:
                continue
            n = record_from_history(store_dir, mk)
            if n > 0:
                print(f"  ğŸ“Š ãƒ‘ã‚¿ãƒ¼ãƒ³è¨˜éŒ²: {store_dir} ({n}ä»¶)")
    except Exception as e:
        print(f"  âš  ãƒ‘ã‚¿ãƒ¼ãƒ³è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
    print()

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # Jinja2ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    env = setup_jinja()

    # å„ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ
    generate_index(env)
    generate_machine_pages(env)
    generate_ranking_pages(env)
    generate_recommend_pages(env)
    generate_verify_page(env)
    generate_history_pages(env)
    copy_static_files()
    generate_metadata()

    print()
    print("=" * 50)
    print("é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆå®Œäº†!")
    print("=" * 50)

    # ãƒ“ãƒ«ãƒ‰å¾Œæ¤œè¨¼ï¼ˆæ—¢å­˜ï¼‰
    print("\n--- ãƒ“ãƒ«ãƒ‰å¾Œæ¤œè¨¼ ---")
    from scripts.validate_output import validate_all
    if not validate_all():
        print("âš ï¸ validate_output: ERRORãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
    
    # post_build_checkï¼ˆHTMLå‡ºåŠ›ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼‰
    from scripts.post_build_check import run_all as _post_build_check
    post_errors = _post_build_check()
    if post_errors > 0:
        print(f"\nâš ï¸ POST-BUILD CHECK: {post_errors}ä»¶ã®ERRORï¼ˆè­¦å‘Šã®ã¿ã€ãƒ“ãƒ«ãƒ‰ã¯ç¶šè¡Œï¼‰")
    print("--- æ¤œè¨¼å®Œäº† ---")


if __name__ == '__main__':
    main()
