#!/usr/bin/env python3
"""
é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Cloudflare Pagesç”¨ã«é™çš„HTMLã‚’ç”Ÿæˆã™ã‚‹
GitHub Actionsã§å®šæœŸå®Ÿè¡Œã—ã€ç”Ÿæˆã—ãŸHTMLã‚’ãƒ‡ãƒ—ãƒ­ã‚¤
"""

import json
import os
import sys
from datetime import datetime, timezone, timedelta
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from jinja2 import Environment, FileSystemLoader
from config.rankings import STORES, MACHINES, get_stores_by_machine, get_machine_info
from analysis.recommender import recommend_units, load_daily_data, generate_store_analysis, calculate_expected_profit, analyze_today_graph, calculate_at_intervals
from scrapers.availability_checker import get_availability, get_realtime_data
from scripts.verify_units import get_active_alerts, get_unit_status

JST = timezone(timedelta(hours=9))
WEEKDAY_NAMES = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUTPUT_DIR = PROJECT_ROOT / 'docs'  # GitHub Pagesäº’æ›


def get_display_mode():
    """ç¾åœ¨æ™‚åˆ»ã‹ã‚‰è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ã‚’æ±ºå®š"""
    now = datetime.now(JST)
    hour = now.hour
    minute = now.minute

    if hour >= 23 or hour < 10:
        return 'result'
    elif hour == 22 and minute >= 50:
        return 'collecting'
    else:
        return 'realtime'


def format_date_with_weekday(dt):
    """æ—¥ä»˜ã‚’æ›œæ—¥ä»˜ãã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    weekday = WEEKDAY_NAMES[dt.weekday()]
    return f"{dt.month}æœˆ{dt.day}æ—¥({weekday})"


def is_business_hours():
    """å–¶æ¥­æ™‚é–“å†…ã‹ã©ã†ã‹"""
    return get_display_mode() == 'realtime'


def rank_color(rank):
    """ãƒ©ãƒ³ã‚¯è‰²ã‚’è¿”ã™"""
    colors = {
        'S': '#ff6b6b',
        'A': '#ffa502',
        'B': '#2ed573',
        'C': '#70a1ff',
        'D': '#747d8c',
    }
    return colors.get(rank, '#747d8c')


def signed_number(value):
    """ç¬¦å·ä»˜ãã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ•°å€¤"""
    try:
        num = int(value)
        if num >= 0:
            return f'+{num:,}'
        else:
            return f'{num:,}'
    except (ValueError, TypeError):
        return str(value)


def medals_badge(value):
    """æœ€å¤§ç²å¾—æšæ•°ãƒãƒƒã‚¸"""
    try:
        num = int(value)
        if num >= 10000:
            return {'class': 'medals-10k', 'icon': 'ğŸ”¥', 'label': '1ä¸‡æšOVER'}
        elif num >= 5000:
            return {'class': 'medals-5k', 'icon': 'ğŸ’°', 'label': '5åƒæšOVER'}
        elif num >= 3000:
            return {'class': 'medals-3k', 'icon': 'âœ¨', 'label': '3åƒæšOVER'}
        elif num >= 2000:
            return {'class': 'medals-2k', 'icon': 'â­', 'label': '2åƒæšOVER'}
        elif num >= 1000:
            return {'class': 'medals-1k', 'icon': 'ğŸ‘', 'label': '1åƒæšOVER'}
        return None
    except (ValueError, TypeError):
        return None


def setup_jinja():
    """Jinja2ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    template_dir = PROJECT_ROOT / 'web' / 'templates'
    env = Environment(loader=FileSystemLoader(str(template_dir)))

    # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ«ã‚¿ãƒ»é–¢æ•°ã‚’è¿½åŠ 
    env.globals['rank_color'] = rank_color
    env.globals['signed_number'] = signed_number
    env.globals['medals_badge'] = medals_badge
    env.globals['url_for'] = lambda endpoint, **kwargs: generate_url(endpoint, **kwargs)

    def pad_unit_id(uid):
        """å°ç•ªå·ã‚’4æ¡ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆ1â†’0001, 23â†’0023, 0752â†’0752ï¼‰"""
        s = str(uid)
        if s.isdigit() and len(s) < 4:
            return s.zfill(4)
        return s
    env.filters['pad_id'] = pad_unit_id
    env.globals['pad_id'] = pad_unit_id

    def format_short_date(date_str):
        """'2026-01-26' â†’ '1/26(æœˆ)'"""
        if not date_str:
            return ''
        try:
            dt = datetime.strptime(str(date_str), '%Y-%m-%d')
            return f"{dt.month}/{dt.day}({WEEKDAY_NAMES[dt.weekday()]})"
        except:
            return str(date_str)
    env.globals['short_date'] = format_short_date

    return env


def generate_url(endpoint, **kwargs):
    """é™çš„ã‚µã‚¤ãƒˆç”¨ã®URLç”Ÿæˆï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ï¼‰"""
    if endpoint == 'index':
        return '/index.html'
    elif endpoint == 'static':
        return f"/static/{kwargs.get('filename', '')}"
    elif endpoint == 'recommend':
        return f"/recommend/{kwargs.get('store_key', '')}.html"
    elif endpoint == 'machine_stores':
        return f"/machine/{kwargs.get('machine_key', '')}.html"
    elif endpoint == 'ranking':
        return f"/ranking/{kwargs.get('machine_key', '')}.html"
    elif endpoint == 'rules':
        return '/rules.html'
    elif endpoint == 'unit_history':
        return f"/history/{kwargs.get('store_key', '')}_{kwargs.get('unit_id', '')}.html"
    elif endpoint == 'api_status':
        return f"https://autogmail.pythonanywhere.com/api/status/{kwargs.get('store_key', '')}"
    elif endpoint == 'verify':
        return '/verify.html'
    return '#'


def generate_index(env):
    """ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating index.html...")

    template = env.get_template('index.html')

    now = datetime.now(JST)
    display_mode = get_display_mode()
    is_open = is_business_hours()
    # æ›œæ—¥å‚¾å‘ã¯å¸¸ã«ã€Œæ¬¡ã«é–‹åº—ã™ã‚‹æ—¥ã€ã®æ›œæ—¥
    # 22:45ã€œ23:59ã¯ç¿Œæ—¥ã€0:00ã€œ09:59ã¯ãã®æ—¥ï¼ˆæ—¢ã«æ—¥ä»˜ãŒå¤‰ã‚ã£ã¦ã„ã‚‹ï¼‰
    if is_open:
        today_weekday = WEEKDAY_NAMES[now.weekday()]
    elif now.hour >= 22:
        # 22:45ã€œ23:59 â†’ ç¿Œæ—¥ã®æ›œæ—¥
        tomorrow_dt = now + timedelta(days=1)
        today_weekday = WEEKDAY_NAMES[tomorrow_dt.weekday()]
    else:
        # 0:00ã€œ09:59 â†’ ä»Šæ—¥ã®æ›œæ—¥ï¼ˆæ—¥ä»˜ã¯æ—¢ã«å¤‰ã‚ã£ã¦ã„ã‚‹ï¼‰
        today_weekday = WEEKDAY_NAMES[now.weekday()]
    today_date = now.strftime('%Y/%m/%d')
    today_date_formatted = format_date_with_weekday(now)

    # ç†ç”±æ–‡ã®æ—¥ä»˜ãƒ©ãƒ™ãƒ«
    reason_data_label, reason_prev_label = get_reason_date_labels()

    # åº—èˆ—æ›œæ—¥å‚¾å‘ï¼ˆç‰©ç†åº—èˆ—ãƒ™ãƒ¼ã‚¹ï¼‰
    store_day_ratings = {
        'island_akihabara': {
            'name': 'ã‚¢ã‚¤ãƒ©ãƒ³ãƒ‰ç§‹è‘‰åŸ',
            'short_name': 'ã‚¢ã‚¤ãƒ©ãƒ³ãƒ‰ç§‹è‘‰åŸ',
            'day_ratings': {'æœˆ': 4, 'ç«': 3, 'æ°´': 5, 'æœ¨': 3, 'é‡‘': 3, 'åœŸ': 1, 'æ—¥': 4},
            'best_note': 'æ°´æ›œãŒæœ€å¼·ã€æ—¥æœˆã‚‚ç‹™ã„ç›®',
            'worst_note': 'åœŸæ›œã¯é¿ã‘ã‚‹ã¹ã',
            'overall_rating': 4,
            'machine_links': [
                {'store_key': 'island_akihabara_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'island_akihabara_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'shibuya_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“æ¸‹è°·æ–°é¤¨',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ¸‹è°·æ–°é¤¨',
            'day_ratings': {'æœˆ': 3, 'ç«': 4, 'æ°´': 4, 'æœ¨': 5, 'é‡‘': 3, 'åœŸ': 3, 'æ—¥': 1},
            'best_note': 'æœ¨æ›œãŒæœ€å¼·ã€ç«æ°´ã‚‚ç‹™ã„ç›®',
            'worst_note': 'æ—¥æ›œã¯é¿ã‘ã‚‹ã¹ã',
            'overall_rating': 3,
            'machine_links': [
                {'store_key': 'shibuya_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'shibuya_espass_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'shinjuku_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“æ–°å®¿æ­Œèˆä¼ç”ºåº—',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ­Œèˆä¼ç”º',
            'day_ratings': {'æœˆ': 2, 'ç«': 3, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 5, 'æ—¥': 3},
            'best_note': 'åœŸæ›œãŒæœ€å¼·ã€é‡‘æ›œã‚‚ç‹™ã„ç›®',
            'worst_note': 'æœˆæ›œã¯æ§ãˆã‚',
            'overall_rating': 3,
            'machine_links': [
                {'store_key': 'shinjuku_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'shinjuku_espass_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'akihabara_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“ç§‹è‘‰åŸé§…å‰åº—',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹ç§‹è‘‰åŸ',
            'day_ratings': {'æœˆ': 2, 'ç«': 3, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 5, 'æ—¥': 4},
            'best_note': 'åœŸæ—¥ãŒç‹™ã„ç›®ã€é‡‘æ›œã‚‚å¯',
            'worst_note': 'æœˆæ›œã¯æ§ãˆã‚',
            'overall_rating': 3,
            'machine_links': [
                {'store_key': 'akihabara_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'akihabara_espass_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'seibu_shinjuku_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“è¥¿æ­¦æ–°å®¿é§…å‰åº—',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹è¥¿æ­¦æ–°å®¿',
            'day_ratings': {'æœˆ': 2, 'ç«': 2, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 4, 'æ—¥': 3},
            'best_note': 'é‡‘åœŸãŒç‹™ã„ç›®',
            'worst_note': 'æœˆç«ã¯æ§ãˆã‚',
            'overall_rating': 2,
            'machine_links': [
                {'store_key': 'seibu_shinjuku_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
            ],
        },
    }

    # æ©Ÿç¨®ä¸€è¦§ã¨ãƒˆãƒƒãƒ—å°ã‚’åé›†
    machines = []
    top3_all = []
    yesterday_top10 = []
    today_top10 = []

    for key, machine in MACHINES.items():
        stores = get_stores_by_machine(key)
        total_units = sum(len(s['units']) for s in stores.values())
        machines.append({
            'key': key,
            'name': machine['name'],
            'short_name': machine['short_name'],
            'icon': machine['icon'],
            'store_count': len(stores),
            'unit_count': total_units,
        })

        for store_key, store in stores.items():
            try:
                availability = {}
                try:
                    availability = get_availability(store_key)
                except:
                    pass

                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæœ¬æ—¥ã®ART/RBç­‰ï¼‰
                realtime = None
                try:
                    realtime = get_realtime_data(store_key)
                except:
                    pass

                recs = recommend_units(store_key, realtime_data=realtime, availability=availability,
                                      data_date_label=reason_data_label, prev_date_label=reason_prev_label)

                # å…¨recsã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä»˜ä¸
                for rec in recs:
                    rec['store_name'] = store.get('short_name', store['name'])
                    rec['store_key'] = store_key
                    rec['machine_key'] = key
                    rec['machine_icon'] = machine['icon']
                    rec['machine_name'] = machine.get('display_name', machine['short_name'])
                    if 'availability' not in rec or rec['availability'] is None:
                        rec['availability'] = availability.get(rec['unit_id'], '')
                    # å‰æ—¥ãƒ»å‰ã€…æ—¥ã®å·®æšè¨ˆç®—
                    y_art = rec.get('yesterday_art', 0)
                    y_games = rec.get('yesterday_games', 0)
                    if y_art and y_art > 0 and y_games and y_games > 0:
                        y_p = calculate_expected_profit(y_games, y_art, key)
                        rec['yesterday_diff_medals'] = y_p.get('current_estimate', 0)
                    db_art = rec.get('day_before_art', 0)
                    db_games = rec.get('day_before_games', 0)
                    if db_art and db_art > 0 and db_games and db_games > 0:
                        db_p = calculate_expected_profit(db_games, db_art, key)
                        rec['day_before_diff_medals'] = db_p.get('current_estimate', 0)
                    td_art = rec.get('three_days_ago_art', 0)
                    td_games = rec.get('three_days_ago_games', 0)
                    if td_art and td_art > 0 and td_games and td_games > 0:
                        td_p = calculate_expected_profit(td_games, td_art, key)
                        rec['three_days_ago_diff_medals'] = td_p.get('current_estimate', 0)

                # TOP3å€™è£œï¼ˆä¸Šä½3å°/åº—èˆ—ï¼‰
                for rec in recs[:3]:
                    top3_all.append(rec)

                # å‰æ—¥ã®çˆ†ç™ºå°ï¼ˆå…¨å°ã‹ã‚‰åé›†ã€yesterday_art > 0ï¼‰
                for rec in recs:
                    y_art = rec.get('yesterday_art', 0)
                    if y_art and y_art > 0:
                        y_games = rec.get('yesterday_games', 0)
                        y_prob = y_games / y_art if y_art > 0 and y_games > 0 else 0
                        # å·®æšè¨ˆç®—
                        y_diff_medals = 0
                        y_setting = ''
                        y_setting_num = 0
                        if y_art > 0 and y_games > 0:
                            y_profit = calculate_expected_profit(y_games, y_art, key)
                            y_diff_medals = y_profit.get('current_estimate', 0)
                            y_si = y_profit.get('setting_info', {})
                            y_setting = y_si.get('estimated_setting', '')
                            y_setting_num = y_si.get('setting_num', 0)
                        # é€£ãƒãƒ£ãƒ³ãƒ»å¤©äº•ãƒ»æœ€å¤§ãƒ¡ãƒ€ãƒ«ã‚’è¨ˆç®—
                        y_max_rensa = rec.get('yesterday_max_rensa', 0) or rec.get('today_max_rensa', 0)
                        y_max_medals = rec.get('yesterday_max_medals', 0)
                        y_ceilings = 0
                        hist = rec.get('today_history', [])
                        if hist:
                            try:
                                graph = analyze_today_graph(hist)
                                y_max_rensa = max(y_max_rensa, graph.get('max_rensa', 0))
                                intervals = calculate_at_intervals(hist)
                                y_ceilings = sum(1 for g in intervals if g >= 999)
                                if not y_max_medals:
                                    y_max_medals = max((h.get('medals', 0) for h in hist), default=0)
                            except:
                                pass
                        # è“„ç©DBã‹ã‚‰ã‚‚è£œå®Œ
                        if not y_max_rensa or not y_max_medals:
                            try:
                                from analysis.history_accumulator import load_unit_history
                                acc_hist = load_unit_history(store_key, rec['unit_id'])
                                y_date = rec.get('yesterday_date', '')
                                for ad in acc_hist.get('days', []):
                                    if ad.get('date') == y_date or (not y_date and ad == acc_hist['days'][-1]):
                                        if not y_max_rensa:
                                            y_max_rensa = ad.get('max_rensa', 0)
                                        if not y_max_medals:
                                            y_max_medals = ad.get('max_medals', 0)
                                        break
                            except:
                                pass
                        yesterday_top10.append({
                            'unit_id': rec['unit_id'],
                            'store_name': rec['store_name'],
                            'store_key': store_key,
                            'machine_icon': machine['icon'],
                            'machine_name': machine.get('display_name', machine['short_name']),
                            'yesterday_art': y_art,
                            'yesterday_rb': rec.get('yesterday_rb', 0),
                            'yesterday_games': y_games,
                            'yesterday_max_rensa': y_max_rensa,
                            'yesterday_max_medals': y_max_medals,
                            'yesterday_ceilings': y_ceilings,
                            'yesterday_prob': y_prob,
                            'diff_medals': y_diff_medals,
                            'estimated_setting': y_setting,
                            'setting_num': y_setting_num,
                        })

                # æœ¬æ—¥ã®çˆ†ç™ºå°ï¼ˆå…¨å°ã‹ã‚‰åé›†ã€art_count > 0ï¼‰
                for rec in recs:
                    t_art = rec.get('art_count', 0)
                    t_medals = rec.get('max_medals', 0)
                    t_games = rec.get('total_games', 0)
                    if t_art > 0 or t_medals > 0:
                        # å·®æšè¨ˆç®—
                        diff_medals = 0
                        if t_art > 0 and t_games > 0:
                            profit = calculate_expected_profit(t_games, t_art, key)
                            diff_medals = profit.get('current_estimate', 0)
                        today_top10.append({
                            'unit_id': rec['unit_id'],
                            'store_name': rec['store_name'],
                            'store_key': store_key,
                            'machine_icon': machine['icon'],
                            'machine_name': machine.get('display_name', machine['short_name']),
                            'art_count': t_art,
                            'rb_count': rec.get('rb_count', 0),
                            'total_games': t_games,
                            'max_medals': t_medals,
                            'art_prob': rec.get('art_prob', 0),
                            'availability': rec.get('availability', ''),
                            'estimated_setting': rec.get('estimated_setting', ''),
                            'setting_num': rec.get('setting_num', 0),
                            'payout_estimate': rec.get('payout_estimate', ''),
                            'today_max_rensa': rec.get('today_max_rensa', 0),
                            'diff_medals': diff_medals,
                        })
            except Exception as e:
                print(f"Error processing {store_key}: {e}")

    # ã‚½ãƒ¼ãƒˆ
    def top3_sort_key(r):
        score = r['final_score']
        if r.get('availability') == 'ç©ºã':
            score += 10
        return -score

    top3_all.sort(key=top3_sort_key)
    top3 = top3_all[:3]

    # å‰æ—¥ã®çˆ†ç™ºå°: å·®æšã§ã‚½ãƒ¼ãƒˆ
    yesterday_top10.sort(key=lambda x: (-x.get('diff_medals', 0), -x['yesterday_art']))
    yesterday_top10 = yesterday_top10[:10]

    # æœ¬æ—¥ã®çˆ†ç™ºå°: å·®æšã§ã‚½ãƒ¼ãƒˆï¼ˆæ¨å®šå·®æšã®å¤šã„é †ï¼‰
    today_top10.sort(key=lambda x: (-x.get('diff_medals', 0), -x['max_medals']))
    today_top10 = today_top10[:10]

    # æ›œæ—¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    today_store_ranking = []
    for store_key, info in store_day_ratings.items():
        today_rating = info['day_ratings'].get(today_weekday, 3)
        today_store_ranking.append({
            'store_key': store_key,
            'name': info['name'],
            'short_name': info['short_name'],
            'today_rating': today_rating,
            'best_note': info['best_note'],
            'worst_note': info['worst_note'],
            'overall_rating': info['overall_rating'],
            'day_ratings': info['day_ratings'],
            'machine_links': info.get('machine_links', []),
        })
    today_store_ranking.sort(key=lambda x: -x['today_rating'])

    today_recommended_stores = [s for s in today_store_ranking if s['today_rating'] >= 4]
    today_avoid_stores = [s for s in today_store_ranking if s['today_rating'] <= 2]

    result_date_str = None
    date_prefix = ''  # ã€Œæ˜¨æ—¥ã€orã€Œæœ¬æ—¥ã€
    if display_mode in ('result', 'collecting'):
        if now.hour >= 23:
            result_date = now
            date_prefix = 'æœ¬æ—¥'
        elif now.hour < 10:
            result_date = now - timedelta(days=1)
            date_prefix = 'æ˜¨æ—¥'
        else:
            result_date = now - timedelta(days=1)
            date_prefix = 'æ˜¨æ—¥'
        result_date_str = format_date_with_weekday(result_date)
    elif is_open:
        date_prefix = 'æœ¬æ—¥'

    # æ¬¡ã®å–¶æ¥­æ—¥ï¼ˆãŠã™ã™ã‚å°ã®å¯¾è±¡æ—¥ï¼‰
    if now.hour >= 22:
        # 22:45ã€œ23:59 â†’ ç¿Œæ—¥
        next_day_dt = now + timedelta(days=1)
        next_day_prefix = 'æ˜æ—¥'
    elif now.hour < 10:
        # 0:00ã€œ9:59 â†’ ä»Šæ—¥
        next_day_dt = now
        next_day_prefix = 'æœ¬æ—¥'
    else:
        # å–¶æ¥­ä¸­ â†’ ä»Šæ—¥
        next_day_dt = now
        next_day_prefix = 'æœ¬æ—¥'
    next_day_str = format_date_with_weekday(next_day_dt)

    # å…¨åº—èˆ—ä¸€è¦§ï¼ˆåº—èˆ—å°ç·šç”¨ï¼‰
    all_stores = []
    for store_key, info in store_day_ratings.items():
        today_rating = info['day_ratings'].get(today_weekday, 3)
        all_stores.append({
            'store_key': store_key,
            'name': info['name'],
            'short_name': info['short_name'],
            'today_rating': today_rating,
            'overall_rating': info['overall_rating'],
            'machine_links': info.get('machine_links', []),
        })
    # ä»Šæ—¥ã®è©•ä¾¡é †ã§ã‚½ãƒ¼ãƒˆ
    all_stores.sort(key=lambda x: (-x['today_rating'], -x['overall_rating']))

    night_mode = is_night_mode()
    tomorrow = now + timedelta(days=1)
    tomorrow_str = format_date_with_weekday(tomorrow)
    yesterday = now - timedelta(days=1)
    yesterday_str = format_date_with_weekday(yesterday)

    # ã€Œæœ¬æ—¥ã€ã€Œå‰æ—¥ã€ã‚’æ—¥ä»˜ä»˜ãã«
    # ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ã¯availability.jsonã®fetched_atã‹ã‚‰å–å¾—
    try:
        from scrapers.availability_checker import get_daidata_availability
        avail_data = get_daidata_availability()
        fetched_at = avail_data.get('fetched_at', '')
        if fetched_at:
            data_dt = datetime.fromisoformat(fetched_at)
            data_date_str = format_date_with_weekday(data_dt)
            prev_date_str = format_date_with_weekday(data_dt - timedelta(days=1))
        else:
            data_date_str = format_date_with_weekday(now)
            prev_date_str = format_date_with_weekday(yesterday)
    except:
        data_date_str = format_date_with_weekday(now)
        prev_date_str = format_date_with_weekday(yesterday)

    # æ©Ÿç¨®åˆ¥çš„ä¸­ç‡ï¼ˆãƒ’ãƒ¼ãƒ­ãƒ¼è¡¨ç¤ºç”¨: é«˜ã„é †ã«2ã¤ï¼‰
    accuracy_hero = []
    for machine_key, machine in MACHINES.items():
        stores = get_stores_by_machine(machine_key)
        m_total = 0
        m_hit = 0
        store_results = []  # åº—èˆ—åˆ¥ã®çµæœ
        for store_key, store in stores.items():
            s_total = 0
            s_hit = 0
            try:
                pre_recs = recommend_units(store_key)  # éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿
                rt = get_realtime_data(store_key)
                rt_recs = recommend_units(store_key, realtime_data=rt)
                rt_map = {}
                for r in rt_recs:
                    rt_map[str(r.get('unit_id', ''))] = r
                for r in pre_recs:
                    uid = str(r.get('unit_id', ''))
                    if r.get('final_rank', 'C') in ('S', 'A'):
                        m_total += 1
                        s_total += 1
                        rt_r = rt_map.get(uid, {})
                        art = rt_r.get('art_count', 0)
                        games = rt_r.get('total_games', 0)
                        if art > 0 and games / art <= 130:
                            m_hit += 1
                            s_hit += 1
            except:
                pass
            if s_total > 0:
                s_rate = s_hit / s_total * 100
                short_name = store.get('name', store_key).replace('ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“', '').replace('åº—', '')
                store_results.append({'name': short_name, 'rate': s_rate, 'hit': s_hit, 'total': s_total})

        # çš„ä¸­ç‡ãŒé«˜ã„åº—èˆ—ã‚’è¡¨ç¤ºï¼ˆ100%ã®åº—ã¯åå‰ã€ãã‚Œä»¥å¤–ã¯ç‡ï¼‰
        store_results.sort(key=lambda x: -x['rate'])
        top_parts = []
        for sr in store_results[:3]:
            if sr['rate'] >= 100:
                top_parts.append(f"{sr['name']}å…¨çš„ä¸­")
            elif sr['rate'] >= 50:
                top_parts.append(f"{sr['name']}{sr['hit']}/{sr['total']}")
        top_stores = ' / '.join(top_parts) if top_parts else ''

        rate = (m_hit / m_total * 100) if m_total > 0 else 0
        accuracy_hero.append({
            'name': machine['short_name'],
            'icon': machine['icon'],
            'rate': rate,
            'hit': m_hit,
            'total': m_total,
            'top_stores': top_stores,
        })
    # é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
    accuracy_hero.sort(key=lambda x: -x['rate'])

    html = template.render(
        machines=machines,
        top3=top3,
        yesterday_top10=yesterday_top10,
        today_top10=today_top10,
        today_weekday=today_weekday,
        today_date=today_date,
        today_date_formatted=today_date_formatted,
        now_time=now.strftime('%H:%M'),
        now_short=now.strftime('%m%d_%H:%M'),
        store_recommendations={},
        today_recommended_stores=today_recommended_stores,
        today_store_ranking=today_store_ranking,
        today_avoid_stores=today_avoid_stores,
        store_day_ratings=store_day_ratings,
        display_mode=display_mode,
        result_date_str=result_date_str,
        is_open=is_open,
        all_stores=all_stores,
        night_mode=night_mode,
        tomorrow_str=tomorrow_str,
        yesterday_str=yesterday_str,
        data_date_str=data_date_str,
        prev_date_str=prev_date_str,
        accuracy_hero=accuracy_hero,
        date_prefix=date_prefix,
        next_day_prefix=next_day_prefix,
        next_day_str=next_day_str,
    )

    output_path = OUTPUT_DIR / 'index.html'
    output_path.write_text(html, encoding='utf-8')
    print(f"  -> {output_path}")


def generate_machine_pages(env):
    """æ©Ÿç¨®åˆ¥åº—èˆ—ä¸€è¦§ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating machine pages...")

    template = env.get_template('stores.html')
    output_subdir = OUTPUT_DIR / 'machine'
    output_subdir.mkdir(parents=True, exist_ok=True)

    for machine_key, machine in MACHINES.items():
        stores = get_stores_by_machine(machine_key)
        store_list = [
            {'key': key, 'name': store['name'], 'unit_count': len(store['units'])}
            for key, store in stores.items()
        ]

        html = template.render(
            machine=machine,
            machine_key=machine_key,
            stores=store_list,
        )

        output_path = output_subdir / f'{machine_key}.html'
        output_path.write_text(html, encoding='utf-8')
        print(f"  -> {output_path}")


def get_reason_date_labels():
    """ç†ç”±æ–‡ã®æ—¥ä»˜ãƒ©ãƒ™ãƒ«ã‚’å–å¾—ï¼ˆé–‰åº—å¾Œã®ã¿æ—¥ä»˜ã«ç½®æ›ï¼‰"""
    if is_business_hours():
        return None, None
    try:
        from scrapers.availability_checker import get_daidata_availability
        avail_data = get_daidata_availability()
        fetched_at = avail_data.get('fetched_at', '')
        if fetched_at:
            data_dt = datetime.fromisoformat(fetched_at)
            data_label = f"{data_dt.month}/{data_dt.day}({WEEKDAY_NAMES[data_dt.weekday()]})"
            prev_dt = data_dt - timedelta(days=1)
            prev_label = f"{prev_dt.month}/{prev_dt.day}({WEEKDAY_NAMES[prev_dt.weekday()]})"
            return data_label, prev_label
    except:
        pass
    return None, None


def is_night_mode():
    """22:45ä»¥é™ã¯ç¿Œæ—¥äºˆæƒ³ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ"""
    now = datetime.now(JST)
    return now.hour > 22 or (now.hour == 22 and now.minute >= 45)


def generate_ranking_pages(env):
    """æ©Ÿç¨®åˆ¥ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating ranking pages...")

    template = env.get_template('ranking.html')
    output_subdir = OUTPUT_DIR / 'ranking'
    output_subdir.mkdir(parents=True, exist_ok=True)

    night_mode = is_night_mode()
    now = datetime.now(JST)
    tomorrow = now + timedelta(days=1)
    tomorrow_str = format_date_with_weekday(tomorrow)
    yesterday = now - timedelta(days=1)
    data_date_str = format_date_with_weekday(now)
    prev_date_str = format_date_with_weekday(yesterday)
    reason_data_label, reason_prev_label = get_reason_date_labels()

    for machine_key, machine in MACHINES.items():
        stores = get_stores_by_machine(machine_key)
        all_recommendations = []

        for store_key, store in stores.items():
            availability = {}
            try:
                availability = get_availability(store_key)
            except:
                pass

            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚‚å–å¾—ï¼ˆè¨­å®šæ¨æ¸¬ã‚„max_medalsç­‰ã«å¿…è¦ï¼‰
            realtime = None
            try:
                realtime = get_realtime_data(store_key)
            except:
                pass

            recommendations = recommend_units(store_key, realtime_data=realtime, availability=availability,
                                              data_date_label=reason_data_label, prev_date_label=reason_prev_label)
            for rec in recommendations:
                rec['store_name'] = store.get('short_name', store['name'])
                rec['store_key'] = store_key
                all_recommendations.append(rec)

        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        def sort_key(r):
            score = r['final_score']
            if r['is_running']:
                score -= 30
            return -score

        all_recommendations.sort(key=sort_key)
        top_recs = [r for r in all_recommendations if r['final_rank'] in ('S', 'A') and not r['is_running']][:10]
        other_recs = [r for r in all_recommendations if r not in top_recs][:20]

        html = template.render(
            machine=machine,
            machine_key=machine_key,
            top_recs=top_recs,
            other_recs=other_recs,
            total_count=len(all_recommendations),
            night_mode=night_mode,
            tomorrow_str=tomorrow_str,
            data_date_str=data_date_str,
            prev_date_str=prev_date_str,
            now_short=now.strftime('%m%d_%H:%M'),
        )

        output_path = output_subdir / f'{machine_key}.html'
        output_path.write_text(html, encoding='utf-8')
        print(f"  -> {output_path}")


def generate_recommend_pages(env):
    """å„åº—èˆ—ã®æ¨å¥¨ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating recommend pages...")

    template = env.get_template('recommend.html')
    output_subdir = OUTPUT_DIR / 'recommend'
    output_subdir.mkdir(parents=True, exist_ok=True)

    is_open = is_business_hours()
    display_mode = get_display_mode()
    reason_data_label, reason_prev_label = get_reason_date_labels()

    # æ—§å½¢å¼ã‚­ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
    old_keys = {'island_akihabara', 'shibuya_espass', 'shinjuku_espass'}

    for store_key, store in STORES.items():
        if store_key in old_keys:
            continue
        print(f"  Processing {store_key}...")

        machine_key = store.get('machine', 'sbj')
        machine = get_machine_info(machine_key)

        # ç©ºãçŠ¶æ³ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        availability = {}
        realtime_data = None
        cache_info = None

        try:
            availability = get_availability(store_key)
        except:
            pass

        try:
            rt_data = get_realtime_data(store_key)
            if rt_data and rt_data.get('units'):
                realtime_data = rt_data
                fetched_at_str = rt_data.get('fetched_at', '')
                if fetched_at_str:
                    try:
                        fetched_time = datetime.fromisoformat(fetched_at_str.replace('Z', '+00:00'))
                        fetched_time_jst = fetched_time.astimezone(JST)
                        now_jst = datetime.now(JST)
                        cache_info = {
                            'fetched_at': fetched_time_jst.strftime('%H:%M'),
                            'age_seconds': int((now_jst - fetched_time_jst).total_seconds()),
                            'source': rt_data.get('source', 'unknown'),
                        }
                    except:
                        pass
        except:
            pass

        recommendations = recommend_units(store_key, realtime_data, availability,
                                          data_date_label=reason_data_label, prev_date_label=reason_prev_label)

        # åˆ†é¡
        sa_recs = [r for r in recommendations if r['final_rank'] in ('S', 'A') and not r['is_running']]
        if sa_recs:
            top_recs = sa_recs
        else:
            top_recs = [r for r in recommendations if not r['is_running']][:3]

        other_recs = [r for r in recommendations if r not in top_recs]

        availability_info = None
        if availability:
            availability_info = {
                'fetched_at': datetime.now(JST).strftime('%H:%M'),
                'empty_count': sum(1 for v in availability.values() if v == 'ç©ºã'),
                'playing_count': sum(1 for v in availability.values() if v == 'éŠæŠ€ä¸­'),
            }

        # åº—èˆ—åˆ†æï¼ˆrecommend_unitsã®è¨ˆç®—çµæœã‹ã‚‰ãƒ©ãƒ³ã‚¯åˆ†å¸ƒã‚’ç”Ÿæˆï¼‰
        daily_data = load_daily_data(machine_key=machine_key)
        store_analysis = generate_store_analysis(store_key, daily_data)

        # ãƒ©ãƒ³ã‚¯åˆ†å¸ƒã‚’recommend_unitsã®çµæœã§ä¸Šæ›¸ãï¼ˆç›¸å¯¾è©•ä¾¡ã®çµæœã‚’æ­£ç¢ºã«åæ˜ ï¼‰
        all_recs_for_analysis = top_recs + other_recs
        if all_recs_for_analysis:
            from collections import Counter
            rank_counts = Counter(r['final_rank'] for r in all_recs_for_analysis)
            rank_parts = []
            for rank in ['S', 'A', 'B', 'C', 'D']:
                count = rank_counts.get(rank, 0)
                if count > 0:
                    rank_parts.append(f"{rank}:{count}å°")
            store_analysis['rank_dist'] = " / ".join(rank_parts)
            high_count = rank_counts.get('S', 0) + rank_counts.get('A', 0)
            total = len(all_recs_for_analysis)
            store_analysis['high_count'] = high_count
            store_analysis['total_units'] = total
            high_ratio = high_count / total * 100 if total > 0 else 0
            if high_ratio >= 70:
                store_analysis['overall'] = f"é«˜è¨­å®šå°ãŒéå¸¸ã«å¤šã„ï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
            elif high_ratio >= 50:
                store_analysis['overall'] = f"é«˜è¨­å®šå°ãŒå¤šã„ï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
            elif high_ratio >= 30:
                store_analysis['overall'] = f"é«˜è¨­å®šå°ã‚ã‚Šï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
            else:
                store_analysis['overall'] = f"é«˜è¨­å®šå°ãŒå°‘ãªã„ï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"

        # å°ç•ªå·ã‚¢ãƒ©ãƒ¼ãƒˆ
        store_alerts = [a for a in get_active_alerts() if a.get('store_key') == store_key]

        html = template.render(
            store=store,
            store_key=store_key,
            machine=machine,
            machine_key=machine_key,
            top_recs=top_recs,
            other_recs=other_recs,
            updated_at=datetime.now(JST).strftime('%H:%M'),
            cache_info=cache_info,
            availability_info=availability_info,
            is_open=is_open,
            display_mode=display_mode,
            store_analysis=store_analysis,
            unit_alerts=store_alerts,
        )

        output_path = output_subdir / f'{store_key}.html'
        output_path.write_text(html, encoding='utf-8')

    print(f"  -> {output_subdir}/")


def _process_history_for_verify(history):
    """å½“ãŸã‚Šå±¥æ­´ã‚’ç­”ãˆåˆã‚ã›è¡¨ç¤ºç”¨ã«åŠ å·¥ã™ã‚‹

    - æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
    - ãƒã‚§ãƒ¼ãƒ³ï¼ˆé€£ãƒãƒ£ãƒ³ï¼‰ã‚’è¨ˆç®—
    - æ·±ã„ãƒãƒã‚Šãƒ»æµ…ã„å½“ãŸã‚Šã®ãƒ•ãƒ©ã‚°ã‚’ä»˜ä¸
    """
    from analysis.analyzer import is_big_hit, RENCHAIN_THRESHOLD

    if not history:
        return [], {}

    # æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_hist = sorted(history, key=lambda x: x.get('time', '00:00'))

    # ãƒã‚§ãƒ¼ãƒ³è¨ˆç®—: ATé–“ã®Gæ•°ã‚’è“„ç©ã—ã€é–¾å€¤ä»¥ä¸‹ãªã‚‰é€£ãƒãƒ£ãƒ³
    processed = []
    chain_id = 0
    chain_hits = []  # ç¾åœ¨ã®ãƒã‚§ãƒ¼ãƒ³å†…ã®ãƒ’ãƒƒãƒˆ
    accumulated_games = 0  # RBã‚’è·¨ã„ã ATé–“Gæ•°

    for i, hit in enumerate(sorted_hist):
        start = hit.get('start', 0)
        hit_type = hit.get('type', 'ART')
        medals = hit.get('medals', 0)
        time_str = hit.get('time', '')

        accumulated_games += start

        entry = {
            'index': i + 1,
            'time': time_str,
            'start': start,
            'type': hit_type,
            'medals': medals,
            'is_deep': start >= 500,
            'is_shallow': start <= 10 and i > 0,
            'is_tenjou': start >= 800,
        }

        if is_big_hit(hit_type):
            if i == 0 or accumulated_games > RENCHAIN_THRESHOLD:
                # æ–°ã—ã„ãƒã‚§ãƒ¼ãƒ³é–‹å§‹
                if chain_hits:
                    chain_len = len(chain_hits)
                    for ch in chain_hits:
                        ch['chain_len'] = chain_len
                chain_id += 1
                chain_hits = [entry]
            else:
                # é€£ãƒãƒ£ãƒ³ç¶™ç¶š
                chain_hits.append(entry)

            entry['chain_id'] = chain_id
            entry['is_hot_chain'] = False  # å¾Œã§æ›´æ–°
            accumulated_games = 0  # ATé–“ãƒªã‚»ãƒƒãƒˆ
        else:
            # RB: ãƒã‚§ãƒ¼ãƒ³ã«å«ã‚ãªã„ï¼ˆATé–“ã¯ç¶™ç¶šï¼‰
            entry['chain_id'] = 0
            entry['chain_len'] = 0
            entry['is_hot_chain'] = False

        processed.append(entry)

    # æœ€å¾Œã®ãƒã‚§ãƒ¼ãƒ³ã‚’å‡¦ç†
    if chain_hits:
        chain_len = len(chain_hits)
        for idx, ch in enumerate(chain_hits):
            ch['chain_len'] = chain_len
            ch['chain_pos'] = idx + 1  # 1é€£ç›®, 2é€£ç›®, ...

    # å…¨ã¦ã®ãƒã‚§ãƒ¼ãƒ³ã«chain_posã‚’ä»˜ä¸ï¼ˆæœ€å¾Œã®ãƒã‚§ãƒ¼ãƒ³ä»¥å¤–ã¯æ—¢ã«ãƒ«ãƒ¼ãƒ—å†…ã§å‡¦ç†æ¸ˆã¿ï¼‰
    # â†’ ä¸Šã®ãƒ«ãƒ¼ãƒ—å†…ã§å‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ä¿®æ­£:
    # chain_hitsã®å‡¦ç†ã‚’å†èµ°æŸ»ã—ã¦å…¨ãƒã‚§ãƒ¼ãƒ³ã«chain_posã‚’ä»˜ä¸
    current_chain_id = 0
    pos = 0
    for entry in processed:
        cid = entry.get('chain_id', 0)
        if cid > 0:
            if cid != current_chain_id:
                current_chain_id = cid
                pos = 1
            else:
                pos += 1
            entry['chain_pos'] = pos
        else:
            entry['chain_pos'] = 0

    # ãƒ›ãƒƒãƒˆãƒã‚§ãƒ¼ãƒ³(5é€£ä»¥ä¸Š)ã«ãƒ•ãƒ©ã‚°ä»˜ä¸
    for entry in processed:
        if entry.get('chain_len', 0) >= 5:
            entry['is_hot_chain'] = True

    # ã‚µãƒãƒªãƒ¼è¨ˆç®—
    starts = [h.get('start', 0) for h in sorted_hist]
    big_hit_starts = []
    acc = 0
    for hit in sorted_hist:
        acc += hit.get('start', 0)
        if is_big_hit(hit.get('type', '')):
            big_hit_starts.append(acc)
            acc = 0

    total_games = sum(starts)
    total_hits = len(sorted_hist)
    total_medals = sum(h.get('medals', 0) for h in sorted_hist)

    # ATé–“ãƒ™ãƒ¼ã‚¹ã®è°·
    valleys = big_hit_starts if big_hit_starts else starts
    max_valley = max(valleys) if valleys else 0
    avg_valley = int(sum(valleys) / len(valleys)) if valleys else 0
    tenjou_count = sum(1 for v in valleys if v >= 800)

    # æœ€å¤§ãƒã‚§ãƒ¼ãƒ³
    chain_lengths = [e.get('chain_len', 0) for e in processed if e.get('chain_id', 0) > 0]
    # å„ãƒã‚§ãƒ¼ãƒ³ã®é•·ã•ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«å–å¾—
    seen_chains = {}
    for e in processed:
        cid = e.get('chain_id', 0)
        clen = e.get('chain_len', 0)
        if cid > 0 and cid not in seen_chains:
            seen_chains[cid] = clen
    max_chain = max(seen_chains.values()) if seen_chains else 0

    summary = {
        'total_games': total_games,
        'total_hits': total_hits,
        'total_medals': total_medals,
        'max_valley': max_valley,
        'avg_valley': avg_valley,
        'tenjou_count': tenjou_count,
        'max_chain': max_chain,
    }

    return processed, summary


def generate_verify_page(env):
    """ç­”ãˆåˆã‚ã›ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ - äºˆæ¸¬ vs å®Ÿç¸¾ã®æ¯”è¼ƒ"""
    print("Generating verify page...")

    template = env.get_template('verify.html')
    old_keys = {'island_akihabara', 'shibuya_espass', 'shinjuku_espass'}

    verify_data = {}
    total_predicted_good = 0  # äºˆæ¸¬S/Aå°æ•°
    total_actual_good = 0     # äºˆæ¸¬S/Aã®ã†ã¡å®Ÿéš›ã«å¥½èª¿ã ã£ãŸå°æ•°
    total_surprise = 0        # äºˆæ¸¬Bä»¥ä¸‹ã ãŒå®Ÿéš›ã«å¥½èª¿ã ã£ãŸå°æ•°

    for machine_key, machine in MACHINES.items():
        stores_data = []
        stores = get_stores_by_machine(machine_key)

        # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆå½“ãŸã‚Šå±¥æ­´å–å¾—ç”¨ï¼‰
        daily_data = load_daily_data(machine_key=machine_key)
        daily_stores = daily_data.get('stores', {}) if daily_data else {}

        for store_key, store in stores.items():
            if store_key in old_keys:
                continue

            # 2ç¨®é¡ã®äºˆæ¸¬ã‚’å–å¾—
            # (1) é–‹åº—å‰äºˆæ¸¬: éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªã—ï¼‰
            # (2) ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬: å½“æ—¥ãƒ‡ãƒ¼ã‚¿è¾¼ã¿
            availability = {}
            realtime = None
            try:
                availability = get_availability(store_key)
                realtime = get_realtime_data(store_key)
            except:
                pass

            # é–‹åº—å‰äºˆæ¸¬ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
            pre_open_recs = recommend_units(store_key, availability=availability)
            pre_open_map = {}
            for r in pre_open_recs:
                pre_open_map[str(r.get('unit_id', ''))] = {
                    'rank': r.get('final_rank', 'C'),
                    'score': r.get('final_score', 50),
                }

            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ï¼ˆå½“æ—¥ãƒ‡ãƒ¼ã‚¿è¾¼ã¿ï¼‰
            recommendations = recommend_units(store_key, realtime_data=realtime, availability=availability)
            units_data = []

            # ã“ã®åº—èˆ—ã®æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¦ãƒ‹ãƒƒãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆ
            store_daily = daily_stores.get(store_key, {})
            daily_units_map = {}
            for u in store_daily.get('units', []):
                daily_units_map[str(u.get('unit_id', ''))] = u

            for rec in recommendations:
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ï¼ˆå½“æ—¥ãƒ‡ãƒ¼ã‚¿è¾¼ã¿ï¼‰
                predicted_rank = rec.get('final_rank', 'C')
                predicted_score = rec.get('final_score', 50)

                # é–‰åº—å¾Œã¯å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿç¸¾ã¨ã—ã¦ä½¿ã†
                actual_art = rec.get('art_count', 0)
                actual_games = rec.get('total_games', 0)
                actual_prob = rec.get('art_prob', 0)
                if actual_art == 0 and not is_business_hours():
                    actual_art = rec.get('yesterday_art', 0)
                    actual_games = rec.get('yesterday_games', 0)
                    if actual_art > 0 and actual_games > 0:
                        actual_prob = actual_games / actual_art
                    else:
                        actual_prob = 0

                # é–‹åº—å‰äºˆæ¸¬ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
                uid = str(rec.get('unit_id', ''))
                pre_open = pre_open_map.get(uid, {})
                pre_open_rank = pre_open.get('rank', 'C')
                pre_open_score = pre_open.get('score', 50)

                # åˆ¤å®š
                is_predicted_good = predicted_rank in ('S', 'A')
                is_actual_good = actual_prob > 0 and actual_prob <= 130
                is_actual_excellent = actual_prob > 0 and actual_prob <= 100
                is_actual_bad = actual_prob >= 200 or (actual_games >= 1000 and actual_art == 0)

                if is_predicted_good:
                    total_predicted_good += 1
                    if is_actual_excellent:
                        verdict = '\u25CE'  # â—
                        verdict_class = 'perfect'
                        total_actual_good += 1
                    elif is_actual_good:
                        verdict = '\u25CB'  # â—‹
                        verdict_class = 'hit'
                        total_actual_good += 1
                    elif is_actual_bad:
                        verdict = '\u2715'  # âœ•
                        verdict_class = 'miss'
                    else:
                        verdict = '\u25B3'  # â–³
                        verdict_class = 'neutral'
                elif not is_predicted_good and is_actual_good:
                    verdict = '\u2605'  # â˜… ç™ºæ˜
                    verdict_class = 'surprise'
                    total_surprise += 1
                elif actual_games < 500:
                    verdict = '-'
                    verdict_class = 'nodata'
                else:
                    verdict = '\u25B3'  # â–³
                    verdict_class = 'neutral'

                # å½“ãŸã‚Šå±¥æ­´ã‚’å–å¾—
                unit_daily = daily_units_map.get(str(rec.get('unit_id', '')), {})
                days = unit_daily.get('days', [])
                today_history_raw = []
                history_date = ''
                if days:
                    # æœ€æ–°ã®æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                    today_data = days[0]
                    today_history_raw = today_data.get('history', [])
                    history_date = today_data.get('date', '')

                processed_history, history_summary = _process_history_for_verify(today_history_raw)

                units_data.append({
                    'unit_id': rec.get('unit_id', ''),
                    'predicted_rank': predicted_rank,
                    'predicted_score': predicted_score,
                    'pre_open_rank': pre_open_rank,
                    'pre_open_score': pre_open_score,
                    'actual_art': actual_art,
                    'actual_prob': actual_prob,
                    'actual_games': actual_games,
                    'verdict': verdict,
                    'verdict_class': verdict_class,
                    'history': processed_history,
                    'history_summary': history_summary,
                    'history_date': history_date,
                })

            if units_data:
                # åº—èˆ—åˆ¥çš„ä¸­ç‡ï¼ˆé–‹åº—å‰äºˆæ¸¬ãƒ™ãƒ¼ã‚¹ï¼‰
                store_sa_total = sum(1 for u in units_data if u['pre_open_rank'] in ('S', 'A'))
                store_sa_hit = sum(1 for u in units_data if u['pre_open_rank'] in ('S', 'A') and u.get('actual_prob', 0) > 0 and u['actual_prob'] <= 130)
                store_sa_rate = (store_sa_hit / store_sa_total * 100) if store_sa_total > 0 else 0
                stores_data.append({
                    'name': store.get('name', store_key),
                    'units': units_data,
                    'sa_total': store_sa_total,
                    'sa_hit': store_sa_hit,
                    'sa_rate': store_sa_rate,
                })

        if stores_data:
            verify_data[machine_key] = {
                'name': machine['short_name'],
                'icon': machine['icon'],
                'stores': stores_data,
            }

    # çš„ä¸­ç‡è¨ˆç®—
    accuracy = 0
    if total_predicted_good > 0:
        accuracy = (total_actual_good / total_predicted_good) * 100

    # æ©Ÿç¨®åˆ¥ã®çš„ä¸­ç‡ï¼ˆé–‹åº—å‰äºˆæ¸¬ãƒ™ãƒ¼ã‚¹ï¼‰
    machine_accuracy = []
    for machine_key, machine_data in verify_data.items():
        m_predicted = 0
        m_actual = 0
        m_surprise = 0
        for store in machine_data.get('stores', []):
            for unit in store.get('units', []):
                is_sa = unit['pre_open_rank'] in ('S', 'A')
                prob = unit.get('actual_prob', 0)
                is_good = prob > 0 and prob <= 130
                if is_sa:
                    m_predicted += 1
                    if is_good:
                        m_actual += 1
                elif not is_sa and is_good:
                    m_surprise += 1
        rate = (m_actual / m_predicted * 100) if m_predicted > 0 else 0
        machine_accuracy.append({
            'name': machine_data['name'],
            'icon': machine_data['icon'],
            'total': m_predicted,
            'hit': m_actual,
            'rate': rate,
            'surprise': m_surprise,
        })

    html = template.render(
        verify_data=verify_data,
        accuracy=accuracy,
        predicted_good=total_predicted_good,
        actual_good=total_actual_good,
        surprise_good=total_surprise,
        machine_accuracy=machine_accuracy,
    )

    output_path = OUTPUT_DIR / 'verify.html'
    output_path.write_text(html, encoding='utf-8')
    print(f"  -> {output_path}")


def copy_static_files():
    """é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼"""
    print("Copying static files...")

    import shutil

    static_src = PROJECT_ROOT / 'web' / 'static'
    static_dst = OUTPUT_DIR / 'static'

    if static_dst.exists():
        shutil.rmtree(static_dst)

    shutil.copytree(static_src, static_dst)
    print(f"  -> {static_dst}/")


def generate_metadata():
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    print("Generating metadata...")

    metadata = {
        'generated_at': datetime.now(JST).isoformat(),
        'version': '2026-01-27-static',
    }

    output_path = OUTPUT_DIR / 'metadata.json'
    output_path.write_text(json.dumps(metadata, ensure_ascii=False, indent=2), encoding='utf-8')
    print(f"  -> {output_path}")


def run_unit_verification():
    """å°ç•ªå·æ¤œè¨¼ã‚’å®Ÿè¡Œã—ã€ã‚¢ãƒ©ãƒ¼ãƒˆãŒã‚ã‚Œã°ä¿å­˜"""
    print("Running unit verification...")
    try:
        from scripts.verify_units import verify_units_from_availability, save_alerts, print_report
        avail_path = PROJECT_ROOT / 'data' / 'availability.json'
        if avail_path.exists():
            with open(avail_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            alerts = verify_units_from_availability(data)
            print_report(alerts)
            if alerts:
                save_alerts(alerts, source='availability')
        else:
            print("  availability.json not found, skipping")
    except Exception as e:
        print(f"  Verification error: {e}")


def run_data_integrity_check():
    """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå…¨åº—èˆ—ã®ART/ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ æç­‰ï¼‰"""
    print("Running data integrity check...")
    try:
        from scripts.verify_units import verify_data_integrity, print_integrity_report
        avail_path = PROJECT_ROOT / 'data' / 'availability.json'
        if avail_path.exists():
            with open(avail_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            issues = verify_data_integrity(data)
            print_integrity_report(issues)
        else:
            print("  availability.json not found, skipping")
    except Exception as e:
        print(f"  Integrity check error: {e}")


def main():
    print("=" * 50)
    print("é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆé–‹å§‹")
    print(f"å‡ºåŠ›å…ˆ: {OUTPUT_DIR}")
    print("=" * 50)
    print()

    # å°ç•ªå·æ¤œè¨¼ï¼ˆã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆï¼‰
    run_unit_verification()

    # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    run_data_integrity_check()

    # æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿è“„ç©ï¼ˆhistory DBæ›´æ–°ï¼‰
    try:
        from analysis.history_accumulator import accumulate_from_daily
        for mk in MACHINES:
            daily = load_daily_data(machine_key=mk)
            if daily:
                result = accumulate_from_daily(daily, mk)
                if result['new_entries'] > 0:
                    print(f"  ğŸ“¦ {mk}: {result['new_entries']}ä»¶è“„ç© ({result['updated_units']}å°)")
    except Exception as e:
        print(f"  âš  è“„ç©ã‚¨ãƒ©ãƒ¼: {e}")
    print()

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # Jinja2ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    env = setup_jinja()

    # å„ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ
    generate_index(env)
    generate_machine_pages(env)
    generate_ranking_pages(env)
    generate_recommend_pages(env)
    generate_verify_page(env)
    copy_static_files()
    generate_metadata()

    print()
    print("=" * 50)
    print("é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆå®Œäº†!")
    print("=" * 50)


if __name__ == '__main__':
    main()
