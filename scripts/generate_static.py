#!/usr/bin/env python3
"""
é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Cloudflare Pagesç”¨ã«é™çš„HTMLã‚’ç”Ÿæˆã™ã‚‹
GitHub Actionsã§å®šæœŸå®Ÿè¡Œã—ã€ç”Ÿæˆã—ãŸHTMLã‚’ãƒ‡ãƒ—ãƒ­ã‚¤
"""

import json
import os
import sys
from datetime import datetime, timezone, timedelta
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from jinja2 import Environment, FileSystemLoader
from config.rankings import STORES, MACHINES, get_stores_by_machine, get_machine_info
from analysis.recommender import recommend_units, load_daily_data, generate_store_analysis, calculate_expected_profit, analyze_today_graph, calculate_at_intervals
from analysis.analyzer import calculate_first_hits, mark_first_hits
from scrapers.availability_checker import get_availability, get_realtime_data
from scripts.verify_units import get_active_alerts, get_unit_status

JST = timezone(timedelta(hours=9))
WEEKDAY_NAMES = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUTPUT_DIR = PROJECT_ROOT / 'docs'  # GitHub Pagesäº’æ›


def get_display_mode():
    """ç¾åœ¨æ™‚åˆ»ã‹ã‚‰è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ã‚’æ±ºå®š
    - before_open: 0:00-9:59ï¼ˆå–¶æ¥­å‰ï¼‰
    - after_close: 22:50-23:59ï¼ˆé–‰åº—å¾Œï¼‰
    - realtime: 10:00-22:49ï¼ˆå–¶æ¥­ä¸­ï¼‰
    """
    now = datetime.now(JST)
    hour = now.hour
    minute = now.minute

    if hour < 10:
        return 'before_open'
    elif hour >= 23 or (hour == 22 and minute >= 50):
        return 'after_close'
    else:
        return 'realtime'


def format_date_with_weekday(dt):
    """æ—¥ä»˜ã‚’æ›œæ—¥ä»˜ãã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    weekday = WEEKDAY_NAMES[dt.weekday()]
    return f"{dt.month}æœˆ{dt.day}æ—¥({weekday})"


def is_business_hours():
    """å–¶æ¥­æ™‚é–“å†…ã‹ã©ã†ã‹"""
    return get_display_mode() == 'realtime'


def rank_color(rank):
    """ãƒ©ãƒ³ã‚¯è‰²ã‚’è¿”ã™"""
    colors = {
        'S': '#ff6b6b',
        'A': '#ffa502',
        'B': '#2ed573',
        'C': '#70a1ff',
        'D': '#747d8c',
    }
    return colors.get(rank, '#747d8c')


def signed_number(value):
    """ç¬¦å·ä»˜ãã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ•°å€¤"""
    try:
        num = int(value)
        if num >= 0:
            return f'+{num:,}'
        else:
            return f'{num:,}'
    except (ValueError, TypeError):
        return str(value)


def medals_badge(value):
    """æœ€å¤§ç²å¾—æšæ•°ãƒãƒƒã‚¸"""
    try:
        num = int(value)
        if num >= 10000:
            return {'class': 'medals-10k', 'icon': 'ğŸ”¥', 'label': '1ä¸‡æšOVER'}
        elif num >= 5000:
            return {'class': 'medals-5k', 'icon': 'ğŸ’°', 'label': '5åƒæšOVER'}
        elif num >= 3000:
            return {'class': 'medals-3k', 'icon': 'âœ¨', 'label': '3åƒæšOVER'}
        elif num >= 2000:
            return {'class': 'medals-2k', 'icon': 'â­', 'label': '2åƒæšOVER'}
        elif num >= 1000:
            return {'class': 'medals-1k', 'icon': 'ğŸ‘', 'label': '1åƒæšOVER'}
        return None
    except (ValueError, TypeError):
        return None


def setup_jinja():
    """Jinja2ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    template_dir = PROJECT_ROOT / 'web' / 'templates'
    env = Environment(loader=FileSystemLoader(str(template_dir)))

    # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ«ã‚¿ãƒ»é–¢æ•°ã‚’è¿½åŠ 
    env.globals['rank_color'] = rank_color
    env.globals['signed_number'] = signed_number
    env.globals['medals_badge'] = medals_badge
    env.globals['url_for'] = lambda endpoint, **kwargs: generate_url(endpoint, **kwargs)

    def pad_unit_id(uid):
        """å°ç•ªå·ã‚’4æ¡ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆ1â†’0001, 23â†’0023, 0752â†’0752ï¼‰"""
        s = str(uid)
        if s.isdigit() and len(s) < 4:
            return s.zfill(4)
        return s
    env.filters['pad_id'] = pad_unit_id
    env.globals['pad_id'] = pad_unit_id
    env.globals['build_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    def generate_sparkline(history, width=120, height=40, diff_medals=None):
        """å½“ãŸã‚Šå±¥æ­´ã‹ã‚‰å·®æšæ¨ç§»ã®SVGã‚¹ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆ

        Args:
            history: å½“ãŸã‚Šå±¥æ­´ãƒªã‚¹ãƒˆ
            diff_medals: æ—¢çŸ¥ã®æœ€çµ‚å·®æšï¼ˆæ­£è¦åŒ–ã«ä½¿ç”¨ï¼‰
        """
        if not history or len(history) < 2:
            return ''
        # hit_numé™é †ï¼ˆå¤§ãã„=å¤ã„ï¼‰ã§ã‚½ãƒ¼ãƒˆ
        sorted_hist = sorted(history, key=lambda x: (-x.get('hit_num', 0), x.get('time', '00:00')))
        # å„å½“ãŸã‚Šã®ãƒ¡ãƒ€ãƒ«ç²å¾—æ•°ã§ç›¸å¯¾æ¨ç§»ã‚’è¨ˆç®—
        # medals: ãƒœãƒ¼ãƒŠã‚¹/ATç²å¾—æšæ•°ã€start: å½“ãŸã‚Šé–“ã®æ¶ˆåŒ–Gæ•°
        cumulative = [0]
        total = 0
        for h in sorted_hist:
            medals = h.get('medals', 0)
            start = h.get('start', 0)
            total -= start * 3  # å½“ãŸã‚Šé–“ã®æŠ•å…¥
            total += medals      # ç²å¾—
            cumulative.append(total)

        # æ—¢çŸ¥ã®å·®æšãŒã‚ã‚Œã°æ­£è¦åŒ–ï¼ˆæ¨ç§»ã®å½¢ã¯ä¿ã¡ã€æœ€çµ‚å€¤ã‚’åˆã‚ã›ã‚‹ï¼‰
        if diff_medals is not None and total != 0:
            scale = diff_medals / total
            cumulative = [v * scale for v in cumulative]
        elif diff_medals is not None and total == 0:
            # ç´¯ç©0ã ãŒå·®æšãŒã‚ã‚‹å ´åˆã€æ¨ç§»ãŒæã‘ãªã„ã®ã§ã‚¹ã‚­ãƒƒãƒ—
            pass
        if len(cumulative) < 2:
            return ''
        min_v = min(cumulative)
        max_v = max(cumulative)
        v_range = max_v - min_v if max_v != min_v else 1
        # SVGãƒã‚¤ãƒ³ãƒˆç”Ÿæˆ
        points = []
        for i, v in enumerate(cumulative):
            x = i / (len(cumulative) - 1) * width
            y = height - ((v - min_v) / v_range * (height - 4)) - 2
            points.append(f'{x:.1f},{y:.1f}')
        polyline = ' '.join(points)
        # ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³
        zero_y = height - ((0 - min_v) / v_range * (height - 4)) - 2
        # è‰²: æœ€çµ‚å€¤ãŒãƒ—ãƒ©ã‚¹ãªã‚‰ç·‘ã€ãƒã‚¤ãƒŠã‚¹ãªã‚‰èµ¤ï¼ˆæ­£è¦åŒ–å¾Œã®å€¤ã§åˆ¤å®šï¼‰
        final_val = cumulative[-1] if cumulative else total
        color = '#2ed573' if final_val >= 0 else '#ff6b6b'
        return f'<svg class="sparkline" width="{width}" height="{height}" viewBox="0 0 {width} {height}"><line x1="0" y1="{zero_y:.1f}" x2="{width}" y2="{zero_y:.1f}" stroke="#555" stroke-width="0.5" stroke-dasharray="2,2"/><polyline points="{polyline}" fill="none" stroke="{color}" stroke-width="1.5"/></svg>'
    env.globals['sparkline'] = generate_sparkline

    def format_short_date(date_str):
        """'2026-01-26' â†’ '1/26(æœˆ)'"""
        if not date_str:
            return ''
        try:
            dt = datetime.strptime(str(date_str), '%Y-%m-%d')
            return f"{dt.month}/{dt.day}({WEEKDAY_NAMES[dt.weekday()]})"
        except:
            return str(date_str)
    env.globals['short_date'] = format_short_date

    return env


def generate_url(endpoint, **kwargs):
    """é™çš„ã‚µã‚¤ãƒˆç”¨ã®URLç”Ÿæˆï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ï¼‰"""
    if endpoint == 'index':
        return '/index.html'
    elif endpoint == 'static':
        return f"/static/{kwargs.get('filename', '')}"
    elif endpoint == 'recommend':
        return f"/recommend/{kwargs.get('store_key', '')}.html"
    elif endpoint == 'machine_stores':
        return f"/machine/{kwargs.get('machine_key', '')}.html"
    elif endpoint == 'ranking':
        return f"/ranking/{kwargs.get('machine_key', '')}.html"
    elif endpoint == 'rules':
        return '/rules.html'
    elif endpoint == 'unit_history':
        return f"/history/{kwargs.get('store_key', '')}_{kwargs.get('unit_id', '')}.html"
    elif endpoint == 'api_status':
        return f"https://autogmail.pythonanywhere.com/api/status/{kwargs.get('store_key', '')}"
    elif endpoint == 'verify':
        return '/verify.html'
    return '#'


def generate_index(env):
    """ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating index.html...")

    template = env.get_template('index.html')

    now = datetime.now(JST)
    display_mode = get_display_mode()
    is_open = is_business_hours()
    # æ›œæ—¥å‚¾å‘ã¯å¸¸ã«ã€Œæ¬¡ã«é–‹åº—ã™ã‚‹æ—¥ã€ã®æ›œæ—¥
    # 22:45ã€œ23:59ã¯ç¿Œæ—¥ã€0:00ã€œ09:59ã¯ãã®æ—¥ï¼ˆæ—¢ã«æ—¥ä»˜ãŒå¤‰ã‚ã£ã¦ã„ã‚‹ï¼‰
    if is_open:
        today_weekday = WEEKDAY_NAMES[now.weekday()]
    elif now.hour >= 22:
        # 22:45ã€œ23:59 â†’ ç¿Œæ—¥ã®æ›œæ—¥
        tomorrow_dt = now + timedelta(days=1)
        today_weekday = WEEKDAY_NAMES[tomorrow_dt.weekday()]
    else:
        # 0:00ã€œ09:59 â†’ ä»Šæ—¥ã®æ›œæ—¥ï¼ˆæ—¥ä»˜ã¯æ—¢ã«å¤‰ã‚ã£ã¦ã„ã‚‹ï¼‰
        today_weekday = WEEKDAY_NAMES[now.weekday()]
    today_date = now.strftime('%Y/%m/%d')
    today_date_formatted = format_date_with_weekday(now)

    # ç†ç”±æ–‡ã®æ—¥ä»˜ãƒ©ãƒ™ãƒ«
    reason_data_label, reason_prev_label = get_reason_date_labels()

    # åº—èˆ—æ›œæ—¥å‚¾å‘ï¼ˆç‰©ç†åº—èˆ—ãƒ™ãƒ¼ã‚¹ï¼‰
    store_day_ratings = {
        'island_akihabara': {
            'name': 'ã‚¢ã‚¤ãƒ©ãƒ³ãƒ‰ç§‹è‘‰åŸ',
            'short_name': 'ã‚¢ã‚¤ãƒ©ãƒ³ãƒ‰ç§‹è‘‰åŸ',
            'day_ratings': {'æœˆ': 4, 'ç«': 3, 'æ°´': 5, 'æœ¨': 3, 'é‡‘': 3, 'åœŸ': 1, 'æ—¥': 4},
            'best_note': 'æ°´æ›œãŒæœ€å¼·ã€æ—¥æœˆã‚‚ç‹™ã„ç›®',
            'worst_note': 'åœŸæ›œã¯é¿ã‘ã‚‹ã¹ã',
            'overall_rating': 4,
            'machine_links': [
                {'store_key': 'island_akihabara_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'island_akihabara_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'shibuya_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“æ¸‹è°·æ–°é¤¨',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ¸‹è°·æ–°é¤¨',
            'day_ratings': {'æœˆ': 3, 'ç«': 4, 'æ°´': 4, 'æœ¨': 5, 'é‡‘': 3, 'åœŸ': 3, 'æ—¥': 1},
            'best_note': 'æœ¨æ›œãŒæœ€å¼·ã€ç«æ°´ã‚‚ç‹™ã„ç›®',
            'worst_note': 'æ—¥æ›œã¯é¿ã‘ã‚‹ã¹ã',
            'overall_rating': 3,
            'machine_links': [
                {'store_key': 'shibuya_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'shibuya_espass_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'shinjuku_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“æ–°å®¿æ­Œèˆä¼ç”ºåº—',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ­Œèˆä¼ç”º',
            'day_ratings': {'æœˆ': 2, 'ç«': 3, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 5, 'æ—¥': 3},
            'best_note': 'åœŸæ›œãŒæœ€å¼·ã€é‡‘æ›œã‚‚ç‹™ã„ç›®',
            'worst_note': 'æœˆæ›œã¯æ§ãˆã‚',
            'overall_rating': 3,
            'machine_links': [
                {'store_key': 'shinjuku_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'shinjuku_espass_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'akiba_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“ç§‹è‘‰åŸé§…å‰åº—',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹ç§‹è‘‰åŸ',
            'day_ratings': {'æœˆ': 2, 'ç«': 3, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 5, 'æ—¥': 4},
            'best_note': 'åœŸæ—¥ãŒç‹™ã„ç›®ã€é‡‘æ›œã‚‚å¯',
            'worst_note': 'æœˆæ›œã¯æ§ãˆã‚',
            'overall_rating': 3,
            'machine_links': [
                {'store_key': 'akiba_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
                {'store_key': 'akiba_espass_hokuto', 'icon': 'ğŸ‘Š', 'short_name': 'åŒ—æ–—è»¢ç”Ÿ2'},
            ],
        },
        'seibu_shinjuku_espass': {
            'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“è¥¿æ­¦æ–°å®¿é§…å‰åº—',
            'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹è¥¿æ­¦æ–°å®¿',
            'day_ratings': {'æœˆ': 2, 'ç«': 2, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 4, 'æ—¥': 3},
            'best_note': 'é‡‘åœŸãŒç‹™ã„ç›®',
            'worst_note': 'æœˆç«ã¯æ§ãˆã‚',
            'overall_rating': 2,
            'machine_links': [
                {'store_key': 'seibu_shinjuku_espass_sbj', 'icon': 'ğŸƒ', 'short_name': 'SBJ'},
            ],
        },
    }

    # æ©Ÿç¨®ä¸€è¦§ã¨ãƒˆãƒƒãƒ—å°ã‚’åé›†
    machines = []
    top3_all = []
    yesterday_top10 = []
    today_top10 = []

    for key, machine in MACHINES.items():
        stores = get_stores_by_machine(key)
        total_units = sum(len(s['units']) for s in stores.values())
        machines.append({
            'key': key,
            'name': machine['name'],
            'short_name': machine['short_name'],
            'icon': machine['icon'],
            'store_count': len(stores),
            'unit_count': total_units,
        })

        for store_key, store in stores.items():
            try:
                availability = {}
                try:
                    availability = get_availability(store_key)
                except:
                    pass

                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæœ¬æ—¥ã®ART/RBç­‰ï¼‰
                realtime = None
                try:
                    realtime = get_realtime_data(store_key)
                except:
                    pass

                recs = recommend_units(store_key, realtime_data=realtime, availability=availability,
                                      data_date_label=reason_data_label, prev_date_label=reason_prev_label)

                # å…¨recsã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä»˜ä¸
                for rec in recs:
                    rec['store_name'] = store.get('short_name', store['name'])
                    rec['store_key'] = store_key
                    rec['machine_key'] = key
                    rec['machine_icon'] = machine['icon']
                    rec['machine_name'] = machine.get('display_name', machine['short_name'])
                    if 'availability' not in rec or rec['availability'] is None:
                        rec['availability'] = availability.get(rec['unit_id'], '')
                    # å·®æšè¨ˆç®—ã¯recommend_unitså†…ã§çµ±åˆæ¸ˆã¿
                    # åˆå½“ãŸã‚Šå›æ•°ã‚’è¨ˆç®—ï¼ˆTOP3è¡¨ç¤ºç”¨ï¼‰
                    _y_hist = rec.get('yesterday_history', [])
                    if _y_hist:
                        rec['first_hit_count'] = calculate_first_hits(_y_hist)['first_hit_count']
                    else:
                        rec['first_hit_count'] = 0

                # TOP3å€™è£œï¼ˆä¸Šä½3å°/åº—èˆ—ï¼‰
                for rec in recs[:3]:
                    top3_all.append(rec)

                # å‰æ—¥ã®çˆ†ç™ºå°ï¼ˆå…¨å°ã‹ã‚‰åé›†ã€yesterday_art > 0ï¼‰
                for rec in recs:
                    y_art = rec.get('yesterday_art', 0)
                    if y_art and y_art > 0:
                        y_games = rec.get('yesterday_games', 0)
                        y_prob = y_games / y_art if y_art > 0 and y_games > 0 else 0
                        # å·®æšè¨ˆç®—ï¼ˆmedalsãƒ™ãƒ¼ã‚¹å„ªå…ˆ â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§æ©Ÿæ¢°å‰²ãƒ™ãƒ¼ã‚¹ï¼‰
                        y_diff_medals = 0
                        y_setting = ''
                        y_setting_num = 0
                        if y_art > 0 and y_games > 0:
                            # è¨­å®šæ¨å®šï¼ˆè¡¨ç¤ºç”¨ï¼‰
                            y_profit = calculate_expected_profit(y_games, y_art, key)
                            y_si = y_profit.get('setting_info', {})
                            y_setting = y_si.get('estimated_setting', '')
                            y_setting_num = y_si.get('setting_num', 0)
                            # å·®æš: historyã®medalsåˆè¨ˆã‹ã‚‰å®Ÿæ¸¬ãƒ™ãƒ¼ã‚¹ã§æ¨å®š
                            try:
                                from analysis.history_accumulator import load_unit_history
                                from analysis.diff_medals_estimator import estimate_diff_medals
                                acc = load_unit_history(store_key, rec['unit_id'])
                                y_date = rec.get('yesterday_date', '')
                                for ad in acc.get('days', []):
                                    if ad.get('date') == y_date:
                                        ad_hist = ad.get('history', [])
                                        ad_games = ad.get('games', ad.get('total_start', 0))
                                        if ad_hist and ad_games > 0:
                                            medals_total = sum(h.get('medals', 0) for h in ad_hist)
                                            y_diff_medals = estimate_diff_medals(medals_total, ad_games, key)
                                        break
                            except Exception:
                                pass
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: medalsãŒå–ã‚Œãªã‘ã‚Œã°æ©Ÿæ¢°å‰²ãƒ™ãƒ¼ã‚¹
                            if y_diff_medals == 0:
                                y_diff_medals = y_profit.get('current_estimate', 0)
                        # é€£ãƒãƒ£ãƒ³ãƒ»å¤©äº•ãƒ»æœ€å¤§ãƒ¡ãƒ€ãƒ«ã‚’è¨ˆç®—
                        y_max_rensa = rec.get('yesterday_max_rensa', 0) or rec.get('today_max_rensa', 0)
                        y_max_medals = rec.get('yesterday_max_medals', 0)
                        y_ceilings = 0
                        hist = rec.get('today_history', [])
                        if hist:
                            try:
                                graph = analyze_today_graph(hist)
                                y_max_rensa = max(y_max_rensa, graph.get('max_rensa', 0))
                                intervals = calculate_at_intervals(hist)
                                y_ceilings = sum(1 for g in intervals if g >= 999)
                                if not y_max_medals:
                                    from analysis.analyzer import calculate_max_chain_medals
                                    y_max_medals = calculate_max_chain_medals(hist)
                            except:
                                pass
                        # è“„ç©DBã‹ã‚‰ã‚‚è£œå®Œ
                        if not y_max_rensa or not y_max_medals:
                            try:
                                from analysis.history_accumulator import load_unit_history
                                from analysis.analyzer import calculate_max_chain_medals as _calc_chain
                                acc_hist = load_unit_history(store_key, rec['unit_id'])
                                y_date = rec.get('yesterday_date', '')
                                for ad in acc_hist.get('days', []):
                                    if ad.get('date') == y_date or (not y_date and ad == acc_hist['days'][-1]):
                                        if not y_max_rensa:
                                            y_max_rensa = ad.get('max_rensa', 0)
                                        if not y_max_medals:
                                            # historyãŒã‚ã‚Œã°é€£ãƒãƒ£ãƒ³ç´¯è¨ˆã§å†è¨ˆç®—
                                            ad_hist = ad.get('history', [])
                                            if ad_hist:
                                                y_max_medals = _calc_chain(ad_hist)
                                            else:
                                                y_max_medals = ad.get('max_medals', 0)
                                        break
                            except:
                                pass
                        # å‰æ—¥ã®äºˆæƒ³ãƒ©ãƒ³ã‚¯ã‚’å–å¾—
                        predicted_rank = rec.get('rank', 'C')
                        predicted_score = rec.get('score', 50)
                        was_predicted_good = predicted_rank in ('S', 'A')
                        # å®Ÿéš›ã®çµæœï¼ˆå¥½èª¿ã ã£ãŸã‹ï¼‰
                        good_threshold = 130 if key == 'sbj' else 330
                        was_actually_good = y_prob > 0 and y_prob <= good_threshold
                        # çš„ä¸­åˆ¤å®š
                        if was_predicted_good and was_actually_good:
                            prediction_result = 'hit'    # äºˆæƒ³â—â†’çµæœâ—
                        elif was_predicted_good and not was_actually_good:
                            prediction_result = 'miss'   # äºˆæƒ³â—â†’çµæœâœ—
                        elif not was_predicted_good and was_actually_good:
                            prediction_result = 'missed'  # è¦‹é€ƒã—ï¼ˆäºˆæƒ³å¤–ã®å¥½èª¿ï¼‰
                        else:
                            prediction_result = 'correct'  # äºˆæƒ³é€šã‚Šä¸èª¿

                        # åˆå½“ãŸã‚Šè¨ˆç®— & å±¥æ­´ãƒãƒ¼ã‚­ãƒ³ã‚°
                        y_hist_raw = rec.get('yesterday_history', [])
                        t_hist_raw = rec.get('today_history', [])
                        y_first_hits = calculate_first_hits(y_hist_raw)
                        y_first_hit_count = y_first_hits['first_hit_count']
                        y_hist_marked = mark_first_hits(y_hist_raw)
                        t_hist_marked = mark_first_hits(t_hist_raw)

                        yesterday_top10.append({
                            'unit_id': rec['unit_id'],
                            'store_name': rec['store_name'],
                            'store_key': store_key,
                            'machine_icon': machine['icon'],
                            'machine_name': machine.get('display_name', machine['short_name']),
                            'yesterday_art': y_art,
                            'yesterday_rb': rec.get('yesterday_rb', 0),
                            'yesterday_games': y_games,
                            'yesterday_max_rensa': y_max_rensa,
                            'yesterday_max_medals': y_max_medals,
                            'yesterday_ceilings': y_ceilings,
                            'yesterday_prob': y_prob,
                            'diff_medals': y_diff_medals,
                            'yesterday_diff_medals': y_diff_medals,
                            'estimated_setting': y_setting,
                            'setting_num': y_setting_num,
                            'predicted_rank': predicted_rank,
                            'predicted_score': predicted_score,
                            'prediction_result': prediction_result,
                            'yesterday_history': y_hist_marked,
                            'today_history': t_hist_marked,
                            'recent_days': rec.get('recent_days', []),
                            'first_hit_count': y_first_hit_count,
                            # å‰ã€…æ—¥ãƒ»3æ—¥å‰ãƒ‡ãƒ¼ã‚¿
                            'day_before_art': rec.get('day_before_art', 0),
                            'day_before_rb': rec.get('day_before_rb', 0),
                            'day_before_games': rec.get('day_before_games', 0),
                            'day_before_date': rec.get('day_before_date', ''),
                            'day_before_diff_medals': rec.get('day_before_diff_medals', 0),
                            'day_before_max_rensa': rec.get('day_before_max_rensa', 0),
                            'day_before_max_medals': rec.get('day_before_max_medals', 0),
                            'three_days_ago_art': rec.get('three_days_ago_art', 0),
                            'three_days_ago_rb': rec.get('three_days_ago_rb', 0),
                            'three_days_ago_games': rec.get('three_days_ago_games', 0),
                            'three_days_ago_date': rec.get('three_days_ago_date', ''),
                            'three_days_ago_diff_medals': rec.get('three_days_ago_diff_medals', 0),
                            'three_days_ago_max_rensa': rec.get('three_days_ago_max_rensa', 0),
                            'three_days_ago_max_medals': rec.get('three_days_ago_max_medals', 0),
                        })

                # æœ¬æ—¥ã®çˆ†ç™ºå°ï¼ˆå…¨å°ã‹ã‚‰åé›†ã€art_count > 0ï¼‰
                for rec in recs:
                    t_art = rec.get('art_count', 0)
                    t_medals = rec.get('max_medals', 0)
                    t_games = rec.get('total_games', 0)
                    if t_art > 0 or t_medals > 0:
                        # å·®æšè¨ˆç®—
                        diff_medals = 0
                        if t_art > 0 and t_games > 0:
                            profit = calculate_expected_profit(t_games, t_art, key)
                            diff_medals = profit.get('current_estimate', 0)
                        # åˆå½“ãŸã‚Šè¨ˆç®—
                        t_hist_raw2 = rec.get('today_history', [])
                        t_first_hits = calculate_first_hits(t_hist_raw2)
                        t_first_hit_count = t_first_hits['first_hit_count']
                        t_hist_marked2 = mark_first_hits(t_hist_raw2)

                        today_top10.append({
                            'unit_id': rec['unit_id'],
                            'store_name': rec['store_name'],
                            'store_key': store_key,
                            'machine_icon': machine['icon'],
                            'machine_name': machine.get('display_name', machine['short_name']),
                            'art_count': t_art,
                            'rb_count': rec.get('rb_count', 0),
                            'total_games': t_games,
                            'max_medals': t_medals,
                            'art_prob': rec.get('art_prob', 0),
                            'availability': rec.get('availability', ''),
                            'estimated_setting': rec.get('estimated_setting', ''),
                            'setting_num': rec.get('setting_num', 0),
                            'payout_estimate': rec.get('payout_estimate', ''),
                            'today_max_rensa': rec.get('today_max_rensa', 0),
                            'diff_medals': diff_medals,
                            'today_history': t_hist_marked2,
                            'first_hit_count': t_first_hit_count,
                        })
            except Exception as e:
                print(f"Error processing {store_key}: {e}")

    # ã‚½ãƒ¼ãƒˆ
    # TOP3: å„æ©Ÿç¨®ã®æœ€å¼·å°ã‚’1å°ãšã¤ + æ®‹ã‚Šæ ã¯å·®æšé †
    # æ©Ÿç¨®é–¢ä¿‚ãªãã€Œå‰æ—¥æœ€ã‚‚ç¨¼ã„ã S/Aå°ã€= é«˜è¨­å®šã®æ®ãˆç½®ãæœŸå¾…
    top3_candidates = [r for r in top3_all if r.get('final_rank') in ('S', 'A')]
    # ã‚¹ã‚³ã‚¢é †ï¼ˆä¿¡é ¼åº¦ãƒ»è©¦è¡Œå›æ•°ã‚’è€ƒæ…®ã—ãŸç·åˆã‚¹ã‚³ã‚¢ï¼‰
    top3_candidates.sort(key=lambda r: -r.get('final_score', 0))

    # å„æ©Ÿç¨®ã‹ã‚‰1å°ãšã¤ç¢ºä¿ + é‡è¤‡å°æ’é™¤
    top3 = []
    seen_machines = set()
    seen_units = set()  # åŒã˜å°ç•ªã®é‡è¤‡æ’é™¤
    for r in top3_candidates:
        mk = r.get('machine_key', '')
        uid = str(r.get('unit_id', ''))
        if mk not in seen_machines and uid not in seen_units:
            top3.append(r)
            seen_machines.add(mk)
            seen_units.add(uid)
        if len(top3) >= len(MACHINES):
            break
    # æ®‹ã‚Šæ ã‚’ã‚¹ã‚³ã‚¢é †ã§åŸ‹ã‚ã‚‹
    for r in top3_candidates:
        uid = str(r.get('unit_id', ''))
        if uid not in seen_units:
            top3.append(r)
            seen_units.add(uid)
        if len(top3) >= 3:
            break
    if not top3:
        top3 = top3_candidates[:3]

    # å‰æ—¥ã®çˆ†ç™ºå°: æœ€å¤§é€£ãƒãƒ£ãƒ³æšæ•°ã§ã‚½ãƒ¼ãƒˆ
    # å·®æšã ã¨ã€Œä¸‡æšå‡ºã—ã¦é£²ã¾ã‚ŒãŸå°ã€ãŒä½ãå‡ºã‚‹ã€‚
    # max_chainï¼ˆ1å›ã®é€£ãƒãƒ£ãƒ³åŒºé–“ã®ç´¯è¨ˆæšæ•°ï¼‰ãªã‚‰çˆ†ç™ºã®ç¬é–“ã‚’æ­£ã—ãè©•ä¾¡ã€‚
    yesterday_top10.sort(key=lambda x: (-x.get('yesterday_max_medals', 0), -x.get('diff_medals', 0)))
    yesterday_top10 = yesterday_top10[:10]

    # æœ¬æ—¥ã®çˆ†ç™ºå°: æœ€å¤§é€£ãƒãƒ£ãƒ³æšæ•°ã§ã‚½ãƒ¼ãƒˆ
    today_top10.sort(key=lambda x: (-x.get('max_medals', 0), -x.get('diff_medals', 0)))
    today_top10 = today_top10[:10]

    # æ›œæ—¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    today_store_ranking = []
    for store_key, info in store_day_ratings.items():
        today_rating = info['day_ratings'].get(today_weekday, 3)
        today_store_ranking.append({
            'store_key': store_key,
            'name': info['name'],
            'short_name': info['short_name'],
            'today_rating': today_rating,
            'best_note': info['best_note'],
            'worst_note': info['worst_note'],
            'overall_rating': info['overall_rating'],
            'day_ratings': info['day_ratings'],
            'machine_links': info.get('machine_links', []),
        })
    today_store_ranking.sort(key=lambda x: -x['today_rating'])

    today_recommended_stores = [s for s in today_store_ranking if s['today_rating'] >= 4]
    today_avoid_stores = [s for s in today_store_ranking if s['today_rating'] <= 2]

    result_date_str = None
    date_prefix = ''  # ã€Œæ˜¨æ—¥ã€orã€Œæœ¬æ—¥ã€
    if display_mode in ('before_open', 'after_close'):
        if now.hour >= 23:
            result_date = now
            date_prefix = 'æœ¬æ—¥'
        elif now.hour < 10:
            result_date = now - timedelta(days=1)
            date_prefix = ''  # æ—¥ä»˜ã ã‘ã§ååˆ†ï¼ˆã€Œæ˜¨æ—¥ã€ã¯å†—é•·ï¼‰
        else:
            result_date = now - timedelta(days=1)
            date_prefix = ''
        result_date_str = format_date_with_weekday(result_date)
    elif is_open:
        date_prefix = 'æœ¬æ—¥'

    # æ¬¡ã®å–¶æ¥­æ—¥ï¼ˆãŠã™ã™ã‚å°ã®å¯¾è±¡æ—¥ï¼‰
    if now.hour >= 22:
        # 22:45ã€œ23:59 â†’ ç¿Œæ—¥
        next_day_dt = now + timedelta(days=1)
        next_day_prefix = 'æ˜æ—¥'
    elif now.hour < 10:
        # 0:00ã€œ9:59 â†’ ä»Šæ—¥
        next_day_dt = now
        next_day_prefix = 'æœ¬æ—¥'
    else:
        # å–¶æ¥­ä¸­ â†’ ä»Šæ—¥
        next_day_dt = now
        next_day_prefix = 'æœ¬æ—¥'
    next_day_str = format_date_with_weekday(next_day_dt)

    # å…¨åº—èˆ—ä¸€è¦§ï¼ˆåº—èˆ—å°ç·šç”¨ï¼‰
    all_stores = []
    for store_key, info in store_day_ratings.items():
        today_rating = info['day_ratings'].get(today_weekday, 3)
        all_stores.append({
            'store_key': store_key,
            'name': info['name'],
            'short_name': info['short_name'],
            'today_rating': today_rating,
            'overall_rating': info['overall_rating'],
            'machine_links': info.get('machine_links', []),
        })
    # ä»Šæ—¥ã®è©•ä¾¡é †ã§ã‚½ãƒ¼ãƒˆ
    all_stores.sort(key=lambda x: (-x['today_rating'], -x['overall_rating']))

    # å…¨åº—èˆ—ãŠã™ã™ã‚ãƒªãƒ³ã‚¯
    recommend_links = []
    for store_key, info in store_day_ratings.items():
        for ml in info.get('machine_links', []):
            link_store_key = ml.get('store_key', store_key)
            _mk = STORES.get(link_store_key, {}).get('machine', 'sbj')
            _machine_display = MACHINES.get(_mk, {}).get('display_name', ml.get('short_name', ''))
            recommend_links.append({
                'store_key': link_store_key,
                'name': info['short_name'],
                'icon': ml.get('icon', ''),
                'machine_name': _machine_display,
            })
    # ä»Šæ—¥ã®è©•ä¾¡é †
    recommend_links.sort(key=lambda x: next(
        (-s['today_rating'] for s in all_stores if any(
            ml.get('store_key') == x['store_key'] for ml in s.get('machine_links', [])
        )), 0
    ))

    night_mode = is_night_mode()
    tomorrow = now + timedelta(days=1)
    tomorrow_str = format_date_with_weekday(tomorrow)
    yesterday = now - timedelta(days=1)
    yesterday_str = format_date_with_weekday(yesterday)

    # ã€Œæœ¬æ—¥ã€ã€Œå‰æ—¥ã€ã‚’æ—¥ä»˜ä»˜ãã«
    # ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ã¯availability.jsonã®fetched_atã‹ã‚‰å–å¾—
    try:
        from scrapers.availability_checker import get_daidata_availability
        avail_data = get_daidata_availability()
        fetched_at = avail_data.get('fetched_at', '')
        if fetched_at:
            data_dt = datetime.fromisoformat(fetched_at)
            data_date_str = format_date_with_weekday(data_dt)
            prev_date_str = format_date_with_weekday(data_dt - timedelta(days=1))
        else:
            data_date_str = format_date_with_weekday(now)
            prev_date_str = format_date_with_weekday(yesterday)
    except:
        data_date_str = format_date_with_weekday(now)
        prev_date_str = format_date_with_weekday(yesterday)

    # æ©Ÿç¨®åˆ¥çš„ä¸­ç‡ï¼ˆãƒ’ãƒ¼ãƒ­ãƒ¼è¡¨ç¤ºç”¨: é«˜ã„é †ã«2ã¤ï¼‰
    accuracy_hero = []
    for machine_key, machine in MACHINES.items():
        stores = get_stores_by_machine(machine_key)
        m_total = 0
        m_hit = 0
        store_results = []  # åº—èˆ—åˆ¥ã®çµæœ
        for store_key, store in stores.items():
            s_total = 0
            s_hit = 0
            try:
                pre_recs = recommend_units(store_key)  # éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿
                rt = get_realtime_data(store_key)
                rt_recs = recommend_units(store_key, realtime_data=rt)
                rt_map = {}
                for r in rt_recs:
                    rt_map[str(r.get('unit_id', ''))] = r
                for r in pre_recs:
                    uid = str(r.get('unit_id', ''))
                    if r.get('final_rank', 'C') in ('S', 'A'):
                        m_total += 1
                        s_total += 1
                        rt_r = rt_map.get(uid, {})
                        art = rt_r.get('art_count', 0)
                        games = rt_r.get('total_games', 0)
                        if art > 0 and games / art <= 130:
                            m_hit += 1
                            s_hit += 1
            except:
                pass
            if s_total > 0:
                s_rate = s_hit / s_total * 100
                short_name = store.get('name', store_key).replace('ã‚¨ã‚¹ãƒ‘ã‚¹æ—¥æ‹“', '').replace('åº—', '')
                store_results.append({'name': short_name, 'rate': s_rate, 'hit': s_hit, 'total': s_total})

        # çš„ä¸­ç‡ãŒé«˜ã„åº—èˆ—ã‚’è¡¨ç¤ºï¼ˆ100%ã®åº—ã¯åå‰ã€ãã‚Œä»¥å¤–ã¯ç‡ï¼‰
        store_results.sort(key=lambda x: -x['rate'])
        top_parts = []
        for sr in store_results[:3]:
            if sr['rate'] >= 100:
                top_parts.append(f"{sr['name']}å…¨çš„ä¸­")
            elif sr['rate'] >= 50:
                top_parts.append(f"{sr['name']}{sr['hit']}/{sr['total']}")
        top_stores = ' / '.join(top_parts) if top_parts else ''

        rate = (m_hit / m_total * 100) if m_total > 0 else 0
        accuracy_hero.append({
            'name': machine['short_name'],
            'icon': machine['icon'],
            'rate': rate,
            'hit': m_hit,
            'total': m_total,
            'top_stores': top_stores,
        })
    # é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
    accuracy_hero.sort(key=lambda x: -x['rate'])

    html = template.render(
        machines=machines,
        top3=top3,
        yesterday_top10=yesterday_top10,
        today_top10=today_top10,
        today_weekday=today_weekday,
        today_date=today_date,
        today_date_formatted=today_date_formatted,
        now_time=now.strftime('%H:%M'),
        now_short=now.strftime('%m%d_%H:%M'),
        store_recommendations={},
        today_recommended_stores=today_recommended_stores,
        today_store_ranking=today_store_ranking,
        today_avoid_stores=today_avoid_stores,
        store_day_ratings=store_day_ratings,
        display_mode=display_mode,
        result_date_str=result_date_str,
        is_open=is_open,
        all_stores=all_stores,
        night_mode=night_mode,
        tomorrow_str=tomorrow_str,
        yesterday_str=yesterday_str,
        data_date_str=data_date_str,
        prev_date_str=prev_date_str,
        accuracy_hero=accuracy_hero,
        date_prefix=date_prefix,
        next_day_prefix=next_day_prefix,
        next_day_str=next_day_str,
        recommend_links=recommend_links,
    )

    output_path = OUTPUT_DIR / 'index.html'
    output_path.write_text(html, encoding='utf-8')
    print(f"  -> {output_path}")


def generate_machine_pages(env):
    """æ©Ÿç¨®åˆ¥åº—èˆ—ä¸€è¦§ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating machine pages...")

    template = env.get_template('stores.html')
    output_subdir = OUTPUT_DIR / 'machine'
    output_subdir.mkdir(parents=True, exist_ok=True)

    for machine_key, machine in MACHINES.items():
        stores = get_stores_by_machine(machine_key)
        store_list = [
            {'key': key, 'name': store['name'], 'unit_count': len(store['units'])}
            for key, store in stores.items()
        ]

        html = template.render(
            machine=machine,
            machine_key=machine_key,
            stores=store_list,
        )

        output_path = output_subdir / f'{machine_key}.html'
        output_path.write_text(html, encoding='utf-8')
        print(f"  -> {output_path}")


def get_reason_date_labels():
    """ç†ç”±æ–‡ã®æ—¥ä»˜ãƒ©ãƒ™ãƒ«ã‚’å–å¾—ï¼ˆé–‰åº—å¾Œã®ã¿æ—¥ä»˜ã«ç½®æ›ï¼‰"""
    if is_business_hours():
        return None, None
    try:
        from scrapers.availability_checker import get_daidata_availability
        avail_data = get_daidata_availability()
        fetched_at = avail_data.get('fetched_at', '')
        if fetched_at:
            data_dt = datetime.fromisoformat(fetched_at)
            data_label = f"{data_dt.month}/{data_dt.day}({WEEKDAY_NAMES[data_dt.weekday()]})"
            prev_dt = data_dt - timedelta(days=1)
            prev_label = f"{prev_dt.month}/{prev_dt.day}({WEEKDAY_NAMES[prev_dt.weekday()]})"
            return data_label, prev_label
    except:
        pass
    return None, None


def is_night_mode():
    """22:45ä»¥é™ã¯ç¿Œæ—¥äºˆæƒ³ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ"""
    now = datetime.now(JST)
    return now.hour > 22 or (now.hour == 22 and now.minute >= 45)


def generate_ranking_pages(env):
    """æ©Ÿç¨®åˆ¥ç·åˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating ranking pages...")

    template = env.get_template('ranking.html')
    output_subdir = OUTPUT_DIR / 'ranking'
    output_subdir.mkdir(parents=True, exist_ok=True)

    night_mode = is_night_mode()
    now = datetime.now(JST)
    tomorrow = now + timedelta(days=1)
    tomorrow_str = format_date_with_weekday(tomorrow)
    yesterday = now - timedelta(days=1)
    data_date_str = format_date_with_weekday(now)
    prev_date_str = format_date_with_weekday(yesterday)
    reason_data_label, reason_prev_label = get_reason_date_labels()

    for machine_key, machine in MACHINES.items():
        stores = get_stores_by_machine(machine_key)
        all_recommendations = []

        for store_key, store in stores.items():
            availability = {}
            try:
                availability = get_availability(store_key)
            except:
                pass

            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚‚å–å¾—ï¼ˆè¨­å®šæ¨æ¸¬ã‚„max_medalsç­‰ã«å¿…è¦ï¼‰
            realtime = None
            try:
                realtime = get_realtime_data(store_key)
            except:
                pass

            recommendations = recommend_units(store_key, realtime_data=realtime, availability=availability,
                                              data_date_label=reason_data_label, prev_date_label=reason_prev_label)
            for rec in recommendations:
                rec['store_name'] = store.get('short_name', store['name'])
                rec['store_key'] = store_key
                # å·®æšè¨ˆç®—ã¯recommend_unitså†…ã§çµ±åˆæ¸ˆã¿
                all_recommendations.append(rec)

        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        def sort_key(r):
            score = r['final_score']
            if r['is_running']:
                score -= 30
            return -score

        all_recommendations.sort(key=sort_key)
        top_recs = [r for r in all_recommendations if r['final_rank'] in ('S', 'A') and not r['is_running']][:10]
        other_recs = [r for r in all_recommendations if r not in top_recs][:20]

        html = template.render(
            machine=machine,
            machine_key=machine_key,
            top_recs=top_recs,
            other_recs=other_recs,
            total_count=len(all_recommendations),
            night_mode=night_mode,
            tomorrow_str=tomorrow_str,
            data_date_str=data_date_str,
            prev_date_str=prev_date_str,
            now_short=now.strftime('%m%d_%H:%M'),
        )

        output_path = output_subdir / f'{machine_key}.html'
        output_path.write_text(html, encoding='utf-8')
        print(f"  -> {output_path}")


def generate_recommend_pages(env):
    """å„åº—èˆ—ã®æ¨å¥¨ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating recommend pages...")

    template = env.get_template('recommend.html')
    output_subdir = OUTPUT_DIR / 'recommend'
    output_subdir.mkdir(parents=True, exist_ok=True)

    is_open = is_business_hours()
    display_mode = get_display_mode()
    reason_data_label, reason_prev_label = get_reason_date_labels()

    # æ—§å½¢å¼ã‚­ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
    old_keys = {'island_akihabara', 'shibuya_espass', 'shinjuku_espass'}

    for store_key, store in STORES.items():
        if store_key in old_keys:
            continue
        print(f"  Processing {store_key}...")

        machine_key = store.get('machine', 'sbj')
        machine = get_machine_info(machine_key)

        # ç©ºãçŠ¶æ³ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        availability = {}
        realtime_data = None
        cache_info = None

        try:
            availability = get_availability(store_key)
        except:
            pass

        try:
            rt_data = get_realtime_data(store_key)
            if rt_data and rt_data.get('units'):
                realtime_data = rt_data
                fetched_at_str = rt_data.get('fetched_at', '')
                if fetched_at_str:
                    try:
                        fetched_time = datetime.fromisoformat(fetched_at_str.replace('Z', '+00:00'))
                        fetched_time_jst = fetched_time.astimezone(JST)
                        now_jst = datetime.now(JST)
                        cache_info = {
                            'fetched_at': fetched_time_jst.strftime('%H:%M'),
                            'age_seconds': int((now_jst - fetched_time_jst).total_seconds()),
                            'source': rt_data.get('source', 'unknown'),
                        }
                    except:
                        pass
        except:
            pass

        recommendations = recommend_units(store_key, realtime_data, availability,
                                          data_date_label=reason_data_label, prev_date_label=reason_prev_label)

        # å·®æšè¨ˆç®—ã¯recommend_unitså†…ã§çµ±åˆæ¸ˆã¿

        # åˆ†é¡
        sa_recs = [r for r in recommendations if r['final_rank'] in ('S', 'A') and not r['is_running']]
        if sa_recs:
            top_recs = sa_recs
        else:
            top_recs = [r for r in recommendations if not r['is_running']][:3]

        other_recs = [r for r in recommendations if r not in top_recs]

        availability_info = None
        if availability:
            availability_info = {
                'fetched_at': datetime.now(JST).strftime('%H:%M'),
                'empty_count': sum(1 for v in availability.values() if v == 'ç©ºã'),
                'playing_count': sum(1 for v in availability.values() if v == 'éŠæŠ€ä¸­'),
            }

        # åº—èˆ—åˆ†æï¼ˆrecommend_unitsã®è¨ˆç®—çµæœã‹ã‚‰ãƒ©ãƒ³ã‚¯åˆ†å¸ƒã‚’ç”Ÿæˆï¼‰
        daily_data = load_daily_data(machine_key=machine_key)
        store_analysis = generate_store_analysis(store_key, daily_data)

        # ãƒ©ãƒ³ã‚¯åˆ†å¸ƒã‚’recommend_unitsã®çµæœã§ä¸Šæ›¸ãï¼ˆç›¸å¯¾è©•ä¾¡ã®çµæœã‚’æ­£ç¢ºã«åæ˜ ï¼‰
        all_recs_for_analysis = top_recs + other_recs
        if all_recs_for_analysis:
            from collections import Counter
            rank_counts = Counter(r['final_rank'] for r in all_recs_for_analysis)
            rank_parts = []
            for rank in ['S', 'A', 'B', 'C', 'D']:
                count = rank_counts.get(rank, 0)
                if count > 0:
                    rank_parts.append(f"{rank}:{count}å°")
            store_analysis['rank_dist'] = " / ".join(rank_parts)
            high_count = rank_counts.get('S', 0) + rank_counts.get('A', 0)
            total = len(all_recs_for_analysis)
            store_analysis['high_count'] = high_count
            store_analysis['total_units'] = total
            high_ratio = high_count / total * 100 if total > 0 else 0
            if high_ratio >= 70:
                store_analysis['overall'] = f"é«˜è¨­å®šå°ãŒéå¸¸ã«å¤šã„ï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
            elif high_ratio >= 50:
                store_analysis['overall'] = f"é«˜è¨­å®šå°ãŒå¤šã„ï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
            elif high_ratio >= 30:
                store_analysis['overall'] = f"é«˜è¨­å®šå°ã‚ã‚Šï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
            else:
                store_analysis['overall'] = f"é«˜è¨­å®šå°ãŒå°‘ãªã„ï¼ˆå…¨{total}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"

        # å°ç•ªå·ã‚¢ãƒ©ãƒ¼ãƒˆ
        store_alerts = [a for a in get_active_alerts() if a.get('store_key') == store_key]

        html = template.render(
            store=store,
            store_key=store_key,
            machine=machine,
            machine_key=machine_key,
            top_recs=top_recs,
            other_recs=other_recs,
            updated_at=datetime.now(JST).strftime('%H:%M'),
            cache_info=cache_info,
            availability_info=availability_info,
            is_open=is_open,
            display_mode=display_mode,
            store_analysis=store_analysis,
            unit_alerts=store_alerts,
        )

        output_path = output_subdir / f'{store_key}.html'
        output_path.write_text(html, encoding='utf-8')

    print(f"  -> {output_subdir}/")


def _process_history_for_verify(history):
    """å½“ãŸã‚Šå±¥æ­´ã‚’ç­”ãˆåˆã‚ã›è¡¨ç¤ºç”¨ã«åŠ å·¥ã™ã‚‹

    - æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
    - ãƒã‚§ãƒ¼ãƒ³ï¼ˆé€£ãƒãƒ£ãƒ³ï¼‰ã‚’è¨ˆç®—
    - æ·±ã„ãƒãƒã‚Šãƒ»æµ…ã„å½“ãŸã‚Šã®ãƒ•ãƒ©ã‚°ã‚’ä»˜ä¸
    """
    from analysis.analyzer import is_big_hit, RENCHAIN_THRESHOLD

    if not history:
        return [], {}

    # æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_hist = sorted(history, key=lambda x: x.get('time', '00:00'))

    # ãƒã‚§ãƒ¼ãƒ³è¨ˆç®—: ATé–“ã®Gæ•°ã‚’è“„ç©ã—ã€é–¾å€¤ä»¥ä¸‹ãªã‚‰é€£ãƒãƒ£ãƒ³
    processed = []
    chain_id = 0
    chain_hits = []  # ç¾åœ¨ã®ãƒã‚§ãƒ¼ãƒ³å†…ã®ãƒ’ãƒƒãƒˆ
    accumulated_games = 0  # RBã‚’è·¨ã„ã ATé–“Gæ•°

    for i, hit in enumerate(sorted_hist):
        start = hit.get('start', 0)
        hit_type = hit.get('type', 'ART')
        medals = hit.get('medals', 0)
        time_str = hit.get('time', '')

        accumulated_games += start

        entry = {
            'index': i + 1,
            'time': time_str,
            'start': start,
            'type': hit_type,
            'medals': medals,
            'is_deep': start >= 500,
            'is_shallow': start <= 10 and i > 0,
            'is_tenjou': start >= 800,
        }

        if is_big_hit(hit_type):
            if i == 0 or accumulated_games > RENCHAIN_THRESHOLD:
                # æ–°ã—ã„ãƒã‚§ãƒ¼ãƒ³é–‹å§‹
                if chain_hits:
                    chain_len = len(chain_hits)
                    for ch in chain_hits:
                        ch['chain_len'] = chain_len
                chain_id += 1
                chain_hits = [entry]
            else:
                # é€£ãƒãƒ£ãƒ³ç¶™ç¶š
                chain_hits.append(entry)

            entry['chain_id'] = chain_id
            entry['is_hot_chain'] = False  # å¾Œã§æ›´æ–°
            accumulated_games = 0  # ATé–“ãƒªã‚»ãƒƒãƒˆ
        else:
            # RB: ãƒã‚§ãƒ¼ãƒ³ã«å«ã‚ãªã„ï¼ˆATé–“ã¯ç¶™ç¶šï¼‰
            entry['chain_id'] = 0
            entry['chain_len'] = 0
            entry['is_hot_chain'] = False

        processed.append(entry)

    # æœ€å¾Œã®ãƒã‚§ãƒ¼ãƒ³ã‚’å‡¦ç†
    if chain_hits:
        chain_len = len(chain_hits)
        for idx, ch in enumerate(chain_hits):
            ch['chain_len'] = chain_len
            ch['chain_pos'] = idx + 1  # 1é€£ç›®, 2é€£ç›®, ...

    # å…¨ã¦ã®ãƒã‚§ãƒ¼ãƒ³ã«chain_posã‚’ä»˜ä¸ï¼ˆæœ€å¾Œã®ãƒã‚§ãƒ¼ãƒ³ä»¥å¤–ã¯æ—¢ã«ãƒ«ãƒ¼ãƒ—å†…ã§å‡¦ç†æ¸ˆã¿ï¼‰
    # â†’ ä¸Šã®ãƒ«ãƒ¼ãƒ—å†…ã§å‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ä¿®æ­£:
    # chain_hitsã®å‡¦ç†ã‚’å†èµ°æŸ»ã—ã¦å…¨ãƒã‚§ãƒ¼ãƒ³ã«chain_posã‚’ä»˜ä¸
    current_chain_id = 0
    pos = 0
    for entry in processed:
        cid = entry.get('chain_id', 0)
        if cid > 0:
            if cid != current_chain_id:
                current_chain_id = cid
                pos = 1
            else:
                pos += 1
            entry['chain_pos'] = pos
        else:
            entry['chain_pos'] = 0

    # ãƒ›ãƒƒãƒˆãƒã‚§ãƒ¼ãƒ³(5é€£ä»¥ä¸Š)ã«ãƒ•ãƒ©ã‚°ä»˜ä¸
    for entry in processed:
        if entry.get('chain_len', 0) >= 5:
            entry['is_hot_chain'] = True

    # ã‚µãƒãƒªãƒ¼è¨ˆç®—
    starts = [h.get('start', 0) for h in sorted_hist]
    big_hit_starts = []
    acc = 0
    for hit in sorted_hist:
        acc += hit.get('start', 0)
        if is_big_hit(hit.get('type', '')):
            big_hit_starts.append(acc)
            acc = 0

    total_games = sum(starts)
    total_hits = len(sorted_hist)
    total_medals = sum(h.get('medals', 0) for h in sorted_hist)

    # ATé–“ãƒ™ãƒ¼ã‚¹ã®è°·
    valleys = big_hit_starts if big_hit_starts else starts
    max_valley = max(valleys) if valleys else 0
    avg_valley = int(sum(valleys) / len(valleys)) if valleys else 0
    tenjou_count = sum(1 for v in valleys if v >= 800)

    # æœ€å¤§ãƒã‚§ãƒ¼ãƒ³
    chain_lengths = [e.get('chain_len', 0) for e in processed if e.get('chain_id', 0) > 0]
    # å„ãƒã‚§ãƒ¼ãƒ³ã®é•·ã•ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«å–å¾—
    seen_chains = {}
    for e in processed:
        cid = e.get('chain_id', 0)
        clen = e.get('chain_len', 0)
        if cid > 0 and cid not in seen_chains:
            seen_chains[cid] = clen
    max_chain = max(seen_chains.values()) if seen_chains else 0

    summary = {
        'total_games': total_games,
        'total_hits': total_hits,
        'total_medals': total_medals,
        'max_valley': max_valley,
        'avg_valley': avg_valley,
        'tenjou_count': tenjou_count,
        'max_chain': max_chain,
    }

    return processed, summary


def _try_load_backtest_results():
    """æœ€æ–°ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’èª­ã¿è¾¼ã‚€"""
    import glob
    results_files = sorted(glob.glob(str(PROJECT_ROOT / 'data' / 'verify' / 'verify_*_results.json')))
    if not results_files:
        return None
    latest = results_files[-1]
    try:
        data = json.loads(Path(latest).read_text())
        if data.get('total_sa', 0) > 0:
            print(f"  ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’ä½¿ç”¨: {Path(latest).name}")
            return data
    except:
        pass
    return None


def _generate_verify_from_backtest(env, results):
    """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‹ã‚‰verifyãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    from analysis.feedback import analyze_prediction_errors
    
    STORE_TO_MACHINE = {}
    for sk, sv in STORES.items():
        STORE_TO_MACHINE[sk] = sv.get('machine_key', 'sbj')
    
    machine_groups = {}
    for store_key, store_data in results.get('stores', {}).items():
        mk = STORE_TO_MACHINE.get(store_key, 'sbj')
        if mk not in machine_groups:
            machine_groups[mk] = {'stores': []}
        
        units = results.get('units', {}).get(store_key, [])
        formatted_units = []
        for u in sorted(units, key=lambda x: -x.get('predicted_score', 0)):
            rank = u.get('predicted_rank', 'C')
            is_sa = rank in ('S', 'A')
            is_good = u.get('actual_is_good', False)
            prob = u.get('actual_prob', 0)
            games = u.get('actual_games', 0)
            
            if is_sa and is_good and prob > 0 and prob <= 100:
                verdict, verdict_class = 'â—', 'perfect'
            elif is_sa and is_good:
                verdict, verdict_class = 'â—‹', 'hit'
            elif is_sa and not is_good:
                verdict, verdict_class = 'âœ•', 'miss'
            elif not is_sa and is_good:
                verdict, verdict_class = 'â˜…', 'surprise'
            elif games < 500:
                verdict, verdict_class = '-', 'nodata'
            else:
                verdict, verdict_class = 'â–³', 'neutral'
            
            formatted_units.append({
                'unit_id': u.get('unit_id', ''),
                'pre_open_rank': rank,
                'pre_open_score': u.get('predicted_score', 50),
                'predicted_rank': rank,
                'predicted_score': u.get('predicted_score', 50),
                'actual_art': u.get('actual_art', 0),
                'actual_prob': prob,
                'actual_games': games,
                'verdict': verdict,
                'verdict_class': verdict_class,
            })
        
        machine_groups[mk]['stores'].append({
            'name': store_data.get('name', store_key),
            'units': formatted_units,
            'sa_total': store_data.get('sa_total', 0),
            'sa_hit': store_data.get('sa_hit', 0),
            'sa_rate': store_data.get('rate', 0),
        })
    
    verify_data = {}
    for mk, mg in machine_groups.items():
        m = MACHINES.get(mk, {})
        verify_data[mk] = {
            'name': m.get('short_name', mk),
            'icon': m.get('icon', 'ğŸ°'),
            'stores': mg['stores'],
        }
    
    accuracy = results.get('overall_rate', 0)
    total_sa = results.get('total_sa', 0)
    total_hit = results.get('total_hit', 0)
    total_surprise = results.get('total_surprise', 0)
    
    machine_accuracy = []
    for mk, md in verify_data.items():
        m_predicted = sum(s['sa_total'] for s in md['stores'])
        m_actual = sum(s['sa_hit'] for s in md['stores'])
        m_surprise = sum(sum(1 for u in s['units'] if u['verdict_class'] == 'surprise') for s in md['stores'])
        m_all = sum(len(s['units']) for s in md['stores'])
        m_rate = (m_actual / m_predicted * 100) if m_predicted > 0 else 0
        machine_accuracy.append({
            'name': md['name'], 'icon': md['icon'],
            'total': m_predicted, 'hit': m_actual,
            'surprise': m_surprise, 'all_units': m_all,
            'total_good': m_actual + m_surprise, 'rate': m_rate,
        })
    
    hypotheses = []
    for mk, md in verify_data.items():
        for sd in md['stores']:
            try:
                analysis = analyze_prediction_errors(sd['units'], '', mk)
                if analysis.get('hypotheses'):
                    hypotheses.extend(analysis['hypotheses'])
            except:
                pass
    
    # æ—¥ä»˜æƒ…å ±ï¼ˆèª­ã¿ã‚„ã™ã„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
    weekdays = ['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥']
    def _fmt_date(date_str):
        try:
            dt = datetime.strptime(date_str, '%Y-%m-%d')
            return f'{dt.month}/{dt.day}({weekdays[dt.weekday()]})'
        except:
            return date_str
    
    pred_date = results.get('prediction_date', '')
    actual_date = results.get('date', '')
    
    template = env.get_template('verify.html')
    html = template.render(
        verify_data=verify_data,
        accuracy=accuracy,
        total_predicted_good=total_sa,
        total_actual_good=total_hit,
        total_surprise=total_surprise,
        machine_accuracy=machine_accuracy,
        hypotheses=hypotheses[:6],
        version=f'backtest_{actual_date}',
        result_date_str=f'{_fmt_date(actual_date)}ã®å®Ÿç¸¾',
        predict_base=f'{_fmt_date(pred_date)}ã¾ã§ã®è“„ç©ãƒ‡ãƒ¼ã‚¿ + æ¨ç§»ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ­ã‚¸ãƒƒã‚¯',
    )
    
    output_path = OUTPUT_DIR / 'verify.html'
    output_path.write_text(html, encoding='utf-8')
    print(f"  -> {output_path} (ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ: çš„ä¸­ç‡{accuracy:.0f}%)")


def generate_verify_page(env):
    """ç­”ãˆåˆã‚ã›ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ - äºˆæ¸¬ vs å®Ÿç¸¾ã®æ¯”è¼ƒ
    
    ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ(data/verify/verify_*_results.json)ãŒã‚ã‚Œã°
    æœ€æ–°ã®ã‚‚ã®ã‚’ä½¿ã£ã¦ç”Ÿæˆã™ã‚‹ã€‚ãªã‘ã‚Œã°é€šå¸¸ã®äºˆæ¸¬vså‰æ—¥å®Ÿç¸¾ã§ç”Ÿæˆã€‚
    """
    print("Generating verify page...")
    
    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãŒã‚ã‚Œã°ãã¡ã‚‰ã‚’ä½¿ã†
    backtest_result = _try_load_backtest_results()
    if backtest_result:
        _generate_verify_from_backtest(env, backtest_result)
        return

    template = env.get_template('verify.html')
    old_keys = {'island_akihabara', 'shibuya_espass', 'shinjuku_espass'}

    verify_data = {}
    total_predicted_good = 0  # äºˆæ¸¬S/Aå°æ•°
    total_actual_good = 0     # äºˆæ¸¬S/Aã®ã†ã¡å®Ÿéš›ã«å¥½èª¿ã ã£ãŸå°æ•°
    total_surprise = 0        # äºˆæ¸¬Bä»¥ä¸‹ã ãŒå®Ÿéš›ã«å¥½èª¿ã ã£ãŸå°æ•°

    for machine_key, machine in MACHINES.items():
        stores_data = []
        stores = get_stores_by_machine(machine_key)

        # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆå½“ãŸã‚Šå±¥æ­´å–å¾—ç”¨ï¼‰
        daily_data = load_daily_data(machine_key=machine_key)
        daily_stores = daily_data.get('stores', {}) if daily_data else {}

        for store_key, store in stores.items():
            if store_key in old_keys:
                continue

            # 2ç¨®é¡ã®äºˆæ¸¬ã‚’å–å¾—
            # (1) é–‹åº—å‰äºˆæ¸¬: éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªã—ï¼‰
            # (2) ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬: å½“æ—¥ãƒ‡ãƒ¼ã‚¿è¾¼ã¿
            availability = {}
            realtime = None
            try:
                availability = get_availability(store_key)
                realtime = get_realtime_data(store_key)
            except:
                pass

            # é–‹åº—å‰äºˆæ¸¬ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
            pre_open_recs = recommend_units(store_key, availability=availability)
            pre_open_map = {}
            for r in pre_open_recs:
                pre_open_map[str(r.get('unit_id', ''))] = {
                    'rank': r.get('final_rank', 'C'),
                    'score': r.get('final_score', 50),
                }

            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ï¼ˆå½“æ—¥ãƒ‡ãƒ¼ã‚¿è¾¼ã¿ï¼‰
            recommendations = recommend_units(store_key, realtime_data=realtime, availability=availability)
            units_data = []

            # ã“ã®åº—èˆ—ã®æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¦ãƒ‹ãƒƒãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆ
            store_daily = daily_stores.get(store_key, {})
            daily_units_map = {}
            for u in store_daily.get('units', []):
                daily_units_map[str(u.get('unit_id', ''))] = u

            for rec in recommendations:
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ï¼ˆå½“æ—¥ãƒ‡ãƒ¼ã‚¿è¾¼ã¿ï¼‰
                predicted_rank = rec.get('final_rank', 'C')
                predicted_score = rec.get('final_score', 50)

                # é–‰åº—å¾Œã¯å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿç¸¾ã¨ã—ã¦ä½¿ã†
                actual_art = rec.get('art_count', 0)
                actual_games = rec.get('total_games', 0)
                actual_prob = rec.get('art_prob', 0)
                if actual_art == 0 and not is_business_hours():
                    actual_art = rec.get('yesterday_art', 0)
                    actual_games = rec.get('yesterday_games', 0)
                    if actual_art > 0 and actual_games > 0:
                        actual_prob = actual_games / actual_art
                    else:
                        actual_prob = 0

                # é–‹åº—å‰äºˆæ¸¬ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
                uid = str(rec.get('unit_id', ''))
                pre_open = pre_open_map.get(uid, {})
                pre_open_rank = pre_open.get('rank', 'C')
                pre_open_score = pre_open.get('score', 50)

                # åˆ¤å®š
                is_predicted_good = predicted_rank in ('S', 'A')
                is_actual_good = actual_prob > 0 and actual_prob <= 130
                is_actual_excellent = actual_prob > 0 and actual_prob <= 100
                is_actual_bad = actual_prob >= 200 or (actual_games >= 1000 and actual_art == 0)

                if is_predicted_good:
                    total_predicted_good += 1
                    if is_actual_excellent:
                        verdict = '\u25CE'  # â—
                        verdict_class = 'perfect'
                        total_actual_good += 1
                    elif is_actual_good:
                        verdict = '\u25CB'  # â—‹
                        verdict_class = 'hit'
                        total_actual_good += 1
                    elif is_actual_bad:
                        verdict = '\u2715'  # âœ•
                        verdict_class = 'miss'
                    else:
                        verdict = '\u25B3'  # â–³
                        verdict_class = 'neutral'
                elif not is_predicted_good and is_actual_good:
                    verdict = '\u2605'  # â˜… ç™ºæ˜
                    verdict_class = 'surprise'
                    total_surprise += 1
                elif actual_games < 500:
                    verdict = '-'
                    verdict_class = 'nodata'
                else:
                    verdict = '\u25B3'  # â–³
                    verdict_class = 'neutral'

                # å½“ãŸã‚Šå±¥æ­´ã‚’å–å¾—
                unit_daily = daily_units_map.get(str(rec.get('unit_id', '')), {})
                days = unit_daily.get('days', [])
                today_history_raw = []
                history_date = ''
                if days:
                    # æœ€æ–°ã®æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                    today_data = days[0]
                    today_history_raw = today_data.get('history', [])
                    history_date = today_data.get('date', '')

                processed_history, history_summary = _process_history_for_verify(today_history_raw)

                units_data.append({
                    'unit_id': rec.get('unit_id', ''),
                    'predicted_rank': predicted_rank,
                    'predicted_score': predicted_score,
                    'pre_open_rank': pre_open_rank,
                    'pre_open_score': pre_open_score,
                    'actual_art': actual_art,
                    'actual_prob': actual_prob,
                    'actual_games': actual_games,
                    'verdict': verdict,
                    'verdict_class': verdict_class,
                    'history': processed_history,
                    'history_summary': history_summary,
                    'history_date': history_date,
                })

            if units_data:
                # åº—èˆ—åˆ¥çš„ä¸­ç‡ï¼ˆé–‹åº—å‰äºˆæ¸¬ãƒ™ãƒ¼ã‚¹ï¼‰
                store_sa_total = sum(1 for u in units_data if u['pre_open_rank'] in ('S', 'A'))
                store_sa_hit = sum(1 for u in units_data if u['pre_open_rank'] in ('S', 'A') and u.get('actual_prob', 0) > 0 and u['actual_prob'] <= 130)
                store_sa_rate = (store_sa_hit / store_sa_total * 100) if store_sa_total > 0 else 0
                stores_data.append({
                    'name': store.get('name', store_key),
                    'units': units_data,
                    'sa_total': store_sa_total,
                    'sa_hit': store_sa_hit,
                    'sa_rate': store_sa_rate,
                })

        if stores_data:
            verify_data[machine_key] = {
                'name': machine['short_name'],
                'icon': machine['icon'],
                'stores': stores_data,
            }

            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿å­˜ï¼ˆç­”ãˆåˆã‚ã›çµæœã‚’æ¬¡å›äºˆæ¸¬ã«åæ˜ ï¼‰
            try:
                from analysis.feedback import analyze_prediction_errors, save_feedback
                for sd in stores_data:
                    store_name = sd.get('name', '')
                    # store_keyã‚’é€†å¼•ã
                    _sk = ''
                    for _skey, _sval in get_stores_by_machine(machine_key).items():
                        if _sval.get('name', '') == store_name:
                            _sk = _skey
                            break
                    if _sk and sd.get('units'):
                        analysis = analyze_prediction_errors(sd['units'], _sk, machine_key)
                        if analysis['hits'] + analysis['misses'] + analysis['surprises'] > 0:
                            save_feedback(analysis)
            except Exception as e:
                print(f"  âš  ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    # çš„ä¸­ç‡è¨ˆç®—
    accuracy = 0
    if total_predicted_good > 0:
        accuracy = (total_actual_good / total_predicted_good) * 100

    # æ©Ÿç¨®åˆ¥ã®çš„ä¸­ç‡ï¼ˆé–‹åº—å‰äºˆæ¸¬ãƒ™ãƒ¼ã‚¹ï¼‰
    machine_accuracy = []
    for machine_key, machine_data in verify_data.items():
        m_all = 0
        m_predicted = 0
        m_actual = 0
        m_surprise = 0
        for store in machine_data.get('stores', []):
            for unit in store.get('units', []):
                m_all += 1
                is_sa = unit['pre_open_rank'] in ('S', 'A')
                prob = unit.get('actual_prob', 0)
                is_good = prob > 0 and prob <= 130
                if is_sa:
                    m_predicted += 1
                    if is_good:
                        m_actual += 1
                elif not is_sa and is_good:
                    m_surprise += 1
        rate = (m_actual / m_predicted * 100) if m_predicted > 0 else 0
        machine_accuracy.append({
            'name': machine_data['name'],
            'icon': machine_data['icon'],
            'all_units': m_all,
            'total': m_predicted,
            'hit': m_actual,
            'rate': rate,
            'surprise': m_surprise,
            'total_good': m_actual + m_surprise,
        })

    # å…¨å°æ•°ã‚’è¨ˆç®—
    total_all_units = 0
    for mk, md in verify_data.items():
        for s in md.get('stores', []):
            total_all_units += len(s.get('units', []))

    # å…¨å°ä¸­ã®å¥½èª¿å°æ•°
    total_good_all = total_actual_good + total_surprise

    # æ—¥ä»˜æƒ…å ±
    now = datetime.now(JST)
    reason_data_label, reason_prev_label = get_reason_date_labels()
    # å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ï¼ˆé–‰åº—å¾Œã¯å‰æ—¥ã€å–¶æ¥­ä¸­ã¯å½“æ—¥ï¼‰
    if is_business_hours():
        result_date_str = format_date_with_weekday(now)
        predict_base = format_date_with_weekday(now - timedelta(days=1))
    else:
        result_date_str = format_date_with_weekday(now - timedelta(days=1))
        predict_base = format_date_with_weekday(now - timedelta(days=2))

    # ä»®èª¬ç”Ÿæˆ
    hypotheses = []
    try:
        from analysis.feedback import generate_hypotheses, load_feedback_history
        import glob
        all_fbs = []
        for fp in sorted(glob.glob('data/feedback/*_2026-*.json')):
            try:
                with open(fp) as fh:
                    all_fbs.append(json.load(fh))
            except Exception:
                pass
        # ä»Šæ—¥ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ã¿ã§ä»®èª¬ç”Ÿæˆ
        today_str = now.strftime('%Y-%m-%d')
        today_fbs = [fb for fb in all_fbs if fb.get('date') == today_str]
        if today_fbs:
            hypotheses = generate_hypotheses(today_fbs)
    except Exception as e:
        print(f"  âš  ä»®èª¬ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

    html = template.render(
        verify_data=verify_data,
        accuracy=accuracy,
        predicted_good=total_predicted_good,
        actual_good=total_actual_good,
        surprise_good=total_surprise,
        machine_accuracy=machine_accuracy,
        total_all_units=total_all_units,
        total_good_all=total_good_all,
        result_date_str=result_date_str,
        predict_base=predict_base,
        hypotheses=hypotheses,
    )

    output_path = OUTPUT_DIR / 'verify.html'
    output_path.write_text(html, encoding='utf-8')
    print(f"  -> {output_path}")


def generate_history_pages(env):
    """å„å°ã®è©³ç´°å±¥æ­´ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("Generating history pages...")

    template = env.get_template('unit_history.html')
    output_subdir = OUTPUT_DIR / 'history'
    output_subdir.mkdir(parents=True, exist_ok=True)

    from analysis.history_accumulator import load_unit_history

    old_keys = {'island_akihabara', 'shibuya_espass', 'shinjuku_espass'}
    page_count = 0

    for store_key, store in STORES.items():
        if store_key in old_keys:
            continue

        machine_key = store.get('machine', 'sbj')
        machine = get_machine_info(machine_key)
        units = store.get('units', [])

        for unit_id in units:
            unit_id_str = str(unit_id)

            # è“„ç©ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            acc_hist = load_unit_history(store_key, unit_id_str)
            acc_days = acc_hist.get('days', [])

            if not acc_days:
                # ãƒ‡ãƒ¼ã‚¿ãŒç„¡ã„å°ã‚‚ãƒšãƒ¼ã‚¸ã ã‘ã¯ä½œæˆï¼ˆç©ºè¡¨ç¤ºï¼‰
                html = template.render(
                    store=store,
                    store_key=store_key,
                    unit_id=unit_id_str,
                    machine=machine,
                    machine_key=machine_key,
                    days=[],
                    total_summary=None,
                )
                output_path = output_subdir / f'{store_key}_{unit_id_str}.html'
                output_path.write_text(html, encoding='utf-8')
                page_count += 1
                continue

            # æ—¥ä»˜ã‚’æ–°ã—ã„é †ã«ã‚½ãƒ¼ãƒˆ
            sorted_days = sorted(acc_days, key=lambda x: x.get('date', ''), reverse=True)

            # å„æ—¥ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
            template_days = []
            total_art = 0
            total_games = 0
            good_count = 0
            total_diff = 0

            for d in sorted_days:
                date_str = d.get('date', '')
                art = d.get('art', 0) or 0
                rb = d.get('rb', 0) or 0
                games = d.get('games', 0) or 0
                prob = d.get('prob', 0) or 0
                is_good = d.get('is_good', False)
                max_rensa = d.get('max_rensa', 0) or 0
                history = d.get('history', [])
                # æœ€å¤§æšæ•°: historyãŒã‚ã‚Œã°é€£ãƒãƒ£ãƒ³åŒºé–“ç´¯è¨ˆã§å†è¨ˆç®—
                if history:
                    from analysis.analyzer import calculate_max_chain_medals
                    max_medals = calculate_max_chain_medals(history)
                else:
                    max_medals = d.get('max_medals', 0) or 0

                # å·®æšè¨ˆç®—
                diff_medals = 0
                if art > 0 and games > 0:
                    try:
                        profit = calculate_expected_profit(games, art, machine_key)
                        diff_medals = profit.get('current_estimate', 0)
                    except Exception:
                        pass

                # æ—¥ä»˜è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                date_display = date_str
                try:
                    dt = datetime.strptime(date_str, '%Y-%m-%d')
                    wd = WEEKDAY_NAMES[dt.weekday()]
                    date_display = f"{dt.month}/{dt.day}({wd})"
                except Exception:
                    pass

                # å½“ãŸã‚Šå±¥æ­´ã‚’æ™‚åˆ»é †ã«ã‚½ãƒ¼ãƒˆï¼ˆå¤ã„æ™‚åˆ»â†’æ–°ã—ã„æ™‚åˆ»ï¼‰
                history_sorted = []
                if history:
                    history_sorted = sorted(history, key=lambda x: x.get('time', '00:00'))

                template_days.append({
                    'date': date_str,
                    'date_display': date_display,
                    'art': art,
                    'rb': rb,
                    'games': games,
                    'prob': prob,
                    'is_good': is_good,
                    'max_rensa': max_rensa,
                    'max_medals': max_medals,
                    'diff_medals': diff_medals,
                    'history': history,
                    'history_sorted': history_sorted,
                })

                # å…¨æœŸé–“ã‚µãƒãƒªãƒ¼ç”¨
                total_art += art
                total_games += games
                if is_good:
                    good_count += 1
                total_diff += diff_medals

            # å…¨æœŸé–“ã‚µãƒãƒªãƒ¼
            total_days = len(sorted_days)
            avg_prob = total_games / total_art if total_art > 0 else 0
            good_rate = round(good_count / total_days * 100) if total_days > 0 else 0

            total_summary = {
                'total_days': total_days,
                'good_days': good_count,
                'good_rate': good_rate,
                'avg_prob': round(avg_prob, 1) if avg_prob > 0 else 0,
                'total_diff_medals': total_diff,
            }

            html = template.render(
                store=store,
                store_key=store_key,
                unit_id=unit_id_str,
                machine=machine,
                machine_key=machine_key,
                days=template_days,
                total_summary=total_summary,
            )

            output_path = output_subdir / f'{store_key}_{unit_id_str}.html'
            output_path.write_text(html, encoding='utf-8')
            page_count += 1

    print(f"  -> {output_subdir}/ ({page_count} pages)")


def copy_static_files():
    """é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼"""
    print("Copying static files...")

    import shutil

    static_src = PROJECT_ROOT / 'web' / 'static'
    static_dst = OUTPUT_DIR / 'static'

    if static_dst.exists():
        shutil.rmtree(static_dst)

    shutil.copytree(static_src, static_dst)
    print(f"  -> {static_dst}/")


def generate_metadata():
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    print("Generating metadata...")

    metadata = {
        'generated_at': datetime.now(JST).isoformat(),
        'version': '2026-01-27-static',
    }

    output_path = OUTPUT_DIR / 'metadata.json'
    output_path.write_text(json.dumps(metadata, ensure_ascii=False, indent=2), encoding='utf-8')
    print(f"  -> {output_path}")


def run_unit_verification():
    """å°ç•ªå·æ¤œè¨¼ã‚’å®Ÿè¡Œã—ã€ã‚¢ãƒ©ãƒ¼ãƒˆãŒã‚ã‚Œã°ä¿å­˜"""
    print("Running unit verification...")
    try:
        from scripts.verify_units import verify_units_from_availability, save_alerts, print_report
        avail_path = PROJECT_ROOT / 'data' / 'availability.json'
        if avail_path.exists():
            with open(avail_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            alerts = verify_units_from_availability(data)
            print_report(alerts)
            if alerts:
                save_alerts(alerts, source='availability')
        else:
            print("  availability.json not found, skipping")
    except Exception as e:
        print(f"  Verification error: {e}")


def run_data_integrity_check():
    """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå…¨åº—èˆ—ã®ART/ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ æç­‰ï¼‰"""
    print("Running data integrity check...")
    try:
        from scripts.verify_units import verify_data_integrity, print_integrity_report
        avail_path = PROJECT_ROOT / 'data' / 'availability.json'
        if avail_path.exists():
            with open(avail_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            issues = verify_data_integrity(data)
            print_integrity_report(issues)
        else:
            print("  availability.json not found, skipping")
    except Exception as e:
        print(f"  Integrity check error: {e}")


def main():
    print("=" * 50)
    print("é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆé–‹å§‹")
    print(f"å‡ºåŠ›å…ˆ: {OUTPUT_DIR}")
    print("=" * 50)
    print()

    # å°ç•ªå·æ¤œè¨¼ï¼ˆã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆï¼‰
    run_unit_verification()

    # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    run_data_integrity_check()

    # æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿è“„ç©ï¼ˆhistory DBæ›´æ–°ï¼‰
    try:
        from analysis.history_accumulator import accumulate_from_daily
        for mk in MACHINES:
            daily = load_daily_data(machine_key=mk)
            if daily:
                result = accumulate_from_daily(daily, mk)
                if result['new_entries'] > 0:
                    print(f"  ğŸ“¦ {mk}: {result['new_entries']}ä»¶è“„ç© ({result['updated_units']}å°)")
    except Exception as e:
        print(f"  âš  è“„ç©ã‚¨ãƒ©ãƒ¼: {e}")

    # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿è¨˜éŒ²ï¼ˆè“„ç©æ¸ˆã¿historyã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼‰
    try:
        from analysis.pattern_detector import record_from_history
        import os
        for store_dir in os.listdir('data/history'):
            if not os.path.isdir(f'data/history/{store_dir}'):
                continue
            if '_sbj' in store_dir:
                mk = 'sbj'
            elif '_hokuto' in store_dir:
                mk = 'hokuto_tensei2'
            else:
                continue
            n = record_from_history(store_dir, mk)
            if n > 0:
                print(f"  ğŸ“Š ãƒ‘ã‚¿ãƒ¼ãƒ³è¨˜éŒ²: {store_dir} ({n}ä»¶)")
    except Exception as e:
        print(f"  âš  ãƒ‘ã‚¿ãƒ¼ãƒ³è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
    print()

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # Jinja2ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    env = setup_jinja()

    # å„ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ
    generate_index(env)
    generate_machine_pages(env)
    generate_ranking_pages(env)
    generate_recommend_pages(env)
    generate_verify_page(env)
    generate_history_pages(env)
    copy_static_files()
    generate_metadata()

    print()
    print("=" * 50)
    print("é™çš„ã‚µã‚¤ãƒˆç”Ÿæˆå®Œäº†!")
    print("=" * 50)


if __name__ == '__main__':
    main()
