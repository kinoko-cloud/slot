#!/usr/bin/env python3
"""
åŒ—æ–—è»¢ç”Ÿ2ã®ä¸¦åˆ—ãƒ‡ãƒ¼ã‚¿å–å¾—

ã‚¨ã‚¹ãƒ‘ã‚¹åŒ—æ–—åº—èˆ—ï¼ˆ5åº—èˆ—ï¼‰ã‚’ä¸¦åˆ—ã§å–å¾—ã—ã¦availability.jsonã«ãƒãƒ¼ã‚¸ã™ã‚‹ã€‚
"""
import sys
import json
from pathlib import Path
from datetime import datetime, timezone, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

sys.path.insert(0, str(Path(__file__).parent.parent))

from playwright.sync_api import sync_playwright
import re

JST = timezone(timedelta(hours=9))
PROJECT_ROOT = Path(__file__).parent.parent

# åŒ—æ–—è»¢ç”Ÿ2ã®åº—èˆ—è¨­å®šï¼ˆfetch_daidata_availability.pyã‹ã‚‰æŠ½å‡ºï¼‰
HOKUTO_STORES = {
    'shibuya_espass_hokuto': {
        'hall_id': '100860',
        'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ¸‹è°·æ–°é¤¨(åŒ—æ–—)',
        'units': [str(i) for i in range(2046, 2068)] + [str(i) for i in range(2233, 2241)],
    },
    'shibuya_honkan_espass_hokuto': {
        'hall_id': '100930',
        'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ¸‹è°·æœ¬é¤¨(åŒ—æ–—)',
        'units': [str(i) for i in range(2013, 2020)] + [str(i) for i in range(2030, 2038)],
    },
    'shinjuku_espass_hokuto': {
        'hall_id': '100949',
        'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ­Œèˆä¼ç”º(åŒ—æ–—)',
        'units': [str(i) for i in range(1, 38)] + [str(i) for i in range(125, 129)],
    },
    'akiba_espass_hokuto': {
        'hall_id': '100928',
        'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹ç§‹è‘‰åŸ(åŒ—æ–—)',
        'units': [str(i) for i in range(2011, 2020)] + [str(i) for i in range(2056, 2069)],
    },
    'seibu_shinjuku_espass_hokuto': {
        'hall_id': '100950',
        'name': 'ã‚¨ã‚¹ãƒ‘ã‚¹è¥¿æ­¦æ–°å®¿(åŒ—æ–—)',
        'units': [str(i) for i in range(3138, 3152)] + ['3165', '3166', '3185', '3186', '3187'],
    },
}


def fetch_unit_data(hall_id, unit_id, hall_name):
    """1å°ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆPlaywrightä½¿ç”¨ï¼‰"""
    url = f'https://daidata.goraggio.com/101033/{hall_id}/unitDetail/{unit_id}'

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        try:
            # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿
            page.goto(url, timeout=20000, wait_until='domcontentloaded')
            page.wait_for_timeout(2000)

            # è¦ç´„åŒæ„ãƒœã‚¿ãƒ³ãŒã‚ã‚Œã°ã‚¯ãƒªãƒƒã‚¯
            try:
                accept_btn = page.locator('text="åˆ©ç”¨è¦ç´„ã«åŒæ„ã™ã‚‹"')
                if accept_btn.count() > 0:
                    accept_btn.click()
                    page.wait_for_timeout(2000)
                    page.goto(url, timeout=20000, wait_until='domcontentloaded')
                    page.wait_for_timeout(2000)
            except:
                pass

            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            text = page.inner_text('body', timeout=30000)
            data = {'unit_id': unit_id, 'bb': 0, 'rb': 0, 'art': 0, 'total_start': 0, 'final_start': 0}

            # BB/RB/ART/ã‚¹ã‚¿ãƒ¼ãƒˆ
            match = re.search(r'BB\s+RB\s+ART\s+ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°\s*\n?\s*(\d+)\s+(\d+)\s+(\d+)\s+(\d+)', text)
            if match:
                data['bb'] = int(match.group(1))
                data['rb'] = int(match.group(2))
                data['art'] = int(match.group(3))
                data['final_start'] = int(match.group(4))

            # ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ
            total_match = re.search(r'ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ\s*\n?\s*(\d+)', text)
            if total_match:
                data['total_start'] = int(total_match.group(1))

            # å·®æš
            diff_match = re.search(r'å·®æš\s*\n?\s*([+-]?\d+)', text)
            if diff_match:
                data['diff_medals'] = int(diff_match.group(1))

            # æœ€å¤§ãƒ¡ãƒ€ãƒ«
            max_match = re.search(r'(?:æœ€å¤§ãƒ¡ãƒ€ãƒ«|æœ€å¤§æŒã¡ã‚³ã‚¤ãƒ³|æœ€å¤§æšæ•°|æœ€å¤§æŒã¡ç‰)\s*\n?\s*([\d,]+)', text)
            if max_match:
                data['max_medals'] = int(max_match.group(1).replace(',', ''))

            # å½“æ—¥å±¥æ­´
            try:
                history = []
                hits = re.findall(
                    r'0\s+(\d+)\s+(\d+)\s+(ART|BB|RB|AT|REG)\s+(\d{1,2}:\d{2})',
                    text
                )

                for i, match in enumerate(hits):
                    history.append({
                        'hit_num': i + 1,
                        'time': match[3],
                        'start': int(match[0]),
                        'medals': int(match[1]),
                        'type': match[2],
                    })

                if history:
                    data['today_history'] = history
                    # æœ€å¤§é€£ãƒãƒ£ãƒ³è¨ˆç®—
                    sorted_hist = sorted(history, key=lambda h: h['time'])
                    max_rensa = 1
                    current_rensa = 1
                    for j in range(1, len(sorted_hist)):
                        if sorted_hist[j]['start'] <= 70:
                            current_rensa += 1
                            max_rensa = max(max_rensa, current_rensa)
                        else:
                            current_rensa = 1
                    data['today_max_rensa'] = max_rensa
            except:
                pass

            return data

        except Exception as e:
            print(f"    âŒ {unit_id}: {e}")
            return None
        finally:
            browser.close()


def fetch_store(store_key, store_config):
    """1åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸¦åˆ—å–å¾—"""
    hall_id = store_config['hall_id']
    hall_name = store_config['name']
    units = store_config['units']

    print(f"\nğŸ”„ {hall_name} ({len(units)}å°) å–å¾—é–‹å§‹...")

    results = []
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = {executor.submit(fetch_unit_data, hall_id, uid, hall_name): uid for uid in units}

        for i, future in enumerate(as_completed(futures), 1):
            try:
                data = future.result(timeout=60)
                if data:
                    results.append(data)
                    if i % 5 == 0 or i == len(units):
                        print(f"  é€²æ—: {i}/{len(units)}å°")
            except Exception as e:
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")

    print(f"âœ… {hall_name} å®Œäº†: {len(results)}/{len(units)}å°")
    return {
        'store_key': store_key,
        'units': results,
        'fetched_at': datetime.now(JST).isoformat(),
    }


def main():
    print("=" * 60)
    print("ğŸš€ åŒ—æ–—è»¢ç”Ÿ2 ä¸¦åˆ—ãƒ‡ãƒ¼ã‚¿å–å¾—")
    print(f"å¯¾è±¡: {len(HOKUTO_STORES)}åº—èˆ—")
    print("=" * 60)

    # availability.jsonã‚’èª­ã¿è¾¼ã¿
    avail_path = PROJECT_ROOT / 'data' / 'availability.json'
    if avail_path.exists():
        with open(avail_path, 'r', encoding='utf-8') as f:
            avail_data = json.load(f)
    else:
        avail_data = {'stores': {}, 'fetched_at': datetime.now(JST).isoformat()}

    # å„åº—èˆ—ã‚’å–å¾—
    for store_key, store_config in HOKUTO_STORES.items():
        result = fetch_store(store_key, store_config)
        avail_data['stores'][store_key] = {
            'units': result['units'],
            'empty': [],
            'playing': [],
        }

    # availability.jsonã«ä¿å­˜
    avail_data['fetched_at'] = datetime.now(JST).isoformat()
    with open(avail_path, 'w', encoding='utf-8') as f:
        json.dump(avail_data, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 60)
    print("âœ… å®Œäº†ï¼availability.jsonã«ä¿å­˜ã—ã¾ã—ãŸ")
    print("=" * 60)


if __name__ == '__main__':
    main()
