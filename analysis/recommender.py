#!/usr/bin/env python3
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å°æ¨å¥¨ã‚·ã‚¹ãƒ†ãƒ 

éå»ãƒ‡ãƒ¼ã‚¿ï¼ˆé™çš„ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰+ å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’çµ„ã¿åˆã‚ã›ã¦
ä»Šæ‰“ã¤ã¹ãå°ã‚’æ¨å¥¨ã™ã‚‹

æ ¹æ‹ ãƒ‡ãƒ¼ã‚¿ï¼š
- éå»7æ—¥é–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆé€£ç¶šãƒ—ãƒ©ã‚¹/ãƒã‚¤ãƒŠã‚¹ï¼‰
- å‰æ—¥å‡¹ã¿â†’ç¿Œæ—¥ç‹™ã„ç›®ãƒ‘ã‚¿ãƒ¼ãƒ³
- å½“æ—¥ã®ä»–å°ã¨ã®ç¨¼åƒæ¯”è¼ƒ
- ARTç¢ºç‡ã®æ¨ç§»
"""

import json
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, List, Dict
import sys

sys.path.insert(0, str(Path(__file__).parent.parent))
from config.rankings import STORES, RANKINGS, get_rank, get_unit_ranking, MACHINES, get_machine_threshold, rank_up, rank_down
from analysis.analyzer import calculate_at_intervals, calculate_current_at_games, calculate_max_rensa

# æ©Ÿç¨®åˆ¥ã®è¨­å®šæƒ…å ±
# SBJ: è¨­å®š1=1/241.7(97.8%), è¨­å®š6=1/181.3(112.7%)
# åŒ—æ–—è»¢ç”Ÿ2: è¨­å®š1=1/366.0(97.6%), è¨­å®š6=1/273.1(114.9%)
MACHINE_SPECS = {
    'sbj': {
        'setting6_at_prob': 181.3,
        'setting1_at_prob': 241.7,
        'setting6_payout': 112.7,
        'setting1_payout': 97.8,
        # é–¾å€¤ï¼ˆè¡¨ç¤ºç”¨ï¼‰
        'excellent_prob': 80,   # è¨­å®š6è¶…ãˆ
        'high_prob': 100,       # é«˜è¨­å®šåŸŸ
        'mid_prob': 130,        # ä¸­é–“è¨­å®šåŸŸ
        'low_prob': 180,        # ä½è¨­å®šåŸŸå¢ƒç•Œ
        'very_low_prob': 250,   # ä½è¨­å®šåŸŸ
    },
    'hokuto_tensei2': {
        'setting6_at_prob': 273.1,
        'setting1_at_prob': 366.0,
        'setting6_payout': 114.9,
        'setting1_payout': 97.6,
        'excellent_prob': 250,
        'high_prob': 290,
        'mid_prob': 330,
        'low_prob': 366,
        'very_low_prob': 450,
    },
}

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚
MACHINE_THRESHOLDS = {
    'sbj': {
        'setting6_at_prob': 80,
        'high_at_prob': 100,
        'mid_at_prob': 130,
        'low_at_prob': 180,
        'very_low_at_prob': 250,
    },
    'hokuto_tensei2': {
        'setting6_at_prob': 273,
        'high_at_prob': 300,
        'mid_at_prob': 340,
        'low_at_prob': 366,
        'very_low_at_prob': 450,
    },
}


def estimate_setting_from_prob(art_prob: float, machine_key: str = 'sbj') -> dict:
    """ARTç¢ºç‡ã‹ã‚‰è¨­å®šã‚’æ¨å®šã—ã€æœŸå¾…å·®æšã‚’è¨ˆç®—

    Returns:
        {
            'estimated_setting': str,  # 'é«˜è¨­å®šæ¿ƒåš', 'é«˜è¨­å®šåŸŸ', 'ä¸­é–“', 'ä½è¨­å®šåŸŸ'
            'payout_estimate': float,  # æ¨å®šæ©Ÿæ¢°å‰²
            'hourly_expected': int,    # 1æ™‚é–“ã‚ãŸã‚ŠæœŸå¾…å·®æš
            'confidence': str,         # 'high', 'medium', 'low'
        }
    """
    specs = MACHINE_SPECS.get(machine_key, MACHINE_SPECS['sbj'])

    if art_prob <= 0:
        return {
            'estimated_setting': 'ä¸æ˜',
            'setting_num': 0,
            'payout_estimate': 100.0,
            'hourly_expected': 0,
            'confidence': 'none',
        }

    # è¨­å®š6ã¨è¨­å®š1ã®ARTç¢ºç‡ã‹ã‚‰æ©Ÿæ¢°å‰²ã‚’ç·šå½¢è£œé–“
    s6_prob = specs['setting6_at_prob']
    s1_prob = specs['setting1_at_prob']
    s6_payout = specs['setting6_payout']
    s1_payout = specs['setting1_payout']

    # ARTç¢ºç‡ãŒè¨­å®š6ã‚ˆã‚Šè‰¯ã„å ´åˆ
    if art_prob <= s6_prob:
        payout = s6_payout + (s6_prob - art_prob) * 0.1  # ã•ã‚‰ã«ä¸Šä¹—ã›
        setting = 'è¨­å®š6'
        setting_num = 6
        confidence = 'high'
    # è¨­å®š6ã€œè¨­å®š1ã®é–“
    elif art_prob <= s1_prob:
        ratio = (s1_prob - art_prob) / (s1_prob - s6_prob)
        payout = s1_payout + (s6_payout - s1_payout) * ratio
        # ratioã‚’è¨­å®šç•ªå·ã«å¤‰æ›ï¼ˆ1.0â†’6, 0.0â†’1ï¼‰
        setting_num = round(1 + ratio * 5)
        setting_num = max(1, min(6, setting_num))  # 1-6ã«ã‚¯ãƒ©ãƒ³ãƒ—
        setting = f'è¨­å®š{setting_num}'
        if ratio >= 0.8:
            confidence = 'high'
        elif ratio >= 0.5:
            confidence = 'medium'
        else:
            confidence = 'low'
    # è¨­å®š1ã‚ˆã‚Šæ‚ªã„å ´åˆ
    else:
        payout = s1_payout - (art_prob - s1_prob) * 0.05
        setting = 'è¨­å®š1'
        setting_num = 1
        confidence = 'low'

    # 1æ™‚é–“ã‚ãŸã‚Šã®æœŸå¾…å·®æšï¼ˆ700G/æ™‚é–“ Ã— 3æš/G Ã— (æ©Ÿæ¢°å‰²-100%)/100ï¼‰
    hourly_games = 700
    hourly_expected = int(hourly_games * 3 * (payout - 100) / 100)

    return {
        'estimated_setting': setting,
        'setting_num': setting_num,
        'payout_estimate': round(payout, 1),
        'hourly_expected': hourly_expected,
        'confidence': confidence,
    }


def calculate_expected_profit(total_games: int, art_count: int, machine_key: str = 'sbj') -> dict:
    """ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœŸå¾…å·®æšã‚’è¨ˆç®—

    Returns:
        {
            'current_estimate': int,      # ç¾åœ¨ã®æ¨å®šå·®æš
            'closing_estimate': int,      # é–‰åº—æ™‚ã®æ¨å®šå·®æš
            'remaining_hours': float,     # æ®‹ã‚Šæ™‚é–“
            'profit_category': str,       # '5000æš+', '3000æš+', '2000æš+', '1000æš+', 'ãƒ—ãƒ©ã‚¹', 'ãƒã‚¤ãƒŠã‚¹'
        }
    """
    now = datetime.now()
    closing_hour = 23  # é–‰åº—æ™‚åˆ»

    # æ®‹ã‚Šæ™‚é–“
    if now.hour >= closing_hour:
        remaining_hours = 0
    else:
        remaining_hours = closing_hour - now.hour - (now.minute / 60)

    # ARTç¢ºç‡ã‹ã‚‰è¨­å®šæ¨å®š
    art_prob = total_games / art_count if art_count > 0 else 0
    setting_info = estimate_setting_from_prob(art_prob, machine_key)

    # ç¾åœ¨ã®æ¨å®šå·®æšï¼ˆæŠ•å…¥æšæ•° Ã— (æ©Ÿæ¢°å‰²-100%)/100ï¼‰
    invested = total_games * 3  # 3æš/G
    current_estimate = int(invested * (setting_info['payout_estimate'] - 100) / 100)

    # é–‰åº—ã¾ã§ã®è¿½åŠ å·®æš
    additional = int(remaining_hours * setting_info['hourly_expected'])
    closing_estimate = current_estimate + additional

    # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
    if closing_estimate >= 5000:
        category = '5000æš+'
    elif closing_estimate >= 3000:
        category = '3000æš+'
    elif closing_estimate >= 2000:
        category = '2000æš+'
    elif closing_estimate >= 1000:
        category = '1000æš+'
    elif closing_estimate > 0:
        category = 'ãƒ—ãƒ©ã‚¹'
    elif closing_estimate > -1000:
        category = 'å¾®ãƒã‚¤ãƒŠã‚¹'
    else:
        category = 'ãƒã‚¤ãƒŠã‚¹'

    return {
        'current_estimate': current_estimate,
        'closing_estimate': closing_estimate,
        'remaining_hours': round(remaining_hours, 1),
        'profit_category': category,
        'setting_info': setting_info,
    }

# åº—èˆ—ã‚­ãƒ¼ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆconfig -> JSON dataï¼‰
STORE_KEY_MAPPING = {
    # SBJ
    'island_akihabara_sbj': 'island_akihabara_sbj',
    'island_akihabara': 'island_akihabara_sbj',
    'shibuya_espass_sbj': 'shibuya_espass_sbj',
    'shibuya_espass': 'shibuya_espass_sbj',
    'shinjuku_espass_sbj': 'shinjuku_espass_sbj',
    # åŒ—æ–—è»¢ç”Ÿ2
    'shibuya_espass_hokuto': 'shibuya_espass_hokuto_tensei2',
    'shinjuku_espass_hokuto': 'shinjuku_espass_hokuto_tensei2',
    'akiba_espass_hokuto': 'akiba_espass_hokuto_tensei2',
    'island_akihabara_hokuto': 'island_akihabara_hokuto_tensei2',
}

# åº—èˆ—åˆ¥æ›œæ—¥å‚¾å‘ãƒ‡ãƒ¼ã‚¿ï¼ˆâ˜…è©•ä¾¡ 1-5ï¼‰
WEEKDAY_NAMES = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
STORE_DAY_RATINGS = {
    'island_akihabara_sbj': {
        'short_name': 'ã‚¢ã‚¤ãƒ©ãƒ³ãƒ‰ç§‹è‘‰åŸ',
        'day_ratings': {'æœˆ': 4, 'ç«': 3, 'æ°´': 5, 'æœ¨': 3, 'é‡‘': 3, 'åœŸ': 1, 'æ—¥': 4},
        'best_days': 'æ°´æ›œãŒæœ€å¼·ã€æ—¥æœˆã‚‚ç‹™ã„ç›®',
        'worst_days': 'åœŸæ›œã¯é¿ã‘ã‚‹ã¹ã',
    },
    'shibuya_espass_sbj': {
        'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ¸‹è°·æ–°é¤¨',
        'day_ratings': {'æœˆ': 3, 'ç«': 4, 'æ°´': 4, 'æœ¨': 5, 'é‡‘': 3, 'åœŸ': 3, 'æ—¥': 1},
        'best_days': 'æœ¨æ›œãŒæœ€å¼·ã€ç«æ°´ã‚‚ç‹™ã„ç›®',
        'worst_days': 'æ—¥æ›œã¯é¿ã‘ã‚‹ã¹ã',
    },
    'shinjuku_espass_sbj': {
        'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹æ­Œèˆä¼ç”º',
        'day_ratings': {'æœˆ': 2, 'ç«': 3, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 5, 'æ—¥': 3},
        'best_days': 'åœŸæ›œãŒæœ€å¼·ã€é‡‘æ›œã‚‚ç‹™ã„ç›®',
        'worst_days': 'æœˆæ›œã¯æ§ãˆã‚',
    },
    'akiba_espass_sbj': {
        'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹ç§‹è‘‰åŸ',
        'day_ratings': {'æœˆ': 2, 'ç«': 3, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 5, 'æ—¥': 4},
        'best_days': 'åœŸæ—¥ãŒç‹™ã„ç›®ã€é‡‘æ›œã‚‚å¯',
        'worst_days': 'æœˆæ›œã¯æ§ãˆã‚',
    },
    'seibu_shinjuku_espass_sbj': {
        'short_name': 'ã‚¨ã‚¹ãƒ‘ã‚¹è¥¿æ­¦æ–°å®¿',
        'day_ratings': {'æœˆ': 2, 'ç«': 2, 'æ°´': 3, 'æœ¨': 3, 'é‡‘': 4, 'åœŸ': 4, 'æ—¥': 3},
        'best_days': 'é‡‘åœŸãŒç‹™ã„ç›®',
        'worst_days': 'æœˆç«ã¯æ§ãˆã‚',
    },
}


def get_store_weekday_info(store_key: str) -> dict:
    """åº—èˆ—ã®ä»Šæ—¥ã®æ›œæ—¥å‚¾å‘ã‚’è¿”ã™"""
    store_info = STORE_DAY_RATINGS.get(store_key, {})
    if not store_info:
        # åŒã˜åº—èˆ—ã®åˆ¥æ©Ÿç¨®ã‚­ãƒ¼ã‚’æ¢ã™ï¼ˆisland_akihabara_hokuto â†’ island_akihabara_sbjç­‰ï¼‰
        base = store_key.rsplit('_', 1)[0] if '_' in store_key else store_key
        for k, v in STORE_DAY_RATINGS.items():
            if k.startswith(base):
                store_info = v
                break
    if not store_info:
        return {}
    today_weekday = WEEKDAY_NAMES[datetime.now().weekday()]
    today_rating = store_info['day_ratings'].get(today_weekday, 3)
    return {
        'short_name': store_info['short_name'],
        'today_weekday': today_weekday,
        'today_rating': today_rating,
        'best_days': store_info['best_days'],
        'worst_days': store_info['worst_days'],
    }


def get_machine_from_store_key(store_key: str) -> str:
    """åº—èˆ—ã‚­ãƒ¼ã‹ã‚‰æ©Ÿç¨®ã‚­ãƒ¼ã‚’å–å¾—"""
    store = STORES.get(store_key)
    if store:
        return store.get('machine', 'sbj')
    # åº—èˆ—ã‚­ãƒ¼ã‹ã‚‰æ¨æ¸¬
    if 'hokuto' in store_key:
        return 'hokuto_tensei2'
    return 'sbj'


def get_machine_thresholds(machine_key: str) -> dict:
    """æ©Ÿç¨®åˆ¥ã®é–¾å€¤ã‚’å–å¾—"""
    return MACHINE_THRESHOLDS.get(machine_key, MACHINE_THRESHOLDS['sbj'])


def load_daily_data(date_str: str = None, machine_key: str = None) -> dict:
    """æ—¥åˆ¥åé›†ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

    Args:
        date_str: æ—¥ä»˜æ–‡å­—åˆ—ï¼ˆYYYYMMDDå½¢å¼ï¼‰ã€‚Noneã®å ´åˆã¯ä»Šæ—¥
        machine_key: æ©Ÿç¨®ã‚­ãƒ¼ï¼ˆ'sbj', 'hokuto_tensei2'ï¼‰ã€‚Noneã®å ´åˆã¯å…¨æ©Ÿç¨®ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆ

    Returns:
        èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿è¾æ›¸
    """
    if date_str is None:
        date_str = datetime.now().strftime('%Y%m%d')

    data_dir = Path(__file__).parent.parent / 'data' / 'daily'

    # æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™ï¼ˆå„ªå…ˆé †ä½é †ï¼‰
    patterns = [
        # è¤‡æ•°æ©Ÿç¨®ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæœ€å„ªå…ˆï¼‰
        f'daily_sbj_hokuto_tensei2_{date_str}.json',
        f'daily_all_{date_str}.json',
        # SBJå°‚ç”¨
        f'daily_sbj_{date_str}.json',
        f'sbj_daily_{date_str}.json',
        # åŒ—æ–—è»¢ç”Ÿ2å°‚ç”¨
        f'daily_hokuto_tensei2_{date_str}.json',
    ]

    # å…¨æ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆï¼ˆæœ€æ–°ã‚’å„ªå…ˆã—ã¤ã¤ã€å¤ã„æ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ã‚‚å–ã‚Šè¾¼ã‚€ï¼‰
    merged_data = {'stores': {}}
    found_dates = []

    # ä»Šæ—¥ + ç›´è¿‘7æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ã¦èª­ã¿è¾¼ã‚“ã§çµ±åˆ
    from datetime import timedelta
    base_date = datetime.strptime(date_str, '%Y%m%d')
    dates_to_check = [date_str] + [(base_date - timedelta(days=d)).strftime('%Y%m%d') for d in range(1, 8)]

    for check_date in dates_to_check:
        found_files = []
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ
        for pattern in patterns:
            file_path = data_dir / pattern.replace(date_str, check_date)
            if file_path.exists():
                found_files.append(file_path)
        # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰
        for wp in [f'daily_*_{check_date}.json', f'*_daily_{check_date}.json']:
            for match in data_dir.glob(wp):
                if match not in found_files:
                    found_files.append(match)

        for file_path in found_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                if machine_key:
                    machines = data.get('machines', [])
                    if machines and machine_key not in machines:
                        continue
                # åº—èˆ—ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆï¼ˆæ—¢ã«ã‚ã‚‹åº—èˆ—ã¯ä¸Šæ›¸ãã—ãªã„=æœ€æ–°å„ªå…ˆï¼‰
                for sk, sv in data.get('stores', {}).items():
                    if sk not in merged_data['stores']:
                        merged_data['stores'][sk] = sv
                        found_dates.append(check_date)
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
                for meta_key in ['machines', 'fetched_at', 'data_date']:
                    if meta_key in data and meta_key not in merged_data:
                        merged_data[meta_key] = data[meta_key]
            except Exception:
                pass

    # rawãƒ‡ãƒ¼ã‚¿ã§è£œå®Œï¼ˆå…¨æ—¥ä»˜ã®rawã‚’è©¦è¡Œã€‚æœ€æ–°ã‚’å„ªå…ˆï¼‰
    for check_date in dates_to_check:
        merged_data = _merge_raw_data(merged_data, check_date)

    if not merged_data.get('stores'):
        return {}

    return merged_data


def _merge_raw_data(daily_data: dict, date_str: str) -> dict:
    """rawãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®papimoç­‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’daily_dataã«è£œå®Œã™ã‚‹

    papimo rawãƒ‡ãƒ¼ã‚¿ï¼ˆãƒªã‚¹ãƒˆå½¢å¼ï¼‰ãŠã‚ˆã³daidata rawãƒ‡ãƒ¼ã‚¿ï¼ˆå€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’
    æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã«å¤‰æ›ã—ã¦ãƒãƒ¼ã‚¸
    """
    raw_dir = Path(__file__).parent.parent / 'data' / 'raw'
    if not raw_dir.exists():
        return daily_data

    stores = daily_data.get('stores', {})

    # --- papimo rawãƒ‡ãƒ¼ã‚¿ï¼ˆãƒªã‚¹ãƒˆå½¢å¼ï¼‰---
    for papimo_pattern, store_key in [
        (f'papimo_island_sbj_{date_str}_*.json', 'island_akihabara_sbj'),
        (f'papimo_island_hokuto_{date_str}_*.json', 'island_akihabara_hokuto_tensei2'),
    ]:
        papimo_files = sorted(raw_dir.glob(papimo_pattern), reverse=True)
        if not papimo_files:
            continue
        try:
            with open(papimo_files[0], 'r', encoding='utf-8') as f:
                raw_units = json.load(f)
            if isinstance(raw_units, list) and raw_units:
                existing = stores.get(store_key, {})
                existing_units = existing.get('units', [])
                existing_days = len(existing_units[0].get('days', [])) if existing_units else 0
                raw_days = len(raw_units[0].get('days', []))
                if raw_days > existing_days:
                    converted_units = []
                    for raw_unit in raw_units:
                        converted_units.append({
                            'unit_id': str(raw_unit.get('unit_id', '')),
                            'days': raw_unit.get('days', []),
                            'machine_key': raw_unit.get('machine_key'),
                        })
                    stores[store_key] = {
                        'units': converted_units,
                        'data_source': 'papimo_raw',
                    }
        except Exception:
            pass

    # --- daidata rawãƒ‡ãƒ¼ã‚¿ï¼ˆå€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«: sbj_UNITID_history_DATE_TIME.jsonï¼‰---
    # hall_id â†’ store_keyã®ãƒãƒƒãƒ”ãƒ³ã‚°
    HALL_STORE_MAP = {
        '100860': {'sbj': 'shibuya_espass_sbj', 'hokuto_tensei2': 'shibuya_espass_hokuto_tensei2'},
        '100949': {'sbj': 'shinjuku_espass_sbj', 'hokuto_tensei2': 'shinjuku_espass_hokuto_tensei2'},
        '100928': {'sbj': 'akiba_espass_sbj', 'hokuto_tensei2': 'akiba_espass_hokuto_tensei2'},
        '100950': {'sbj': 'seibu_shinjuku_espass_sbj', 'hokuto_tensei2': 'seibu_shinjuku_espass_hokuto_tensei2'},
    }
    from collections import defaultdict
    raw_by_store = defaultdict(list)  # store_key -> [unit_data, ...]

    raw_files = sorted(raw_dir.glob(f'sbj_*_history_{date_str}_*.json'))
    for raw_file in raw_files:
        try:
            with open(raw_file, 'r', encoding='utf-8') as f:
                raw_unit = json.load(f)
            if not isinstance(raw_unit, dict):
                continue
            hall_id = str(raw_unit.get('hall_id', ''))
            uid = str(raw_unit.get('unit_id', ''))
            days = raw_unit.get('days', [])
            if not hall_id or not uid or not days:
                continue
            # æ©Ÿç¨®åˆ¤å®š: BB=0ãªã‚‰åŒ—æ–—è»¢ç”Ÿ2ã€BB>0ãªã‚‰SBJ
            bb_total = sum(d.get('bb', 0) for d in days)
            machine_key = 'sbj' if bb_total > 0 else 'hokuto_tensei2'
            hall_map = HALL_STORE_MAP.get(hall_id)
            if not hall_map:
                continue
            store_key = hall_map.get(machine_key)
            if not store_key:
                continue
            raw_by_store[store_key].append({
                'unit_id': uid,
                'days': days,
                'machine_key': machine_key,
            })
        except Exception:
            pass

    # rawãƒ‡ãƒ¼ã‚¿ã‚’storesã«ãƒãƒ¼ã‚¸
    for store_key, raw_units in raw_by_store.items():
        existing = stores.get(store_key, {})
        existing_units = existing.get('units', [])
        existing_count = len(existing_units)
        raw_count = len(raw_units)
        # rawã®æ–¹ãŒå°æ•°ãŒå¤šã„å ´åˆã«ä¸Šæ›¸ã
        if raw_count > existing_count:
            stores[store_key] = {
                'units': raw_units,
                'data_source': 'daidata_raw',
            }

    daily_data['stores'] = stores
    return daily_data


def calculate_unit_historical_performance(days: List[dict], machine_key: str = 'sbj') -> dict:
    """ã€æ”¹å–„1ã€‘å°ç•ªå·ã”ã¨ã®éå»å®Ÿç¸¾ï¼ˆå¥½èª¿ç‡ï¼‰ã‚’è¨ˆç®—

    éå»ã®æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å„å°ã®ã€Œå¥½èª¿ç‡ã€ï¼ˆARTç¢ºç‡ãŒå¥½èª¿åŸŸã ã£ãŸæ—¥ã®å‰²åˆï¼‰ã‚’ç®—å‡ºã€‚
    åˆ†æçµæœ: å¸¸ã«çš„ä¸­ã™ã‚‹å°ã¨å¸¸ã«å¤–ã‚Œã‚‹å°ã§å¥½èª¿ç‡ã«æ˜ç¢ºãªå·®ãŒã‚ã‚‹ã€‚

    Args:
        days: éå»æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆï¼ˆtotal_start or games ã‚­ãƒ¼ã«å¯¾å¿œï¼‰
        machine_key: æ©Ÿç¨®ã‚­ãƒ¼

    Returns:
        {
            'good_day_rate': float,     # å¥½èª¿æ—¥ã®å‰²åˆ (0.0-1.0)
            'good_days': int,           # å¥½èª¿æ—¥æ•°
            'total_days': int,          # æœ‰åŠ¹æ—¥æ•°
            'score_bonus': float,       # ã‚¹ã‚³ã‚¢ãƒœãƒ¼ãƒŠã‚¹ (-8 to +10)
            'avg_prob': float,          # å¹³å‡ARTç¢ºç‡
            'consecutive_bad': int,     # ç›´è¿‘ã®é€£ç¶šä¸èª¿æ—¥æ•°
        }
    """
    def _get_games(day):
        """gamesãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å–å¾— â€” è“„ç©DB(games) or daily JSON(total_start)"""
        return day.get('games', 0) or day.get('total_start', 0)

    # æ©Ÿç¨®åˆ¥ã®å¥½èª¿åˆ¤å®šé–¾å€¤
    good_prob_threshold = get_machine_threshold(machine_key, 'good_prob')
    bad_prob_threshold = get_machine_threshold(machine_key, 'bad_prob')

    good_days = 0
    bad_days = 0
    total_days = 0
    probs = []
    consecutive_bad = 0  # ç›´è¿‘ã®é€£ç¶šä¸èª¿æ—¥æ•°

    # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
    sorted_days = sorted(days, key=lambda x: x.get('date', ''), reverse=True)

    for day in sorted_days:
        art = day.get('art', 0)
        games = _get_games(day)
        if art > 0 and games > 0:
            prob = games / art
            probs.append(prob)
            total_days += 1
            if prob <= good_prob_threshold:
                good_days += 1
            if prob >= bad_prob_threshold:
                bad_days += 1

    # ç›´è¿‘ã®é€£ç¶šä¸èª¿æ—¥æ•°ã‚’è¨ˆç®—
    for day in sorted_days:
        art = day.get('art', 0)
        games = _get_games(day)
        if art > 0 and games > 0:
            prob = games / art
            if prob >= bad_prob_threshold:
                consecutive_bad += 1
            else:
                break

    good_day_rate = good_days / total_days if total_days > 0 else 0.5
    avg_prob = sum(probs) / len(probs) if probs else 0

    # å¥½èª¿ç¿Œæ—¥â†’ç¿Œæ—¥ã‚‚å¥½èª¿ã ã£ãŸç‡ï¼ˆæ®ãˆç½®ãç‡ã®ç›®å®‰ï¼‰
    good_after_good = 0
    good_after_good_total = 0
    # sorted_daysã¯æ–°ã—ã„é †ãªã®ã§ã€iç•ªç›®ã®ç¿Œæ—¥ã¯i+1ç•ªç›®
    # ãŸã ã—æ—¥ä»˜é€£ç¶šã‚’ç¢ºèª
    for i in range(len(sorted_days) - 1):
        curr = sorted_days[i]
        nxt = sorted_days[i + 1]  # nxtã¯å‰æ—¥
        curr_art = curr.get('art', 0)
        curr_games = _get_games(curr)
        nxt_art = nxt.get('art', 0)
        nxt_games = _get_games(nxt)
        if nxt_art > 0 and nxt_games > 0:
            nxt_prob = nxt_games / nxt_art
            if nxt_prob <= good_prob_threshold:
                # å‰æ—¥ãŒå¥½èª¿ã ã£ãŸå ´åˆã€ç¿Œæ—¥(curr)ã‚‚å¥½èª¿ã‹ï¼Ÿ
                good_after_good_total += 1
                if curr_art > 0 and curr_games > 0:
                    curr_prob = curr_games / curr_art
                    if curr_prob <= good_prob_threshold:
                        good_after_good += 1
    continuation_rate = good_after_good / good_after_good_total if good_after_good_total > 0 else 0

    # ç›´è¿‘3æ—¥ã®ARTç¢ºç‡æ¨ç§»
    recent_probs = probs[:3]  # æ–°ã—ã„é †

    # ã‚¹ã‚³ã‚¢ãƒœãƒ¼ãƒŠã‚¹è¨ˆç®—
    # å¥½èª¿ç‡ãŒé«˜ã„å°ã«ãƒœãƒ¼ãƒŠã‚¹ã€ä½ã„å°ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæœ€å¤§Â±10ç‚¹ï¼‰
    if good_day_rate >= 0.8:
        score_bonus = 10  # 80%ä»¥ä¸Šå¥½èª¿ â†’ é«˜è¨­å®šãŒé »ç¹ã«å…¥ã‚‹å°
    elif good_day_rate >= 0.7:
        score_bonus = 7
    elif good_day_rate >= 0.6:
        score_bonus = 4
    elif good_day_rate >= 0.5:
        score_bonus = 0   # åŠã€… â†’ ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«
    elif good_day_rate >= 0.4:
        score_bonus = -3
    elif good_day_rate >= 0.3:
        score_bonus = -5
    else:
        score_bonus = -8  # 30%æœªæº€å¥½èª¿ â†’ ä½è¨­å®šãŒå…¥ã‚Šã‚„ã™ã„å°

    # å¥½èª¿æ—¥ã®è©³ç´°ï¼ˆçˆ†ç™ºãƒ¬ãƒ™ãƒ«åˆ†æç”¨ï¼‰
    good_day_details = []
    for d in sorted_days:
        art = d.get('art', 0)
        games = d.get('games', d.get('total_games', 0))
        if art > 0 and games > 0 and (games / art) <= good_prob_threshold:
            good_day_details.append({
                'date': d.get('date', ''),
                'art': art,
                'prob': games / art if art > 0 else 0,
                'max_rensa': d.get('max_rensa', 0),
                'max_medals': d.get('max_medals', 0),
            })

    # æœ€é•·é€£ç¶šå¥½èª¿è¨˜éŒ²
    max_consecutive_good = 0
    current_streak = 0
    for d in reversed(sorted_days):  # å¤ã„é †ã§èµ°æŸ»
        art = d.get('art', 0)
        games = d.get('games', d.get('total_games', 0))
        if art > 0 and games > 0 and (games / art) <= good_prob_threshold:
            current_streak += 1
            max_consecutive_good = max(max_consecutive_good, current_streak)
        else:
            current_streak = 0

    return {
        'good_day_rate': good_day_rate,
        'good_days': good_days,
        'total_days': total_days,
        'score_bonus': score_bonus,
        'avg_prob': avg_prob,
        'consecutive_bad': consecutive_bad,
        'continuation_rate': continuation_rate,         # å¥½èª¿ç¿Œæ—¥ã‚‚å¥½èª¿ã ã£ãŸç‡
        'continuation_total': good_after_good_total,    # ã‚µãƒ³ãƒ—ãƒ«æ•°
        'continuation_good': good_after_good,           # ç¿Œæ—¥ã‚‚å¥½èª¿ã ã£ãŸå›æ•°
        'recent_probs': recent_probs,                   # ç›´è¿‘3æ—¥ã®ARTç¢ºç‡ï¼ˆæ–°â†’å¤ï¼‰
        'good_day_details': good_day_details,           # å¥½èª¿æ—¥ã®è©³ç´°ãƒªã‚¹ãƒˆ
        'max_consecutive_good': max_consecutive_good,   # æœ€é•·é€£ç¶šå¥½èª¿è¨˜éŒ²
        'weekday_breakdown': _calc_weekday_breakdown(days, good_prob_threshold),  # æ›œæ—¥åˆ¥å¥½èª¿ç‡
    }


def _calc_weekday_breakdown(days: list, good_threshold: int) -> dict:
    """æ›œæ—¥åˆ¥ã®å¥½èª¿ç‡ã‚’è¨ˆç®—"""
    from datetime import datetime as _dt
    WDAYS = ['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥']
    stats = {w: {'good': 0, 'total': 0} for w in WDAYS}
    for day in days:
        date_str = day.get('date', '')
        art = day.get('art', 0)
        games = day.get('games', 0) or day.get('total_start', 0)
        if date_str and art > 0 and games > 0:
            try:
                wd = WDAYS[_dt.strptime(date_str, '%Y-%m-%d').weekday()]
                stats[wd]['total'] += 1
                if games / art <= good_threshold:
                    stats[wd]['good'] += 1
            except:
                pass
    return stats


def analyze_activity_pattern(history: List[dict], day_data: dict = None) -> dict:
    """ã€æ”¹å–„4ã€‘ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆæ™‚åˆ»ãƒ‡ãƒ¼ã‚¿æ´»ç”¨ï¼‰

    å½“ãŸã‚Šå±¥æ­´ã®æ™‚åˆ»ã‹ã‚‰ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ:
    - ç²˜ã‚Šåº¦: æœã‹ã‚‰é–‰åº—ã¾ã§æ‰“ãŸã‚Œã¦ã‚‹å°ã¯é«˜è¨­å®šã®å¯èƒ½æ€§UP
    - é€”ä¸­æ”¾æ£„: å½“ãŸã‚Šé–“ã®æ™‚é–“å·®1æ™‚é–“ä»¥ä¸Š = é›¢å¸­åˆ¤å®š
    - å¥½èª¿å°ã®é€”ä¸­æ”¾æ£„ = ãŠã„ã—ã„å°ï¼ˆãƒœãƒ¼ãƒŠã‚¹ï¼‰
    - ä¸èª¿å°ã®é€”ä¸­æ”¾æ£„ = ä½è¨­å®šã¨è¦‹åˆ‡ã‚‰ã‚ŒãŸï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
    - 100-200Gã§ã‚„ã‚ã¦ã‚‹å° = ç‹™ã„ç›®ï¼ˆå¤©äº•ç‹™ã„ä½™åœ°ï¼‰

    Args:
        history: å½“æ—¥ã®å½“ãŸã‚Šå±¥æ­´ãƒªã‚¹ãƒˆ
        day_data: å½“æ—¥ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆart, total_startç­‰ï¼‰

    Returns:
        {
            'persistence_score': float,    # ç²˜ã‚Šåº¦ã‚¹ã‚³ã‚¢ (-5 to +8)
            'abandonment_type': str,       # 'none', 'good_abandoned', 'bad_abandoned', 'early_quit'
            'abandonment_bonus': float,    # é€”ä¸­æ”¾æ£„ãƒœãƒ¼ãƒŠã‚¹ (-5 to +5)
            'play_duration_hours': float,  # ç¨¼åƒæ™‚é–“
            'gap_count': int,              # 1æ™‚é–“ä»¥ä¸Šã®ç©ºãã®å›æ•°
            'is_hyena_target': bool,       # ãƒã‚¤ã‚¨ãƒŠå¯¾è±¡ã‹ã€æ”¹å–„5ã€‘
            'hyena_penalty': float,        # ãƒã‚¤ã‚¨ãƒŠãƒšãƒŠãƒ«ãƒ†ã‚£ (0 to -5)
            'description': str,
        }
    """
    result = {
        'persistence_score': 0,
        'abandonment_type': 'none',
        'abandonment_bonus': 0,
        'play_duration_hours': 0,
        'gap_count': 0,
        'is_hyena_target': False,
        'hyena_penalty': 0,
        'description': '',
    }

    if not history or len(history) < 2:
        return result

    # æ™‚åˆ»é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_hist = sorted(history, key=lambda x: x.get('time', '00:00'))

    # ç¨¼åƒæ™‚é–“ã‚’è¨ˆç®—
    try:
        first_time = datetime.strptime(sorted_hist[0].get('time', '10:00'), '%H:%M')
        last_time = datetime.strptime(sorted_hist[-1].get('time', '10:00'), '%H:%M')
        duration_hours = (last_time - first_time).total_seconds() / 3600
        result['play_duration_hours'] = max(0, duration_hours)
    except:
        return result

    # --- ç²˜ã‚Šåº¦åˆ†æ ---
    # æœï¼ˆ10:00-11:00ï¼‰ã‹ã‚‰å§‹ã¾ã‚Šã€å¤œï¼ˆ19:00ä»¥é™ï¼‰ã¾ã§æ‰“ã¡ç¶šã‘ãŸå°ã¯é«˜è¨­å®šå¯èƒ½æ€§UP
    first_hour = first_time.hour
    last_hour = last_time.hour

    if first_hour <= 11 and last_hour >= 19:
        # æœã‹ã‚‰é–‰åº—è¿‘ãã¾ã§ç²˜ã£ã¦ã„ã‚‹ â†’ é«˜è¨­å®šã®å¯èƒ½æ€§
        result['persistence_score'] = 8
        result['description'] = 'æœã‹ã‚‰å¤œã¾ã§ç²˜ã‚Š â†’ é«˜è¨­å®šã®å¯èƒ½æ€§'
    elif first_hour <= 11 and last_hour >= 17:
        result['persistence_score'] = 5
        result['description'] = 'æœã‹ã‚‰å¤•æ–¹ã¾ã§ç¨¼åƒ'
    elif first_hour <= 11 and last_hour < 15:
        # æœã‹ã‚‰å§‹ã‚ã¦åˆå¾Œæ—©ã‚ã«ã‚„ã‚ãŸ â†’ è¦‹åˆ‡ã‚Šã®å¯èƒ½æ€§
        result['persistence_score'] = -3
        result['description'] = 'æœã‹ã‚‰ç¨¼åƒã‚‚æ—©ã‚ã«æ’¤é€€'
    elif first_hour >= 15:
        # å¤•æ–¹ä»¥é™ã‹ã‚‰ç¨¼åƒ â†’ å¤©äº•ç‹™ã„ or ç©ºãå°ç‹™ã„ã®å¯èƒ½æ€§
        result['persistence_score'] = -2
        result['description'] = 'å¤•æ–¹ä»¥é™ã‹ã‚‰ç¨¼åƒï¼ˆãƒã‚¤ã‚¨ãƒŠã®å¯èƒ½æ€§ï¼‰'

    # --- é€”ä¸­æ”¾æ£„åˆ†æ ---
    gap_count = 0
    max_gap_minutes = 0
    gap_positions = []  # ç©ºããŒç™ºç”Ÿã—ãŸä½ç½®

    for i in range(1, len(sorted_hist)):
        try:
            t1 = datetime.strptime(sorted_hist[i-1].get('time', '00:00'), '%H:%M')
            t2 = datetime.strptime(sorted_hist[i].get('time', '00:00'), '%H:%M')
            gap_minutes = (t2 - t1).total_seconds() / 60

            if gap_minutes >= 60:  # 1æ™‚é–“ä»¥ä¸Šã®ç©ºã = é›¢å¸­åˆ¤å®š
                gap_count += 1
                max_gap_minutes = max(max_gap_minutes, gap_minutes)
                gap_positions.append(i)
        except:
            continue

    result['gap_count'] = gap_count

    if gap_count > 0:
        # ç©ºãã®å‰ã¾ã§ã®ç¢ºç‡ã‚’è¨ˆç®—ï¼ˆå¥½èª¿å°ã®é€”ä¸­æ”¾æ£„ã‹ã©ã†ã‹ï¼‰
        art = day_data.get('art', 0) if day_data else 0
        games = day_data.get('total_start', 0) if day_data else 0
        overall_prob = games / art if art > 0 and games > 0 else 999

        if overall_prob <= 130:
            # å¥½èª¿å°ãªã®ã«é€”ä¸­æ”¾æ£„ = ãŠã„ã—ã„å°ï¼ˆãƒœãƒ¼ãƒŠã‚¹ï¼‰
            result['abandonment_type'] = 'good_abandoned'
            result['abandonment_bonus'] = 5
            result['description'] = f'å¥½èª¿å°(1/{overall_prob:.0f})ãŒé€”ä¸­æ”¾æ£„ â†’ ãŠã„ã—ã„å°'
        elif overall_prob >= 180:
            # ä¸èª¿å°ã®é€”ä¸­æ”¾æ£„ = ä½è¨­å®šã¨è¦‹åˆ‡ã‚‰ã‚ŒãŸï¼ˆãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
            result['abandonment_type'] = 'bad_abandoned'
            result['abandonment_bonus'] = -5
            result['description'] = f'ä¸èª¿å°(1/{overall_prob:.0f})ãŒè¦‹åˆ‡ã‚‰ã‚ŒãŸ â†’ ä½è¨­å®šç–‘ã„'
        else:
            result['abandonment_type'] = 'neutral_abandoned'
            result['abandonment_bonus'] = 0

    # --- æ—©æœŸæ’¤é€€åˆ†æï¼ˆ100-200Gã§ã‚„ã‚ã¦ã‚‹å°ï¼‰ ---
    if sorted_hist:
        last_start = sorted_hist[-1].get('start', 0)
        # æœ€çµ‚å½“ãŸã‚ŠãŒ100-200Gã®å°‘ãªã„Gæ•°ã§ã€ã‹ã¤ç¨¼åƒæ™‚é–“ãŒçŸ­ã„
        if day_data:
            final_start = day_data.get('final_start', 0)
            if 100 <= final_start <= 200:
                result['description'] = f'æœ€çµ‚{final_start}Gã§ã‚„ã‚ â†’ å¤©äº•ç‹™ã„ä½™åœ°ã‚ã‚Š'

    # --- ã€æ”¹å–„5ã€‘ãƒã‚¤ã‚¨ãƒŠæ¤œçŸ¥ ---
    # å¤•æ–¹ä»¥é™ï¼ˆ16æ™‚ä»¥é™ï¼‰ã«æ€¥ã«å½“ãŸã‚Šå§‹ã‚ãŸå° = å¤©äº•ç‹™ã„ã®å¯èƒ½æ€§
    evening_hits = [h for h in sorted_hist if h.get('time', '00:00') >= '16:00']
    morning_hits = [h for h in sorted_hist if h.get('time', '00:00') < '16:00']

    if len(evening_hits) > 0 and len(morning_hits) == 0:
        # å¤•æ–¹ä»¥é™ã«ã—ã‹å½“ãŸã‚ŠãŒãªã„ â†’ ãƒã‚¤ã‚¨ãƒŠã®å¯èƒ½æ€§
        result['is_hyena_target'] = True
        result['hyena_penalty'] = -5
        result['description'] = 'å¤•æ–¹ä»¥é™ã®ã¿ç¨¼åƒ â†’ ãƒã‚¤ã‚¨ãƒŠã®å¯èƒ½æ€§ï¼ˆé«˜è¨­å®šã¨ã¯é™ã‚‰ãªã„ï¼‰'
    elif len(evening_hits) > len(morning_hits) * 2 and len(evening_hits) >= 10:
        # å¤•æ–¹ä»¥é™ã«å½“ãŸã‚ŠãŒé›†ä¸­ â†’ å¤©äº•ç‹™ã„å¾Œã®é€£ãƒãƒ£ãƒ³ã®å¯èƒ½æ€§
        result['is_hyena_target'] = True
        result['hyena_penalty'] = -3
        result['description'] = 'å¤•æ–¹ä»¥é™ã«å½“ãŸã‚Šé›†ä¸­ â†’ ãƒã‚¤ã‚¨ãƒŠå¾Œã®é€£ãƒãƒ£ãƒ³ã®å¯èƒ½æ€§'

    return result


def analyze_trend(days: List[dict], machine_key: str = 'sbj') -> dict:
    """éå»æ—¥ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ

    Returns:
        {
            'consecutive_plus': int,  # é€£ç¶šãƒ—ãƒ©ã‚¹æ—¥æ•°
            'consecutive_minus': int, # é€£ç¶šãƒã‚¤ãƒŠã‚¹æ—¥æ•°
            'trend': str,  # 'up', 'down', 'flat'
            'yesterday_result': str,  # 'plus', 'minus', 'unknown'
            'yesterday_diff': int,  # æ˜¨æ—¥ã®æ¨å®šå·®æš
            'avg_art_7days': float,  # 7æ—¥é–“å¹³å‡ART
            'avg_games_7days': float,  # 7æ—¥é–“å¹³å‡Gæ•°
            'best_day': dict,  # æœ€é«˜ã®æ—¥
            'worst_day': dict,  # æœ€æ‚ªã®æ—¥
            'art_trend': str,  # ARTç¢ºç‡ã®å‚¾å‘
            'reasons': list,  # ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ ¹æ‹ 
        }
    """
    result = {
        'consecutive_plus': 0,
        'consecutive_minus': 0,
        'trend': 'flat',
        'yesterday_result': 'unknown',
        'yesterday_diff': 0,
        'avg_art_7days': 0,
        'avg_games_7days': 0,
        'best_day': None,
        'worst_day': None,
        'art_trend': 'flat',
        'reasons': [],
    }

    if not days:
        return result

    # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
    sorted_days = sorted(days, key=lambda x: x.get('date', ''), reverse=True)

    # 7æ—¥é–“ã®çµ±è¨ˆ
    art_counts = []
    game_counts = []
    daily_results = []  # [(date, estimated_diff), ...]

    for day in sorted_days[:7]:
        art = day.get('art', 0)
        games = day.get('total_start', 0)
        art_counts.append(art)
        game_counts.append(games)

        # å·®æšæ¨å®šï¼ˆhistoryã®medalsãŒã‚ã‚Œã°æ­£ç¢ºã«è¨ˆç®—ã€ãªã‘ã‚Œã°ç¢ºç‡ãƒ™ãƒ¼ã‚¹ï¼‰
        if games > 0:
            estimated_diff = 0
            hist = day.get('history', [])
            if hist:
                # historyãŒã‚ã‚Œã°å®Ÿmedalsãƒ™ãƒ¼ã‚¹ã§å·®æšæ¨å®š
                try:
                    from analysis.diff_medals_estimator import estimate_diff_medals
                    medals_total = sum(h.get('medals', 0) for h in hist)
                    estimated_diff = estimate_diff_medals(medals_total, games, machine_key)
                except Exception:
                    pass
            if estimated_diff == 0 and art > 0:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç¢ºç‡ãƒ™ãƒ¼ã‚¹æ¨å®š
                art_prob = games / art
                if art_prob <= 80:
                    estimated_diff = games * 0.3
                elif art_prob <= 120:
                    estimated_diff = games * 0.1
                elif art_prob <= 180:
                    estimated_diff = -games * 0.05
                else:
                    estimated_diff = -games * 0.15
            elif estimated_diff == 0:
                estimated_diff = -games * 0.2
            daily_results.append((day.get('date'), estimated_diff, art, games))
        elif art > 0:
            daily_results.append((day.get('date'), 0, art, games))

    if art_counts:
        result['avg_art_7days'] = sum(art_counts) / len(art_counts)
    if game_counts:
        result['avg_games_7days'] = sum(game_counts) / len(game_counts)

    # é€£ç¶šãƒ—ãƒ©ã‚¹/ãƒã‚¤ãƒŠã‚¹åˆ¤å®š
    # ä½ç¨¼åƒæ—¥ã®æ‰±ã„:
    #   - ç¢ºç‡ãŒå¥½èª¿åŸŸï¼ˆprob <= good_thresholdï¼‰â†’ ãƒ—ãƒ©ã‚¹ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆï¼ˆå³ã‚„ã‚=é«˜è¨­å®šã®å¯èƒ½æ€§ï¼‰
    #   - ç¢ºç‡ãŒä¸èª¿åŸŸ â†’ ãƒã‚¤ãƒŠã‚¹ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆ
    #   - ãƒ‡ãƒ¼ã‚¿æ¥µå°‘ï¼ˆART<3ã‹ã¤G<500ï¼‰â†’ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆåˆ¤å®šä¸èƒ½ï¼‰
    good_prob_threshold = get_machine_threshold(machine_key, 'good_prob')
    consecutive_plus = 0
    consecutive_minus = 0
    for date, diff, art, games in daily_results:
        if art < 3 and games < 500 and games > 0:
            # æ¥µå°‘ãƒ‡ãƒ¼ã‚¿ï¼ˆå³ã‚„ã‚ç­‰ï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé€£ç¶šã‚’é€”åˆ‡ã‚Œã•ã›ãªã„ï¼‰
            continue
        if diff > 0:
            consecutive_plus += 1
            consecutive_minus = 0
        elif diff < 0:
            # ä½ç¨¼åƒã§ãƒã‚¤ãƒŠã‚¹ã ãŒç¢ºç‡ãŒè‰¯ã„å ´åˆã¯ãƒ—ãƒ©ã‚¹æ‰±ã„
            if art > 0 and games > 0:
                prob = games / art
                if prob <= good_prob_threshold:
                    consecutive_plus += 1
                    consecutive_minus = 0
                    continue
            consecutive_minus += 1
            consecutive_plus = 0
        elif games == 0 and art > 0:
            continue
        else:
            break

    result['consecutive_plus'] = consecutive_plus
    result['consecutive_minus'] = consecutive_minus

    # æ˜¨æ—¥ã®çµæœ
    if daily_results:
        yesterday_date, yesterday_diff, yesterday_art, yesterday_games = daily_results[0]
        result['yesterday_diff'] = int(yesterday_diff)
        result['yesterday_art'] = yesterday_art  # æ˜¨æ—¥ã®ARTæ•°ã‚’è¿½åŠ 
        result['yesterday_games'] = int(yesterday_games)  # æ˜¨æ—¥ã®Gæ•°
        if yesterday_diff > 500:
            result['yesterday_result'] = 'big_plus'
        elif yesterday_diff > 0:
            result['yesterday_result'] = 'plus'
        elif yesterday_diff < -500:
            result['yesterday_result'] = 'big_minus'
        elif yesterday_diff < 0:
            result['yesterday_result'] = 'minus'
        else:
            result['yesterday_result'] = 'even'

    # æ˜¨æ—¥ã®RBãƒ»æœ€å¤§é€£ãƒãƒ£ãƒ³ãƒ»æœ€å¤§æšæ•°ã‚’å–å¾—
    if sorted_days:
        yesterday_day = sorted_days[0]
        result['yesterday_rb'] = yesterday_day.get('rb', 0)
        result['yesterday_date'] = yesterday_day.get('date', '')
        # æ˜¨æ—¥ã®æœ€å¤§é€£ãƒãƒ£ãƒ³æ•°ãƒ»æœ€å¤§é€£ãƒãƒ£ãƒ³æšæ•°
        yesterday_history = yesterday_day.get('history', [])
        if yesterday_history:
            from analysis.analyzer import calculate_max_chain_medals
            result['yesterday_max_rensa'] = calculate_max_rensa(yesterday_history)
            result['yesterday_max_medals'] = calculate_max_chain_medals(yesterday_history)
            result['yesterday_history'] = yesterday_history
        else:
            result['yesterday_max_medals'] = yesterday_day.get('max_medals', 0)

    # å‰ã€…æ—¥ã®çµæœ
    if len(daily_results) >= 2:
        db_date, db_diff, db_art, db_games = daily_results[1]
        result['day_before_art'] = db_art
        result['day_before_games'] = int(db_games)
        result['day_before_date'] = db_date
        result['day_before_diff_medals'] = int(db_diff) if db_diff else 0
    if len(sorted_days) >= 2:
        result['day_before_rb'] = sorted_days[1].get('rb', 0)
        db_history = sorted_days[1].get('history', [])
        if db_history:
            from analysis.analyzer import calculate_max_chain_medals
            result['day_before_max_rensa'] = calculate_max_rensa(db_history)
            result['day_before_max_medals'] = calculate_max_chain_medals(db_history)
        else:
            result['day_before_max_rensa'] = sorted_days[1].get('max_rensa', 0)
            result['day_before_max_medals'] = sorted_days[1].get('max_medals', 0)

    # 3æ—¥å‰ã®çµæœ
    if len(daily_results) >= 3:
        td_date, td_diff, td_art, td_games = daily_results[2]
        result['three_days_ago_art'] = td_art
        result['three_days_ago_games'] = int(td_games)
        result['three_days_ago_date'] = td_date
        result['three_days_ago_diff_medals'] = int(td_diff) if td_diff else 0
    if len(sorted_days) >= 3:
        result['three_days_ago_rb'] = sorted_days[2].get('rb', 0)
        td_history = sorted_days[2].get('history', [])
        if td_history:
            from analysis.analyzer import calculate_max_chain_medals
            result['three_days_ago_max_rensa'] = calculate_max_rensa(td_history)
            result['three_days_ago_max_medals'] = calculate_max_chain_medals(td_history)
        else:
            result['three_days_ago_max_rensa'] = sorted_days[2].get('max_rensa', 0)
            result['three_days_ago_max_medals'] = sorted_days[2].get('max_medals', 0)

    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
    if consecutive_plus >= 3:
        result['trend'] = 'strong_up'
        result['reasons'].append(f'{consecutive_plus}æ—¥é€£ç¶šãƒ—ãƒ©ã‚¹æ¨å®š')
    elif consecutive_plus >= 2:
        result['trend'] = 'up'
        result['reasons'].append(f'{consecutive_plus}æ—¥é€£ç¶šãƒ—ãƒ©ã‚¹æ¨å®š')
    elif consecutive_minus >= 3:
        result['trend'] = 'strong_down'
        result['reasons'].append(f'{consecutive_minus}æ—¥é€£ç¶šãƒã‚¤ãƒŠã‚¹æ¨å®š')
    elif consecutive_minus >= 2:
        result['trend'] = 'down'
        result['reasons'].append(f'{consecutive_minus}æ—¥é€£ç¶šãƒã‚¤ãƒŠã‚¹æ¨å®š')

    # æœ€é«˜/æœ€æ‚ªã®æ—¥
    if daily_results:
        best = max(daily_results, key=lambda x: x[1])
        worst = min(daily_results, key=lambda x: x[1])
        result['best_day'] = {'date': best[0], 'diff': int(best[1]), 'art': best[2]}
        result['worst_day'] = {'date': worst[0], 'diff': int(worst[1]), 'art': worst[2]}

    # ARTç¢ºç‡ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆç›´è¿‘3æ—¥ vs 4-7æ—¥å‰ï¼‰
    if len(art_counts) >= 5:
        recent_avg = sum(art_counts[:3]) / 3
        older_avg = sum(art_counts[3:min(7, len(art_counts))]) / min(4, len(art_counts) - 3)
        if recent_avg > older_avg * 1.2:
            result['art_trend'] = 'improving'
            result['reasons'].append('ç›´è¿‘ARTç¢ºç‡æ”¹å–„å‚¾å‘')
        elif recent_avg < older_avg * 0.8:
            result['art_trend'] = 'declining'
            result['reasons'].append('ç›´è¿‘ARTç¢ºç‡æ‚ªåŒ–å‚¾å‘')

    # --- ã€æ”¹å–„2ã€‘å‰æ—¥ãƒ»å‰ã€…æ—¥ã®ARTç¢ºç‡ã‚’è¨ˆç®—ï¼ˆä¸èª¿â†’ç¿Œæ—¥ç‹™ã„ç›®åˆ¤å®šç”¨ï¼‰ ---
    if sorted_days:
        d = sorted_days[0]
        art = d.get('art', 0)
        games = d.get('total_start', 0)
        if art > 0 and games > 0:
            result['yesterday_prob'] = games / art
        else:
            result['yesterday_prob'] = 0
    if len(sorted_days) >= 2:
        d = sorted_days[1]
        art = d.get('art', 0)
        games = d.get('total_start', 0)
        if art > 0 and games > 0:
            result['day_before_prob'] = games / art
        else:
            result['day_before_prob'] = 0

    # --- å®Ÿç”¨æŒ‡æ¨™ã®è¨ˆç®— ---

    # ATé–“ï¼ˆARTâ†’ARTé–“ã®Gæ•°ï¼‰ã‚’å±¥æ­´ã‹ã‚‰æ­£ã—ãè¨ˆç®—
    # RBã‚’è·¨ã„ã§ARTåˆ°é”ã¾ã§ã®ç·Gæ•°ã‚’ç®—å‡º
    all_at_intervals = []
    for day in sorted_days[:7]:
        history = day.get('history', [])
        if history:
            day_intervals = calculate_at_intervals(history)
            all_at_intervals.extend(day_intervals)

    if all_at_intervals:
        result['avg_at_interval'] = sum(all_at_intervals) / len(all_at_intervals)
        result['max_at_interval'] = max(all_at_intervals)
        result['ceiling_count'] = sum(1 for g in all_at_intervals if g >= 999)
    else:
        result['avg_at_interval'] = 0
        result['max_at_interval'] = 0
        result['ceiling_count'] = 0

    # ARTç¢ºç‡ï¼ˆtotal_start / art_countï¼‰
    art_probs = []
    for day in sorted_days[:7]:
        art = day.get('art', 0)
        games = day.get('total_start', 0)
        if art > 0 and games > 0:
            art_probs.append(games / art)
    if art_probs:
        result['avg_art_prob'] = sum(art_probs) / len(art_probs)
    else:
        result['avg_art_prob'] = 0

    # æœ€å¤§å‡ºç‰æ—¥ã®æƒ…å ±
    max_art_day = None
    if sorted_days:
        max_art_day = max(sorted_days[:7], key=lambda x: x.get('art', 0))
        result['max_art_day'] = {
            'date': max_art_day.get('date', ''),
            'art': max_art_day.get('art', 0),
            'games': max_art_day.get('total_start', 0),
        }

    # ç›´è¿‘7æ—¥åˆ†ã®ã‚µãƒãƒªé…åˆ—ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¡¨ç¤ºç”¨ï¼‰
    recent_days = []
    for d in sorted_days[:7]:
        art = d.get('art', 0)
        games = d.get('games', 0) or d.get('total_start', 0)
        prob = games / art if art > 0 and games > 0 else 0
        # max_medals: historyãŒã‚ã‚Œã°é€£ãƒãƒ£ãƒ³ç´¯è¨ˆã§è¨ˆç®—
        day_history = d.get('history', [])
        if day_history:
            from analysis.analyzer import calculate_max_chain_medals
            day_max_medals = calculate_max_chain_medals(day_history)
        else:
            day_max_medals = d.get('max_medals', 0)

        recent_days.append({
            'date': d.get('date', ''),
            'art': art,
            'rb': d.get('rb', 0),
            'games': games,
            'prob': round(prob, 1) if prob > 0 else 0,
            'max_rensa': d.get('max_rensa', 0),
            'max_medals': day_max_medals,
            'history': day_history,
        })
    result['recent_days'] = recent_days

    return result


def analyze_today_data(unit_data: dict, current_hour: int = None, machine_key: str = 'sbj') -> dict:
    """å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ

    Args:
        unit_data: å°ãƒ‡ãƒ¼ã‚¿ã€‚'days'ã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆã¯æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã€
                   ãªã„å ´åˆã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ï¼ˆç›´æ¥å½“æ—¥ãƒ‡ãƒ¼ã‚¿ï¼‰ã¨ã—ã¦æ‰±ã†
        current_hour: ç¾åœ¨æ™‚åˆ»ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
        machine_key: æ©Ÿç¨®ã‚­ãƒ¼ï¼ˆ'sbj', 'hokuto_tensei2'ï¼‰- é–¾å€¤åˆ¤å®šã«ä½¿ç”¨
    """
    if current_hour is None:
        current_hour = datetime.now().hour

    result = {
        'art_count': 0,
        'bb_count': 0,
        'rb_count': 0,
        'total_games': 0,
        'art_prob': 0,
        'last_hit_time': None,
        'first_hit_time': None,
        'is_running': False,
        'today_score_bonus': 0,
        'status': '-',
        'hourly_rate': 0,  # 1æ™‚é–“ã‚ãŸã‚Šã®ARTæ•°
        'expected_games': 0,  # ã“ã®æ™‚é–“å¸¯ã§ã®æœŸå¾…Gæ•°
        'today_reasons': [],
        'data_date': '',  # ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜
        'is_today_data': False,  # æœ¬æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‹ã©ã†ã‹
    }

    if not unit_data:
        return result

    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿å½¢å¼ï¼ˆdaysã‚­ãƒ¼ãªã—ï¼‰ã®å ´åˆ
    if 'days' not in unit_data:
        today_data = unit_data
        result['status'] = 'ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ '
        result['data_date'] = datetime.now().strftime('%Y-%m-%d')
        result['is_today_data'] = True
    else:
        # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®å ´åˆ
        days = unit_data.get('days', [])
        if not days:
            return result

        today = datetime.now().strftime('%Y-%m-%d')
        yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        today_data = None
        yesterday_data = None

        for day in days:
            if day.get('date') == today:
                today_data = day
                break
            elif day.get('date') == yesterday:
                yesterday_data = day

        if not today_data:
            # å½“æ—¥ãƒ‡ãƒ¼ã‚¿ãªã— â†’ æ˜¨æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            if yesterday_data:
                today_data = yesterday_data
                result['status'] = 'æ˜¨æ—¥ãƒ‡ãƒ¼ã‚¿'
                result['data_date'] = yesterday
                result['today_reasons'].append('æœ¬æ—¥ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆæ˜¨æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºï¼‰')
            else:
                result['status'] = 'ãƒ‡ãƒ¼ã‚¿ãªã—'
                result['today_score_bonus'] = 5  # æœªç¨¼åƒå°ã¯ç‹™ã„ç›®ã®å¯èƒ½æ€§
                result['today_reasons'].append('æœ¬æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆç‹™ã„ç›®ã®å¯èƒ½æ€§ï¼‰')
                return result
        else:
            result['data_date'] = today
            result['status'] = 'æœ¬æ—¥ãƒ‡ãƒ¼ã‚¿'
            result['is_today_data'] = True

    result['art_count'] = today_data.get('art', 0)
    result['bb_count'] = today_data.get('bb', 0)
    result['rb_count'] = today_data.get('rb', 0)
    result['total_games'] = today_data.get('total_start', 0)

    if result['art_count'] > 0 and result['total_games'] > 0:
        result['art_prob'] = result['total_games'] / result['art_count']

    # å±¥æ­´ã‹ã‚‰æ™‚é–“æƒ…å ±ã‚’å–å¾—
    history = today_data.get('history', [])
    if history:
        # æ™‚é–“é †ã§ã‚½ãƒ¼ãƒˆ
        sorted_history = sorted(history, key=lambda x: x.get('time', '00:00'))
        result['first_hit_time'] = sorted_history[0].get('time')
        result['last_hit_time'] = sorted_history[-1].get('time')

        # 1æ™‚é–“ã‚ãŸã‚Šã®ARTæ•°ã‚’è¨ˆç®—
        if result['first_hit_time'] and result['last_hit_time']:
            try:
                first = datetime.strptime(result['first_hit_time'], '%H:%M')
                last = datetime.strptime(result['last_hit_time'], '%H:%M')
                duration_hours = (last - first).total_seconds() / 3600
                if duration_hours > 0:
                    result['hourly_rate'] = result['art_count'] / duration_hours
            except:
                pass

        # ç¨¼åƒä¸­åˆ¤å®šï¼ˆæœ€çµ‚å½“ãŸã‚Šã‹ã‚‰30åˆ†ä»¥å†…ï¼‰
        if result['last_hit_time']:
            try:
                last_time = datetime.strptime(result['last_hit_time'], '%H:%M')
                now = datetime.now()
                current_time = datetime.strptime(now.strftime('%H:%M'), '%H:%M')
                diff_minutes = (current_time - last_time).total_seconds() / 60

                if diff_minutes < 0:
                    diff_minutes += 24 * 60  # æ—¥ä»˜ã‚’ã¾ãŸã„ã å ´åˆ

                if diff_minutes < 30:
                    result['is_running'] = True
                    result['status'] = 'ç¨¼åƒä¸­'
                elif diff_minutes < 60:
                    result['status'] = f'ç©ºã{int(diff_minutes)}åˆ†'
                else:
                    hours = int(diff_minutes // 60)
                    mins = int(diff_minutes % 60)
                    result['status'] = f'ç©ºã{hours}æ™‚é–“{mins}åˆ†'
            except:
                pass

    # å½“æ—¥ã®ARTç¢ºç‡è©•ä¾¡ï¼ˆæ©Ÿç¨®åˆ¥é–¾å€¤ã‚’ä½¿ç”¨ï¼‰
    # ã‚²ãƒ¼ãƒ æ•°ãŒå¤šã„ã»ã©ä¿¡é ¼åº¦ãŒé«˜ã„ãŸã‚ã€ãƒœãƒ¼ãƒŠã‚¹ã‚’å¢—ã‚„ã™
    thresholds = get_machine_thresholds(machine_key)
    games_multiplier = 1.0
    if result['total_games'] >= 5000:
        games_multiplier = 1.5  # 5000Gä»¥ä¸Š: ä¿¡é ¼åº¦é«˜
    elif result['total_games'] >= 3000:
        games_multiplier = 1.3  # 3000Gä»¥ä¸Š: ã‚„ã‚„ä¿¡é ¼
    elif result['total_games'] < 1000:
        games_multiplier = 0.5  # 1000Gæœªæº€: ä¿¡é ¼åº¦ä½

    if result['art_prob'] > 0:
        if result['art_prob'] <= thresholds['setting6_at_prob']:
            result['today_score_bonus'] = int(25 * games_multiplier)
            result['today_reasons'].append(f'æœ¬æ—¥ARTç¢ºç‡ 1/{result["art_prob"]:.0f} (è¨­å®š6åŸŸ)')
        elif result['art_prob'] <= thresholds['high_at_prob']:
            result['today_score_bonus'] = int(18 * games_multiplier)
            result['today_reasons'].append(f'æœ¬æ—¥ARTç¢ºç‡ 1/{result["art_prob"]:.0f} (é«˜è¨­å®šåŸŸ)')
        elif result['art_prob'] <= thresholds['mid_at_prob']:
            result['today_score_bonus'] = int(12 * games_multiplier)
            result['today_reasons'].append(f'æœ¬æ—¥ARTç¢ºç‡ 1/{result["art_prob"]:.0f} (ä¸­é–“è¨­å®šåŸŸ)')
        elif result['art_prob'] <= thresholds['low_at_prob']:
            # 130-180: ä½è¨­å®šå¯„ã‚Š â†’ å¼·ã‚ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
            result['today_score_bonus'] = int(-20 * games_multiplier)
            result['today_reasons'].append(f'ğŸš¨ æœ¬æ—¥ARTç¢ºç‡ 1/{result["art_prob"]:.0f} (ä½è¨­å®šå¯„ã‚Š)')
        elif result['art_prob'] >= thresholds['very_low_at_prob']:
            # 250ä»¥ä¸Š: å®Œå…¨ã«ä½è¨­å®š â†’ æœ€å¤§ãƒšãƒŠãƒ«ãƒ†ã‚£
            result['today_score_bonus'] = int(-30 * games_multiplier)
            result['today_reasons'].append(f'ğŸš¨ æœ¬æ—¥ARTç¢ºç‡ 1/{result["art_prob"]:.0f} (ä½è¨­å®šåŸŸ)')
        else:
            # 180-250: ä½è¨­å®šæ¿ƒåš â†’ å¼·ãƒšãƒŠãƒ«ãƒ†ã‚£
            result['today_score_bonus'] = int(-25 * games_multiplier)
            result['today_reasons'].append(f'ğŸš¨ æœ¬æ—¥ARTç¢ºç‡ 1/{result["art_prob"]:.0f} (ä½è¨­å®šæ¿ƒåš)')

    # æ™‚é–“å¸¯ã«å¯¾ã™ã‚‹ç¨¼åƒé‡ã®è©•ä¾¡
    if current_hour >= 10:
        elapsed_hours = current_hour - 10 + (datetime.now().minute / 60)
        expected_games_per_hour = 800  # è¨­å®š6ãªã‚‰1æ™‚é–“800Gãã‚‰ã„
        result['expected_games'] = elapsed_hours * expected_games_per_hour * 0.7  # 70%ç¨¼åƒæƒ³å®š

        if result['total_games'] > 0:
            actual_rate = result['total_games'] / result['expected_games'] if result['expected_games'] > 0 else 0
            if actual_rate < 0.3:
                result['today_reasons'].append(f'ç¨¼åƒå°‘ãªã‚ï¼ˆæœŸå¾…å€¤ã®{actual_rate*100:.0f}%ï¼‰')

    return result


def compare_with_others(store_key: str, unit_id: str, all_units_today: dict) -> dict:
    """ä»–å°ã¨ã®æ¯”è¼ƒåˆ†æ

    Args:
        store_key: åº—èˆ—ã‚­ãƒ¼
        unit_id: å¯¾è±¡å°ç•ªå·
        all_units_today: å…¨å°ã®å½“æ—¥ãƒ‡ãƒ¼ã‚¿

    Returns:
        {
            'rank_in_store': int,  # åº—èˆ—å†…é †ä½
            'total_units': int,  # ç·å°æ•°
            'avg_art_store': float,  # åº—èˆ—å¹³å‡ART
            'diff_from_avg': float,  # å¹³å‡ã¨ã®å·®
            'is_top_performer': bool,  # ãƒˆãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‹
            'comparison_note': str,  # æ¯”è¼ƒã‚³ãƒ¡ãƒ³ãƒˆ
        }
    """
    result = {
        'rank_in_store': 0,
        'total_units': 0,
        'avg_art_store': 0,
        'diff_from_avg': 0,
        'is_top_performer': False,
        'comparison_note': '',
    }

    if not all_units_today:
        return result

    # å…¨å°ã®ARTæ•°ã‚’åé›†
    unit_arts = []
    target_art = 0
    for unit in all_units_today:
        uid = unit.get('unit_id')
        art = unit.get('art', 0)
        if art > 0:
            unit_arts.append((uid, art))
            if uid == unit_id:
                target_art = art

    if not unit_arts:
        return result

    result['total_units'] = len(unit_arts)
    result['avg_art_store'] = sum(a for _, a in unit_arts) / len(unit_arts)

    # é †ä½è¨ˆç®—
    sorted_units = sorted(unit_arts, key=lambda x: -x[1])
    for i, (uid, art) in enumerate(sorted_units, 1):
        if uid == unit_id:
            result['rank_in_store'] = i
            break

    if target_art > 0:
        result['diff_from_avg'] = target_art - result['avg_art_store']
        if result['rank_in_store'] == 1:
            result['is_top_performer'] = True
            result['comparison_note'] = 'æœ¬æ—¥ãƒˆãƒƒãƒ—'
        elif result['rank_in_store'] <= 3:
            result['comparison_note'] = f'æœ¬æ—¥{result["rank_in_store"]}ä½/{result["total_units"]}å°'
        elif result['diff_from_avg'] < -5:
            result['comparison_note'] = f'å¹³å‡ã‚ˆã‚Š{abs(result["diff_from_avg"]):.0f}å›å°‘ãªã„'

    return result


def analyze_graph_pattern(days: List[dict]) -> dict:
    """ã‚°ãƒ©ãƒ•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆãƒŸãƒŸã‚º/ãƒ¢ãƒŸãƒ¢ãƒŸ/å³è‚©ä¸ŠãŒã‚Šç­‰ï¼‰

    ãƒŸãƒŸã‚º: ãƒãƒã‚‰ãªã„ãŒé£²ã¾ã‚Œã‚‹ã€REGã®ç¹°ã‚Šè¿”ã—ã§å¤§ãƒãƒã—ãªã„æ¨ªã°ã„çŠ¶æ…‹
    ãƒ¢ãƒŸãƒ¢ãƒŸ: å°åˆ»ã¿ã«ä¸Šä¸‹ã™ã‚‹ãŒå¤§ããªå¤‰å‹•ãªã—ã€ã“ã®ã‚ã¨è·³ã­ã‚‹ã“ã¨ãŒå¤šã„

    Returns:
        {
            'pattern': str,
            'volatility': float,
            'description': str,
            'likely_to_rise': bool,  # ã“ã®ã‚ã¨ä¼¸ã³ãã†ã‹
        }
    """
    if not days or len(days) < 3:
        return {'pattern': 'unknown', 'volatility': 0, 'description': '', 'likely_to_rise': False}

    # ç›´è¿‘7æ—¥ã®ARTæ•°ã¨æœ€å¤§é€£ãƒãƒ£ãƒ³æ•°ã‚’åˆ†æ
    arts = []
    max_rensas = []  # æœ€å¤§é€£ãƒãƒ£ãƒ³æ•°
    for d in days[:7]:
        art = d.get('art', 0)
        if art > 0:
            arts.append(art)
            # å±¥æ­´ã‹ã‚‰æœ€å¤§é€£ãƒãƒ£ãƒ³ã‚’è¨ˆç®—
            history = d.get('history', [])
            if history:
                max_rensa = calculate_max_rensa(history)
                max_rensas.append(max_rensa)

    if len(arts) < 3:
        return {'pattern': 'unknown', 'volatility': 0, 'description': '', 'likely_to_rise': False}

    avg = sum(arts) / len(arts)
    if avg == 0:
        return {'pattern': 'unknown', 'volatility': 0, 'description': '', 'likely_to_rise': False}

    # å¤‰å‹•å¹…
    deviations = [abs(a - avg) for a in arts]
    volatility = sum(deviations) / len(deviations) / avg * 100

    # ãƒˆãƒ¬ãƒ³ãƒ‰
    recent_avg = sum(arts[:3]) / 3
    older_avg = sum(arts[3:]) / len(arts[3:]) if len(arts) > 3 else avg

    # æœ€å¤§é€£ãƒãƒ£ãƒ³å‚¾å‘ï¼ˆ10é€£ä»¥ä¸ŠãŒã‚ã‚‹ã‹ï¼‰
    has_big_rensa = any(r >= 10 for r in max_rensas) if max_rensas else False
    avg_max_rensa = sum(max_rensas) / len(max_rensas) if max_rensas else 0

    # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®š
    likely_to_rise = False

    if volatility < 15:
        # å¤‰å‹•ãŒå°‘ãªã„ = ãƒŸãƒŸã‚ºï¼ˆæ¨ªã°ã„ï¼‰
        pattern = 'mimizu'
        if avg >= 35 and has_big_rensa:
            description = f'å®‰å®šé«˜æŒ™å‹•ï¼ˆå¹³å‡{avg:.0f}ARTã€10é€£+ã‚ã‚Šï¼‰â†’ é«˜è¨­å®šæ¿ƒåš'
        elif avg >= 30:
            description = f'å®‰å®šæ¨ç§»ï¼ˆå¹³å‡{avg:.0f}ARTï¼‰'
            if not has_big_rensa:
                description += ' â†’ çˆ†ç™ºå¾…ã¡ã®å¯èƒ½æ€§'
                likely_to_rise = True
        else:
            description = f'ãƒŸãƒŸã‚ºï¼ˆä½ç©ºé£›è¡Œã§æ¨ªã°ã„ï¼‰'
            if avg >= 20:
                description += ' â†’ ã“ã®ã‚ã¨è·³ã­ã‚‹å¯èƒ½æ€§'
                likely_to_rise = True
    elif volatility < 30:
        # ãƒ¢ãƒŸãƒ¢ãƒŸï¼ˆå°åˆ»ã¿å¤‰å‹•ã€å¤§ãƒãƒã—ãªã„ï¼‰
        pattern = 'momimomi'
        if not has_big_rensa and avg >= 20:
            description = f'ãƒ¢ãƒŸãƒ¢ãƒŸï¼ˆ10é€£ãªã—ã€å¹³å‡{avg:.0f}ARTï¼‰â†’ çˆ†ç™ºå¾…ã¡çŠ¶æ…‹'
            likely_to_rise = True
        elif recent_avg > older_avg * 1.1:
            description = f'ãƒ¢ãƒŸãƒ¢ãƒŸã‹ã‚‰ä¸Šæ˜‡å…†å€™ â†’ ãã‚ãã‚è·³ã­ã‚‹'
            likely_to_rise = True
        else:
            description = f'ãƒ¢ãƒŸãƒ¢ãƒŸä¸­ï¼ˆå¹³å‡{avg:.0f}ARTï¼‰'
            if not has_big_rensa:
                likely_to_rise = True
    else:
        # å¤‰å‹•ãŒå¤§ãã„
        if recent_avg > older_avg * 1.2:
            pattern = 'rising'
            description = f'å³è‚©ä¸ŠãŒã‚Š â†’ é«˜è¨­å®šã«å¤‰æ›´ã•ã‚ŒãŸå¯èƒ½æ€§'
        elif recent_avg < older_avg * 0.8:
            pattern = 'falling'
            description = f'å³è‚©ä¸‹ãŒã‚Š â†’ è¨­å®šä¸‹ã’è­¦æˆ’'
        else:
            pattern = 'volatile'
            if has_big_rensa:
                description = f'è’ã„å°ï¼ˆ10é€£+å®Ÿç¸¾ã‚ã‚Šï¼‰â†’ ä¸€ç™ºç‹™ã„å‘ã'
            else:
                description = f'å¤‰å‹•å¤§ã ãŒçˆ†ç™ºãªã— â†’ æ§˜å­è¦‹æ¨å¥¨'

    return {
        'pattern': pattern,
        'volatility': volatility,
        'description': description,
        'likely_to_rise': likely_to_rise,
        'has_big_rensa': has_big_rensa,
        'avg_max_rensa': avg_max_rensa,
    }


def calc_no_explosion_next_day_stats(machine_key: str = 'sbj') -> dict:
    """ç¢ºç‡ã¯å¥½èª¿ã ãŒçˆ†ç™ºã—ãªã‹ã£ãŸæ—¥ã®ç¿Œæ—¥çµ±è¨ˆï¼ˆå…¨åº—èˆ—çµ±åˆï¼‰

    Returns:
        {'total': N, 'next_good': N, 'rate': float}
    """
    import glob
    good_threshold = get_machine_threshold(machine_key, 'good_prob')
    total = 0
    next_good = 0

    hist_base = 'data/history'
    if not os.path.isdir(hist_base):
        return {'total': 0, 'next_good': 0, 'rate': 0.0}

    for store_dir in os.listdir(hist_base):
        if machine_key not in store_dir:
            continue
        store_path = os.path.join(hist_base, store_dir)
        if not os.path.isdir(store_path):
            continue
        for f in glob.glob(os.path.join(store_path, '*.json')):
            try:
                with open(f) as fp:
                    data = json.load(fp)
            except:
                continue
            days = sorted(data.get('days', []), key=lambda d: d.get('date', ''))
            for i, d in enumerate(days):
                art = d.get('art', 0)
                games = d.get('total_start', 0) or d.get('games', 0)
                mr = d.get('max_rensa', 0)
                if art <= 0 or games <= 0 or mr <= 0:
                    continue
                prob = games / art
                # ç¢ºç‡ã¯å¥½èª¿ã ãŒæœ€å¤§é€£ãƒãƒ£ãƒ³ãŒ15é€£æœªæº€ â†’ çˆ†ç™ºãªã—
                if prob <= good_threshold and mr < 15:
                    if i + 1 < len(days):
                        nd = days[i + 1]
                        na = nd.get('art', 0)
                        ng = nd.get('total_start', 0) or nd.get('games', 0)
                        if na > 0 and ng > 0:
                            total += 1
                            if (ng / na) <= good_threshold:
                                next_good += 1

    rate = next_good / total if total > 0 else 0.0
    return {'total': total, 'next_good': next_good, 'rate': rate}


# ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_no_explosion_cache = {}


def get_no_explosion_stats(machine_key: str = 'sbj') -> dict:
    if machine_key not in _no_explosion_cache:
        _no_explosion_cache[machine_key] = calc_no_explosion_next_day_stats(machine_key)
    return _no_explosion_cache[machine_key]


def calc_recovery_stats(store_key: str, machine_key: str = 'sbj') -> dict:
    """è“„ç©ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é€£ç¶šä¸èª¿â†’ç¿Œæ—¥å›å¾©ç‡ã‚’è¨ˆç®—

    Returns:
        {1: {'total': N, 'recovered': N, 'rate': float}, ...}
    """
    import glob
    hist_dir = f'data/history/{store_key}'
    good_threshold = get_machine_threshold(machine_key, 'good_prob')
    results = {}
    for n in range(1, 6):
        results[n] = {'total': 0, 'recovered': 0, 'rate': 0.0}

    if not os.path.isdir(hist_dir):
        return results

    for f in glob.glob(os.path.join(hist_dir, '*.json')):
        try:
            with open(f) as fp:
                data = json.load(fp)
        except:
            continue
        days = sorted(data.get('days', []), key=lambda d: d.get('date', ''))
        probs = []
        for d in days:
            art = d.get('art', 0)
            games = d.get('total_start', 0) or d.get('games', 0)
            if art > 0 and games > 0:
                probs.append(games / art)
            else:
                probs.append(None)

        for i in range(1, len(probs)):
            if probs[i] is None:
                continue
            is_good = probs[i] <= good_threshold
            streak = 0
            for j in range(i-1, -1, -1):
                if probs[j] is None or probs[j] <= good_threshold:
                    break
                streak += 1
            for n in range(1, min(streak+1, 6)):
                results[n]['total'] += 1
                if is_good:
                    results[n]['recovered'] += 1

    for n in results:
        t = results[n]['total']
        results[n]['rate'] = results[n]['recovered'] / t if t > 0 else 0.0

    return results


# å›å¾©ç‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥
_recovery_cache = {}

def get_recovery_stats(store_key: str, machine_key: str = 'sbj') -> dict:
    cache_key = f'{store_key}_{machine_key}'
    if cache_key not in _recovery_cache:
        _recovery_cache[cache_key] = calc_recovery_stats(store_key, machine_key)
    return _recovery_cache[cache_key]


def get_machine_recovery_stats(machine_key: str = 'sbj') -> dict:
    """å…¨åº—èˆ—çµ±åˆã®æ©Ÿç¨®åˆ¥å›å¾©ç‡"""
    cache_key = f'__machine__{machine_key}'
    if cache_key in _recovery_cache:
        return _recovery_cache[cache_key]

    total = {}
    for n in range(1, 6):
        total[n] = {'total': 0, 'recovered': 0, 'rate': 0.0}

    hist_base = 'data/history'
    if os.path.isdir(hist_base):
        for store_dir in os.listdir(hist_base):
            if machine_key in store_dir or (machine_key == 'sbj' and 'sbj' in store_dir):
                r = calc_recovery_stats(store_dir, machine_key)
                for n in range(1, 6):
                    total[n]['total'] += r[n]['total']
                    total[n]['recovered'] += r[n]['recovered']

    for n in total:
        t = total[n]['total']
        total[n]['rate'] = total[n]['recovered'] / t if t > 0 else 0.0

    _recovery_cache[cache_key] = total
    return total


def analyze_rotation_pattern(days: List[dict], machine_key: str = 'sbj') -> dict:
    """ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ

    Returns:
        {
            'has_pattern': bool,
            'cycle_days': int,  # ãƒ­ãƒ¼ãƒ†å‘¨æœŸ
            'next_high_chance': bool,  # æ¬¡ã«ä¸ŠãŒã‚Šãã†ã‹
            'description': str,
        }
    """
    if not days or len(days) < 5:
        return {'has_pattern': False, 'cycle_days': 0, 'next_high_chance': False, 'description': ''}

    # ç›´è¿‘7æ—¥ã®çµæœï¼ˆãƒ—ãƒ©ã‚¹/ãƒã‚¤ãƒŠã‚¹ï¼‰ã‚’ãƒ‘ã‚¿ãƒ¼ãƒ³åŒ–
    SYMBOL_GOOD = '<span class="rot-good">â—</span>'
    SYMBOL_BAD = '<span class="rot-bad">âœ•</span>'
    SYMBOL_MID = '<span class="rot-mid">â–³</span>'
    results = []
    for day in days[:7]:
        art = day.get('art', 0)
        games = day.get('total_start', 0)
        if games > 0 and art > 0:
            prob = games / art
            _good = get_machine_threshold(machine_key, 'good_prob')
            _vbad = get_machine_threshold(machine_key, 'very_bad_prob')
            if prob <= _good:
                results.append(SYMBOL_GOOD)
            elif prob >= _vbad:
                results.append(SYMBOL_BAD)
            else:
                results.append(SYMBOL_MID)

    if len(results) < 5:
        return {'has_pattern': False, 'cycle_days': 0, 'next_high_chance': False, 'description': ''}

    # é€£ç¶šãƒã‚¤ãƒŠã‚¹å¾Œã®ãƒ—ãƒ©ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
    is_bad = lambda s: s == SYMBOL_BAD
    is_good = lambda s: s == SYMBOL_GOOD

    # è¡¨ç¤ºç”¨ï¼ˆå¤ã„â†’æ–°ã—ã„ã®é †ã€â†’ã§ç¹‹ãï¼‰
    def _fmt_pattern(r):
        return 'â†’'.join(reversed(r[:min(6, len(r))]))

    # 2æ—¥ä¸‹ã’ã¦ä¸Šã’ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
    if len(results) >= 3 and is_bad(results[2]) and is_bad(results[1]) and is_good(results[0]):
        return {
            'has_pattern': True,
            'cycle_days': 3,
            'next_high_chance': is_bad(results[0]) and is_bad(results[1]),
            'description': f'{_fmt_pattern(results)}ï¼ˆ2æ—¥ä¸‹ã’â†’ä¸Šã’ã®ãƒ­ãƒ¼ãƒ†å‚¾å‘ï¼‰'
        }

    # 3æ—¥ä¸‹ã’ã¦ä¸Šã’ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³
    if len(results) >= 4 and is_bad(results[3]) and is_bad(results[2]) and is_bad(results[1]) and is_good(results[0]):
        return {
            'has_pattern': True,
            'cycle_days': 4,
            'next_high_chance': is_bad(results[0]) and is_bad(results[1]) and is_bad(results[2]),
            'description': f'{_fmt_pattern(results)}ï¼ˆ3æ—¥ä¸‹ã’â†’ä¸Šã’ã®ãƒ­ãƒ¼ãƒ†å‚¾å‘ï¼‰'
        }

    # äº¤äº’ãƒ‘ã‚¿ãƒ¼ãƒ³
    alternating = sum(1 for i in range(len(results)-1) if results[i] != results[i+1])
    alt_rate = alternating / (len(results) - 1) if len(results) > 1 else 0
    # 80%ä»¥ä¸Š ã‹ã¤ ç›´è¿‘2æ—¥ãŒåŒã˜ã§ãªã„å ´åˆã®ã¿
    if alt_rate >= 0.8 and len(results) >= 2 and results[0] != results[1]:
        return {
            'has_pattern': True,
            'cycle_days': 2,
            'next_high_chance': is_bad(results[0]),
            'description': f'{_fmt_pattern(results)}ï¼ˆ{alternating}/{len(results)-1}å›äº¤äº’ï¼‰'
        }

    return {'has_pattern': False, 'cycle_days': 0, 'next_high_chance': False, 'description': ''}


def analyze_today_graph(history: List[dict]) -> dict:
    """æœ¬æ—¥ã®ã‚°ãƒ©ãƒ•åˆ†æï¼ˆãƒãƒã‚Šãªã—/é€£ãƒãƒ£ãƒ³ä¸­/çˆ†ç™ºåˆ¤å®šç­‰ï¼‰

    Returns:
        {
            'no_deep_valley': bool,  # æ·±ã„ãƒãƒã‚Šãªã—
            'max_valley': int,  # æœ€å¤§ãƒãƒã‚Š
            'is_on_fire': bool,  # é€£ãƒãƒ£ãƒ³ä¸­
            'has_explosion': bool,  # 10é€£ä»¥ä¸Šã®çˆ†ç™ºã‚ã‚Š
            'max_rensa': int,  # æœ€å¤§é€£ãƒãƒ£ãƒ³æ•°
            'recent_trend': str,  # ç›´è¿‘ã®å‚¾å‘
            'description': str,
            'explosion_potential': str,  # çˆ†ç™ºãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«
        }
    """
    default_result = {
        'no_deep_valley': True,
        'max_valley': 0,
        'is_on_fire': False,
        'has_explosion': False,
        'max_rensa': 0,
        'recent_trend': 'unknown',
        'description': '',
        'explosion_potential': 'unknown',
    }

    if not history:
        return default_result

    # ATé–“ï¼ˆå¤§å½“ãŸã‚Šé–“ã®Gæ•°ï¼‰ã‚’æ­£ã—ãè¨ˆç®—ï¼ˆRBã‚’è·¨ã„ã§åˆç®—ï¼‰
    valleys = calculate_at_intervals(history)

    # é€£ãƒãƒ£ãƒ³æ•°ã‚’è¨ˆç®—ï¼ˆå±¥æ­´ã®startå€¤ã‹ã‚‰70Gä»¥ä¸‹ã®é€£ç¶šå¤§å½“ãŸã‚Šã‚’ç®—å‡ºï¼‰
    max_rensa = calculate_max_rensa(history)

    if not valleys:
        return default_result

    max_valley = max(valleys)
    avg_valley = sum(valleys) / len(valleys)
    recent_valleys = valleys[-5:] if len(valleys) >= 5 else valleys
    has_explosion = max_rensa >= 10  # 10é€£ä»¥ä¸Šã‚’çˆ†ç™ºã¨ã¿ãªã™

    # æ·±ã„ãƒãƒã‚Šãªã—åˆ¤å®š
    no_deep_valley = max_valley < 500

    # é€£ãƒãƒ£ãƒ³ä¸­åˆ¤å®š
    is_on_fire = len(recent_valleys) >= 3 and all(v <= 100 for v in recent_valleys)

    # çˆ†ç™ºãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«åˆ¤å®š
    total_hits = len(history)
    if has_explosion:
        explosion_potential = 'exploded'
    elif total_hits >= 30 and not has_explosion:
        # 30å›ä»¥ä¸Šå½“ãŸã£ã¦10é€£ãªã— = çˆ†ç™ºã—ã«ãã„å±•é–‹
        explosion_potential = 'low'
    elif total_hits >= 15 and no_deep_valley and not has_explosion:
        # ãƒãƒã‚‰ãšæ·¡ã€…ã¨å½“ãŸã‚‹ãŒçˆ†ç™ºãªã— = ãƒ¢ãƒŸãƒ¢ãƒŸã€ã“ã®ã‚ã¨æ¥ã‚‹å¯èƒ½æ€§
        explosion_potential = 'building'
    elif total_hits < 15:
        explosion_potential = 'unknown'
    else:
        explosion_potential = 'normal'

    # ç›´è¿‘ã®å‚¾å‘ã¨èª¬æ˜
    if is_on_fire:
        recent_trend = 'hot'
        if has_explosion:
            description = f'æœ¬æ—¥{max_rensa}é€£é”æˆæ¸ˆã¿ã€é€£ãƒãƒ£ãƒ³ç¶™ç¶šä¸­'
        else:
            description = f'é€£ãƒãƒ£ãƒ³ä¸­ï¼ˆç›´è¿‘{len(recent_valleys)}å›å…¨ã¦100Gä»¥å†…ï¼‰'
    elif has_explosion:
        recent_trend = 'exploded'
        description = f'ã€æœ¬æ—¥ã€‘{max_rensa}é€£ã®çˆ†ç™ºã‚ã‚Šï¼'
    elif explosion_potential == 'low':
        recent_trend = 'flat'
        description = f'ã€æœ¬æ—¥ã€‘{total_hits}ARTæ¶ˆåŒ–ã€é€£è˜æ§ãˆã‚ â†’ é«˜è¨­å®šã§ã‚‚ãƒ ãƒ©ã‚ã‚Š'
    elif explosion_potential == 'building':
        recent_trend = 'building'
        description = f'ã€æœ¬æ—¥ã€‘ãƒãƒã‚Šãªã{total_hits}å›å½“é¸ä¸­ â†’ é€£è˜æœŸå¾…'
    elif no_deep_valley and avg_valley < 100:
        recent_trend = 'very_hot'
        description = f'çµ¶å¥½èª¿ï¼ˆå¹³å‡{avg_valley:.0f}Gã€æœ€å¤§{max_valley}Gï¼‰'
    elif no_deep_valley:
        recent_trend = 'stable'
        description = f'ãƒãƒã‚Šãªã—å®‰å®šï¼ˆæœ€å¤§{max_valley}Gï¼‰'
    elif max_valley >= 800:
        recent_trend = 'recovering'
        description = f'{max_valley}Gãƒãƒã‚Šã‚ã‚Š â†’ å¤©äº•å¾Œã¯æ§˜å­è¦‹'
    else:
        recent_trend = 'normal'
        description = ''

    return {
        'no_deep_valley': no_deep_valley,
        'max_valley': max_valley,
        'is_on_fire': is_on_fire,
        'has_explosion': has_explosion,
        'max_rensa': max_rensa,
        'recent_trend': recent_trend,
        'description': description,
        'explosion_potential': explosion_potential,
    }


def generate_reasons(unit_id: str, trend: dict, today: dict, comparison: dict,
                     base_rank: str, final_rank: str, days: List[dict] = None,
                     today_history: List[dict] = None,
                     store_key: str = None,
                     is_today_data: bool = False,
                     current_at_games: int = 0,
                     data_date_label: str = None,
                     prev_date_label: str = None,
                     **kwargs) -> List[str]:
    """æ¨å¥¨ç†ç”±ã‚’ç”Ÿæˆï¼ˆå°å›ºæœ‰ã®æ ¹æ‹ ã‚’æœ€å„ªå…ˆï¼‰

    å„ªå…ˆé †ä½:
    1. ã“ã®å°ã®éå»ãƒ©ãƒ³ã‚¯ï¼ˆãªãœã“ã®å°ãªã®ã‹ï¼‰
    2. å‰æ—¥ã®å®Ÿç¸¾åˆ†æï¼ˆç¿Œæ—¥äºˆæ¸¬ã®æ ¹æ‹ ï¼‰
    3. é€£ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆè¨­å®šå¤‰æ›´ã‚µã‚¤ã‚¯ãƒ«ã®èª­ã¿ï¼‰
    4. æœ¬æ—¥ãƒ‡ãƒ¼ã‚¿ï¼ˆç¨¼åƒä¸­ã®å ´åˆã®ã¿ï¼‰
    5. åº—èˆ—æ›œæ—¥å‚¾å‘ï¼ˆè£œè¶³æƒ…å ±ï¼‰
    """
    reasons = []

    weekday_info = get_store_weekday_info(store_key) if store_key else {}
    store_name = weekday_info.get('short_name', '')
    today_weekday = weekday_info.get('today_weekday', '')
    today_rating = weekday_info.get('today_rating', 3)

    # ç¿Œæ—¥/æœ¬æ—¥ã®è¡¨ç¾ï¼ˆ0:00ã€œ10:00ã¯ã€Œæœ¬æ—¥ã€ã€10:00ã€œ24:00ã¯ã€Œç¿Œæ—¥ã€ï¼‰
    _hour = datetime.now().hour
    next_day_label = 'æœ¬æ—¥' if _hour < 10 else 'ç¿Œæ—¥'

    total_games = today.get('total_games', 0)
    art_prob = today.get('art_prob', 0)

    consecutive_plus = trend.get('consecutive_plus', 0)
    consecutive_minus = trend.get('consecutive_minus', 0)
    yesterday_art = trend.get('yesterday_art', 0)
    yesterday_rb = trend.get('yesterday_rb', 0)
    yesterday_games = trend.get('yesterday_games', 0)
    day_before_art = trend.get('day_before_art', 0)
    day_before_games = trend.get('day_before_games', 0)

    # === 1. ã“ã®å°ã®éå»ãƒ©ãƒ³ã‚¯ + éå»å®Ÿç¸¾ï¼ˆãªãœã“ã®å°ã‚’é¸ã‚“ã ã®ã‹ï¼‰ ===
    historical_perf = kwargs.get('historical_perf', {})
    good_day_rate = historical_perf.get('good_day_rate', 0)
    good_days = historical_perf.get('good_days', 0)
    total_perf_days = historical_perf.get('total_days', 0)
    miss_days = total_perf_days - good_days if total_perf_days > 0 else 0

    if total_perf_days > 0 and good_day_rate >= 0.7:
        # å¥½èª¿ç‡ã¯ğŸ”„ã«é€£ç¶šå¥½èª¿ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯çœç•¥ï¼ˆé‡è¤‡å›é¿ï¼‰
        # é€£ç¶šå¥½èª¿3æ—¥ä»¥ä¸Šãªã‚‰ğŸ”„ã§ã€ŒNæ—¥é€£ç¶šå¥½èª¿ + æ›œæ—¥ã€ãŒå‡ºã‚‹ã®ã§å¥½èª¿ç‡ã¯å†—é•·
        if consecutive_plus < 3:
            reasons.append(f"ğŸ“Š {total_perf_days}æ—¥é–“ä¸­{good_days}æ—¥å¥½èª¿ï¼ˆå¥½èª¿ç‡{good_day_rate:.0%}ï¼‰â†’ é«˜è¨­å®šãŒå…¥ã‚Šã‚„ã™ã„å°")

        # --- å¥½èª¿ã®ä¸­èº«åˆ†æï¼ˆARTå›æ•°ãƒ»æœ€å¤§é€£ãƒãƒ£ãƒ³ã§å¥½èª¿ãƒ¬ãƒ™ãƒ«ã‚’å¯è¦–åŒ–ï¼‰---
        good_day_details = historical_perf.get('good_day_details', [])
        if good_day_details and len(good_day_details) >= 3:
            # çˆ†ç™ºãƒ¬ãƒ™ãƒ«åˆ†é¡
            def _level(art):
                if art >= 80: return 'big'
                if art >= 50: return 'mid'
                return 'small'
            
            levels = [_level(d.get('art', 0)) for d in good_day_details]  # æ–°â†’å¤
            big_days = levels.count('big')
            mid_days = levels.count('mid')
            small_days = levels.count('small')
            total_good = len(levels)
            
            # --- ç›´è¿‘ã®æ¨ç§»ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰æ¬¡ã®äºˆæ¸¬ ---
            recent_levels = levels[:5]  # ç›´è¿‘5æ—¥ã®çˆ†ç™ºãƒ¬ãƒ™ãƒ«ï¼ˆæ–°â†’å¤ï¼‰
            
            # ç›´è¿‘ã§ä¸­/å°ãŒé€£ç¶šã—ã¦ãŸã‚‰ã€Œãã‚ãã‚å¤§çˆ†ç™ºã€
            recent_non_big = 0
            for lv in recent_levels:
                if lv != 'big':
                    recent_non_big += 1
                else:
                    break
            
            # å¤§çˆ†ç™ºâ†’ä¸­/å°â†’å¤§çˆ†ç™ºã®äº¤äº’ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
            alternating = 0
            for i in range(len(recent_levels) - 1):
                if recent_levels[i] != recent_levels[i+1]:
                    alternating += 1
            alt_rate = alternating / max(len(recent_levels) - 1, 1)
            
            # ã€Œä¸­â†’ä¸­â†’å¤§â†’ä¸­â†’å¤§â†’ä¸­â†’å¤§ã€ã®ã‚ˆã†ãªæ¨ç§»ã‚’èª¬æ˜
            level_labels = {'big': 'å¤§', 'mid': 'ä¸­', 'small': 'å°'}
            trend_str = 'â†’'.join(level_labels[lv] for lv in reversed(recent_levels))
            
            # æœ€æ–°æ—¥ã‹ã‚‰ã®é€£ç¶šå¤§çˆ†ç™ºã‚«ã‚¦ãƒ³ãƒˆ
            consec_big = 0
            for lv in recent_levels:
                if lv == 'big':
                    consec_big += 1
                else:
                    break
            
            if recent_non_big >= 2 and big_days >= 1:
                # ä¸­/å°ãŒ2æ—¥ä»¥ä¸Šç¶šã„ã¦ã‚‹ â†’ å¤§çˆ†ç™ºäºˆæ¸¬
                reasons.append(f"ğŸ”¥ ç›´è¿‘ã®æ¨ç§»: {trend_str}ï¼ˆART80å›ä»¥ä¸Šã®å¤§çˆ†ç™ºãŒãªã{recent_non_big}æ—¥çµŒéã€‚éå»ã®å‚¾å‘ã§ã¯ä¸­/å°ã®å¾Œã«å¤§ãŒæ¥ã‚„ã™ã„ï¼‰")
            elif consec_big >= 2:
                # å¤§çˆ†ç™ºãŒ2æ—¥ä»¥ä¸Šé€£ç¶š
                reasons.append(f"ğŸ”¥ ç›´è¿‘ã®æ¨ç§»: {trend_str}ï¼ˆå¤§çˆ†ç™º{consec_big}æ—¥é€£ç¶š â†’ é«˜è¨­å®šæ®ãˆç½®ãã®è¨¼æ‹ ï¼‰")
            elif alt_rate >= 0.6 and total_good >= 4:
                # äº¤äº’ãƒ‘ã‚¿ãƒ¼ãƒ³
                last_level = recent_levels[0]
                next_expect = 'å¤§çˆ†ç™º' if last_level != 'big' else 'ä¸­ç¨‹åº¦'
                reasons.append(f"ğŸ”¥ ç›´è¿‘ã®æ¨ç§»: {trend_str}ï¼ˆå¤§å°äº¤äº’ â†’ æœ¬æ—¥ã¯{next_expect}ã®å¯èƒ½æ€§ï¼‰")
            elif recent_non_big == 1 and recent_levels[0] != 'big':
                # ç›´è¿‘1æ—¥ã ã‘ä¸­/å° â†’ ã¾ã å¤§çˆ†ç™ºã®å°„ç¨‹å†…
                reasons.append(f"ğŸ”¥ ç›´è¿‘ã®æ¨ç§»: {trend_str}ï¼ˆå‰æ—¥ã¯ä½ã‚ã ãŒé«˜è¨­å®šã®ç¯„å›²å†… â†’ å¤§çˆ†ç™ºã«æœŸå¾…ï¼‰")
            elif total_good >= 3:
                reasons.append(f"ğŸ”¥ ç›´è¿‘ã®æ¨ç§»: {trend_str}ï¼ˆå¥½èª¿{total_good}æ—¥ä¸­ã€å¤§{big_days}/ä¸­{mid_days}/å°{small_days}æ—¥ï¼‰")

        # --- ã“ã®å°ã®å¥½èª¿ç¶™ç¶šç‡ ---
        continuation_rate = historical_perf.get('continuation_rate', 0)
        continuation_total = historical_perf.get('continuation_total', 0)
        continuation_good = historical_perf.get('continuation_good', 0)
        if continuation_total >= 3:
            if continuation_rate >= 0.8:
                reasons.append(f"ğŸ“Š ã“ã®å°ã¯å¥½èª¿ãŒç¶šãã‚„ã™ã„ï¼ˆéå»{continuation_total}å›ä¸­{continuation_good}å› = {continuation_rate:.0%}ã§ç¿Œæ—¥ã‚‚å¥½èª¿ï¼‰")
            elif continuation_rate >= 0.6:
                reasons.append(f"ğŸ“Š å¥½èª¿â†’ç¿Œæ—¥ã‚‚å¥½èª¿ã®å®Ÿç¸¾: {continuation_good}/{continuation_total}å›ï¼ˆ{continuation_rate:.0%}ï¼‰â€»ã‚„ã‚„æœŸå¾…ã§ãã‚‹ç¨‹åº¦")
            elif continuation_rate < 0.4:
                reasons.append(f"âš ï¸ ã“ã®å°ã¯å¥½èª¿ãŒé•·ç¶šãã—ã«ãã„ï¼ˆ{continuation_good}/{continuation_total}å› = {continuation_rate:.0%}ï¼‰")

        # --- é€£ç¶šå¥½èª¿ã®å®Ÿç¸¾ ---
        max_streak = historical_perf.get('max_consecutive_good', 0)
        if consecutive_plus >= 3 and max_streak > 0:
            if consecutive_plus >= max_streak:
                reasons.append(f"ğŸ“Š {consecutive_plus}æ—¥é€£ç¶šå¥½èª¿ä¸­ â†’ ã“ã®å°ã®éå»æœ€é•·ã‚’æ›´æ–°ä¸­ï¼ˆåº—ãŒé«˜è¨­å®šã‚’å…¥ã‚Œç¶šã‘ã¦ã‚‹å¯èƒ½æ€§ï¼‰")
            elif consecutive_plus >= max_streak - 1:
                reasons.append(f"ğŸ“Š {consecutive_plus}æ—¥é€£ç¶šå¥½èª¿ä¸­ï¼ˆã“ã®å°ã®éå»æœ€é•·{max_streak}æ—¥ã«ã‚ã¨1æ—¥ï¼‰")
            else:
                reasons.append(f"ğŸ“Š {consecutive_plus}æ—¥é€£ç¶šå¥½èª¿ä¸­ï¼ˆã“ã®å°ã®éå»æœ€é•·ã¯{max_streak}æ—¥ï¼‰")

        # è¨­å®šå¤‰æ›´å‘¨æœŸæƒ…å ±ï¼ˆPhase 2+ï¼‰
        cycle_analysis = kwargs.get('cycle_analysis', {})
        analysis_phase = kwargs.get('analysis_phase', 1)
        if cycle_analysis and analysis_phase >= 2:
            cycle_parts = []
            # ç¾åœ¨ã®é€£ç¶šä¸èª¿æ—¥æ•°ã«åŸºã¥ãã€Œæ¬¡ã¯å¥½èª¿ã€ç¢ºç‡
            if consecutive_minus > 0:
                btg = cycle_analysis.get('bad_to_good', {})
                key = min(consecutive_minus, max(btg.keys())) if btg else 0
                if key and key in btg:
                    rate = btg[key]
                    if rate['total'] >= 2:
                        cycle_parts.append(f"{key}æ—¥ä¸èª¿ãŒç¶šã„ãŸå¾Œâ†’å¥½èª¿ã«åˆ‡ã‚Šæ›¿ã‚ã‚‹ç‡{rate['rate']:.0%}ï¼ˆ{rate['good']}/{rate['total']}å›ï¼‰")
            # é€£ç¶šå¥½èª¿ä¸­ãªã‚‰æ®ãˆç½®ãç‡ï¼ˆ2æ—¥ä»¥ä¸Šã®ã¿ï¼‰
            if consecutive_plus >= 2:
                gtg = cycle_analysis.get('good_to_good', {})
                key = min(consecutive_plus, max(gtg.keys())) if gtg else 0
                if key and key in gtg:
                    rate = gtg[key]
                    if rate['total'] >= 3 and rate['rate'] >= 0.7:
                        cycle_parts.append(f"{key}æ—¥é€£ç¶šå¥½èª¿ã®ç¿Œæ—¥ã‚‚å¥½èª¿ç‡{rate['rate']:.0%}ï¼ˆ{rate['good']}/{rate['total']}å›ï¼‰")
            # äº¤äº’ãƒ‘ã‚¿ãƒ¼ãƒ³
            alt_score = cycle_analysis.get('alternating_score', 0)
            if alt_score >= 0.6 and cycle_analysis.get('total_days', 0) >= 7:
                cycle_parts.append(f"äº¤äº’ãƒ‘ã‚¿ãƒ¼ãƒ³å‚¾å‘ã‚ã‚Š({alt_score:.0%})")
            # å¹³å‡å‘¨æœŸ
            avg_cycle = cycle_analysis.get('avg_cycle', 0)
            if avg_cycle > 0 and cycle_analysis.get('total_days', 0) >= 7:
                if avg_cycle <= 1.5:
                    cycle_parts.append(f"ã»ã¼æ¯æ—¥å¥½èª¿ã«ãªã‚‹å°")
                elif avg_cycle <= 2.5:
                    cycle_parts.append(f"2æ—¥ã«1å›ãã‚‰ã„å¥½èª¿ã«ãªã‚‹å°")
                else:
                    cycle_parts.append(f"å¥½èª¿ã«ãªã‚‹ã®ã¯{avg_cycle:.0f}æ—¥ã«1å›ãƒšãƒ¼ã‚¹")
            if cycle_parts:
                reasons.append(f"ğŸ” {' / '.join(cycle_parts)}")

        # æ›œæ—¥ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆPhase 3+ï¼‰
        weekday_pattern = kwargs.get('weekday_pattern', {})
        if weekday_pattern and analysis_phase >= 3:
            wd_data = weekday_pattern.get(today_weekday, {})
            if wd_data.get('total', 0) >= 2:
                wd_rate = wd_data['rate']
                wd_total = wd_data['total']
                wd_good = wd_data['good']
                if wd_rate >= 0.7:
                    reasons.append(f"ğŸ“… ã“ã®å°ã®{today_weekday}æ›œå¥½èª¿ç‡: {wd_good}/{wd_total}å›({wd_rate:.0%}) â†’ æœŸå¾…å¤§")
                elif wd_rate <= 0.3:
                    reasons.append(f"ğŸš¨ ã“ã®å°ã®{today_weekday}æ›œå¥½èª¿ç‡: {wd_good}/{wd_total}å›({wd_rate:.0%}) â†’ è¦æ³¨æ„")

        # å°å€‹åˆ¥ã®æ›œæ—¥åˆ¥å¥½èª¿ç‡ï¼ˆè“„ç©ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
        unit_weekday = historical_perf.get('weekday_breakdown', {})
        if unit_weekday and today_weekday:
            uwd = unit_weekday.get(today_weekday, {})
            if uwd.get('total', 0) >= 3:  # ã‚µãƒ³ãƒ—ãƒ«3ä»¥ä¸Š
                uwd_rate = uwd['good'] / uwd['total']
                if uwd_rate >= 0.8:
                    reasons.append(f"ğŸ“… ã“ã®å°ã®{today_weekday}æ›œå®Ÿç¸¾: {uwd['good']}/{uwd['total']}å›å¥½èª¿ï¼ˆ{uwd_rate:.0%}ï¼‰")
                elif uwd_rate <= 0.2:
                    reasons.append(f"ğŸš¨ ã“ã®å°ã®{today_weekday}æ›œå®Ÿç¸¾: {uwd['good']}/{uwd['total']}å›å¥½èª¿ï¼ˆ{uwd_rate:.0%}ï¼‰â†’ ã“ã®æ›œæ—¥ã¯å¼±ã„")

        # ãªãœä»Šæ—¥ã‚‚å¥½èª¿ã¨è¦‹ã‚‹ã‹ã®æ ¹æ‹ ã‚’è¿½åŠ 
        continuation_rate = historical_perf.get('continuation_rate', 0)
        continuation_total = historical_perf.get('continuation_total', 0)
        continuation_good = historical_perf.get('continuation_good', 0)

        # åº—èˆ—å‚¾å‘ã¯å°ã®æ¨å¥¨ç†ç”±ã¨ã—ã¦ã¯è¡¨ç¤ºã—ãªã„ï¼ˆå°å›ºæœ‰ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
        # åº—èˆ—å‚¾å‘ã¯åº—èˆ—åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§åˆ¥é€”è¡¨ç¤º
    elif total_perf_days > 0 and good_day_rate <= 0.4:
        reasons.append(f"ğŸ“Š {total_perf_days}æ—¥é–“ä¸­{good_days}æ—¥å¥½èª¿ï¼ˆå¥½èª¿ç‡{good_day_rate:.0%}ï¼‰â†’ ä½è¨­å®šãŒå…¥ã‚Šã‚„ã™ã„å°")
    elif base_rank == 'S':
        if total_perf_days > 0 and good_day_rate < 0.5:
            reasons.append(f"ğŸ“Š éå»ãƒ‡ãƒ¼ã‚¿Sãƒ©ãƒ³ã‚¯ï¼ˆãŸã ã—ç›´è¿‘{total_perf_days}æ—¥ã¯å¥½èª¿{good_days}æ—¥ã®ã¿={good_day_rate:.0%}ï¼‰")
        else:
            reasons.append(f"ğŸ“Š éå»ãƒ‡ãƒ¼ã‚¿Sãƒ©ãƒ³ã‚¯: é«˜è¨­å®šãŒé »ç¹ã«å…¥ã‚‹å°")
    elif base_rank == 'A':
        consecutive_bad = historical_perf.get('consecutive_bad', 0)
        if total_perf_days > 0 and good_day_rate < 0.5:
            reasons.append(f"ğŸ“Š éå»ãƒ‡ãƒ¼ã‚¿Aãƒ©ãƒ³ã‚¯ï¼ˆãŸã ã—ç›´è¿‘{total_perf_days}æ—¥ã¯å¥½èª¿{good_days}æ—¥ã®ã¿={good_day_rate:.0%}ï¼‰")
        elif consecutive_bad >= 2:
            reasons.append(f"ğŸ“Š éå»ãƒ‡ãƒ¼ã‚¿Aãƒ©ãƒ³ã‚¯ï¼ˆå¥½èª¿ç‡{good_day_rate:.0%}ã ãŒç›´è¿‘{consecutive_bad}æ—¥é€£ç¶šä¸èª¿ä¸­ï¼‰")
        else:
            reasons.append(f"ğŸ“Š éå»ãƒ‡ãƒ¼ã‚¿Aãƒ©ãƒ³ã‚¯: é«˜è¨­å®šãŒå…¥ã‚Šã‚„ã™ã„å°")
    elif base_rank == 'B':
        reasons.append(f"ğŸ“Š éå»ãƒ‡ãƒ¼ã‚¿Bãƒ©ãƒ³ã‚¯: ä¸­é–“è¨­å®šä»¥ä¸ŠãŒå¤šã„å°")

    # === 2. é€£ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ»å‚¾å‘ï¼ˆè¨­å®šå¤‰æ›´ã‚µã‚¤ã‚¯ãƒ«ã®èª­ã¿ï¼‰ ===
    # ã“ã‚ŒãŒç¿Œæ—¥äºˆæ¸¬ã®æ ¸å¿ƒ â€” å‰æ—¥å˜ä½“ã®æˆç¸¾ã§ã¯ãªãã€Œæµã‚Œã€
    # è“„ç©ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®å›å¾©ç‡çµ±è¨ˆã‚’å–å¾—ï¼ˆåº—èˆ— â†’ è¶³ã‚Šãªã‘ã‚Œã°æ©Ÿç¨®å…¨ä½“ï¼‰
    _mk = kwargs.get('machine_key', 'sbj')
    _recovery = get_recovery_stats(store_key or '', _mk) if store_key else {}
    _machine_recovery = get_machine_recovery_stats(_mk)

    def _recovery_note(n):
        """Næ—¥é€£ç¶šä¸èª¿ã®å›å¾©ç‡æ³¨è¨˜ã‚’ç”Ÿæˆï¼ˆåº—èˆ—â†’æ©Ÿç¨®å…¨ä½“ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        rs = _recovery.get(n, {})
        if rs.get('total', 0) >= 2:
            return f"ï¼ˆã“ã®åº—ã®éå»å®Ÿç¸¾: {rs['recovered']}/{rs['total']}å›={rs['rate']:.0%}ã§ç¿Œæ—¥å›å¾©ï¼‰"
        mrs = _machine_recovery.get(n, {})
        if mrs.get('total', 0) >= 3:
            return f"ï¼ˆSBJå…¨åº—èˆ—å®Ÿç¸¾: {mrs['recovered']}/{mrs['total']}å›={mrs['rate']:.0%}ã§ç¿Œæ—¥å›å¾©ï¼‰"
        return ""

    if consecutive_minus >= 4:
        _r_note = _recovery_note(4)
        reasons.append(f"ğŸ”„ {consecutive_minus}æ—¥é€£ç¶šä¸èª¿ â†’ {next_day_label}è¨­å®šå¤‰æ›´ã®å¯èƒ½æ€§å¤§{_r_note}")
    elif consecutive_minus >= 3:
        _r_note = _recovery_note(3)
        reasons.append(f"ğŸ”„ {consecutive_minus}æ—¥é€£ç¶šä¸èª¿ â†’ ãã‚ãã‚{next_day_label}è¨­å®šä¸Šã’æœŸå¾…{_r_note}")
    elif consecutive_minus == 2:
        _r_note = _recovery_note(2)
        if today_rating >= 4:
            reasons.append(f"ğŸ”„ 2æ—¥é€£ç¶šä¸èª¿ + {store_name}ã®{today_weekday}æ›œã¯ç‹™ã„ç›® â†’ {next_day_label}ãƒªã‚»ãƒƒãƒˆæœŸå¾…{_r_note}")
        else:
            reasons.append(f"ğŸ”„ 2æ—¥é€£ç¶šä¸èª¿ â†’ {next_day_label}ãƒªã‚»ãƒƒãƒˆæœŸå¾…{_r_note}")

    if consecutive_plus >= 3:
        if today_rating >= 4:
            reasons.append(f"ğŸ”„ {consecutive_plus}æ—¥é€£ç¶šå¥½èª¿ + {store_name}ã¯{today_weekday}æ›œãŒç‹™ã„ç›® â†’ æ®ãˆç½®ãæ¿ƒåš")
        elif today_rating <= 2:
            reasons.append(f"ğŸ”„ {consecutive_plus}æ—¥é€£ç¶šå¥½èª¿ã ãŒ{store_name}ã®{today_weekday}æ›œã¯å¼±ã„æ—¥ â†’ è»¢è½è­¦æˆ’")
        else:
            reasons.append(f"ğŸ”„ {consecutive_plus}æ—¥é€£ç¶šå¥½èª¿ â†’ æ®ãˆç½®ãæœŸå¾…ï¼ˆãŸã ã—è»¢è½è­¦æˆ’ã‚‚ï¼‰")
    elif consecutive_plus == 2:
        if today_rating >= 4:
            reasons.append(f"ğŸ”„ 2æ—¥é€£ç¶šå¥½èª¿ + {store_name}ã¯{today_weekday}æ›œãŒç‹™ã„ç›® â†’ æ®ãˆç½®ãæœŸå¾…")
        elif today_rating <= 2:
            reasons.append(f"ğŸ”„ 2æ—¥é€£ç¶šå¥½èª¿ã ãŒ{store_name}ã®{today_weekday}æ›œã¯å¼±ã„æ—¥ â†’ ä¸‹ã’ã®å¯èƒ½æ€§")
        else:
            reasons.append(f"ğŸ”„ 2æ—¥é€£ç¶šå¥½èª¿ â†’ æ®ãˆç½®ãæœŸå¾…")

    # 2æ—¥é€£ç¶šä¸èª¿â†’ç¿Œæ—¥ãƒªã‚»ãƒƒãƒˆæœŸå¾…
    yesterday_prob_val = trend.get('yesterday_prob', 0)
    day_before_prob_val = trend.get('day_before_prob', 0)
    if yesterday_prob_val >= 150 and day_before_prob_val >= 150:
        _r_note2 = _recovery_note(2)
        reasons.append(f"ğŸ”„ ç›´è¿‘2æ—¥ã¨ã‚‚ä¸èª¿ï¼ˆ1/{day_before_prob_val:.0f}â†’1/{yesterday_prob_val:.0f}ï¼‰â†’ {next_day_label}è¨­å®šå¤‰æ›´æœŸå¾…å¤§{_r_note2}")

    # ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³
    if days:
        rotation = analyze_rotation_pattern(days, machine_key=_mk)
        if rotation['has_pattern'] and rotation['next_high_chance']:
            reasons.append(f"ğŸ”„ ãƒ­ãƒ¼ãƒ†å‚¾å‘: {rotation['description']} â†’ {next_day_label}ä¸Šã’æœŸå¾…")

    # === 2.5 ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ ===
    activity_data = kwargs.get('activity_data', {})
    if activity_data:
        activity_desc = activity_data.get('description', '')
        if activity_data.get('is_hyena_target'):
            reasons.append(f"ğŸš¨ {activity_desc}")
        elif activity_data.get('abandonment_type') == 'good_abandoned':
            reasons.append(f"ğŸ’¡ {activity_desc}")
        elif activity_data.get('persistence_score', 0) >= 8:
            reasons.append(f"ğŸ“Š {activity_desc}")

    # === 3. å½“æ—¥ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ï¼ˆå–¶æ¥­ä¸­ã®ã¿æœ‰ç”¨ï¼‰ ===
    # é–‰åº—å¾Œã¯ã€Œå½“æ—¥ã®çµæœã€ã¨ã—ã¦è¡¨ç¤ºï¼ˆç¿Œæ—¥äºˆæ¸¬ã®æ ¹æ‹ ã«ã¯ã—ãªã„ï¼‰
    if total_games > 0 and is_today_data:
        if art_prob > 0 and art_prob <= 80:
            reasons.append(f"ğŸ”¥ æœ¬æ—¥ARTç¢ºç‡1/{art_prob:.0f} ({total_games:,}Gæ¶ˆåŒ–) â†’ è¨­å®š6åŸŸã®æŒ™å‹•")
        elif art_prob > 0 and art_prob <= 100:
            reasons.append(f"ğŸ”¥ æœ¬æ—¥ARTç¢ºç‡1/{art_prob:.0f} ({total_games:,}Gæ¶ˆåŒ–) â†’ é«˜è¨­å®šæ¿ƒåš")
        elif art_prob > 0 and art_prob <= 130 and total_games >= 3000:
            reasons.append(f"ğŸ”¥ æœ¬æ—¥1/{art_prob:.0f}ã§å®‰å®šç¨¼åƒä¸­ ({total_games:,}Gæ¶ˆåŒ–)")
        elif art_prob > 0 and art_prob >= 200:
            reasons.append(f"ğŸš¨ æœ¬æ—¥ARTç¢ºç‡1/{art_prob:.0f} ({total_games:,}Gæ¶ˆåŒ–) â†’ ä½è¨­å®šåŸŸã®æŒ™å‹•")

    # æœ¬æ—¥ã®å¤©äº•åˆ°é”ãƒ»é€£ãƒãƒ£ãƒ³åˆ¤å®šï¼ˆå½“æ—¥ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
    if today_history and is_today_data:
        today_graph = analyze_today_graph(today_history)
        today_at_intervals = calculate_at_intervals(today_history)
        today_ceiling = sum(1 for g in today_at_intervals if g >= 999)
        if today_ceiling > 0:
            reasons.append(f"ğŸ”¥ æœ¬æ—¥å¤©äº•åˆ°é”{today_ceiling}å› â†’ ä½è¨­å®šã®å¯èƒ½æ€§ã«æ³¨æ„")
        if today_graph.get('has_explosion'):
            reasons.append(f"ğŸ”¥ æœ¬æ—¥{today_graph['max_rensa']}é€£ã®çˆ†ç™ºã‚ã‚Š")
        elif today_graph.get('is_on_fire'):
            if current_at_games <= 100:
                reasons.append("ğŸ”¥ é€£ãƒãƒ£ãƒ³ä¸­ â†’ é«˜è¨­å®šç¶™ç¶šã®æœŸå¾…")

    # === 3.5 å‡ºç‰ãƒãƒ©ãƒ³ã‚¹åˆ¤å®š ===
    medal_balance_penalty = kwargs.get('medal_balance_penalty', 0)
    if medal_balance_penalty <= -8:
        reasons.append(f"ğŸš¨ å‡ºç‰ãƒãƒ©ãƒ³ã‚¹æ‚ªã„: ARTå¤šã„ãŒæœ€å¤§æšæ•°å°‘ãªã„ï¼ˆä½è¨­å®šã®å¯èƒ½æ€§ï¼‰")
    elif medal_balance_penalty <= -5:
        reasons.append(f"ğŸš¨ ARTå›æ•°ã®å‰²ã«å‡ºç‰ãŒä¼¸ã³ã¦ã„ãªã„")

    # === 6. åº—èˆ—æ›œæ—¥å‚¾å‘ï¼ˆè£œè¶³æƒ…å ±ï¼‰ ===
    # å¥½èª¿ç‡ã®æ ¹æ‹ ã§æ—¢ã«æ›œæ—¥æƒ…å ±ã‚’å‡ºã—ã¦ãŸã‚‰é‡è¤‡ã•ã›ãªã„
    has_weekday_in_confidence = any('ä»Šæ—¥ã‚‚æœŸå¾…ã§ãã‚‹æ ¹æ‹ ' in r and today_weekday in r for r in reasons)
    # åº—èˆ—ã®æ›œæ—¥å‚¾å‘ã¯å°ã®æ¨å¥¨ç†ç”±ã«ã¯å«ã‚ãªã„ï¼ˆåº—èˆ—åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è¡¨ç¤ºï¼‰
    # ãŸã ã—å¼±ã„æ—¥ã®è­¦å‘Šã ã‘ã¯æ®‹ã™
    if store_name and today_weekday and not has_weekday_in_confidence:
        if today_rating <= 2:
            worst_info = weekday_info.get('worst_days', '')
            reasons.append(f"âš ï¸ {store_name}ã®{today_weekday}æ›œã¯å‡ºç‰ãŒå°‘ãªã„å‚¾å‘ï¼ˆæ³¨æ„ï¼‰")

    # === ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ===
    if not reasons:
        if base_rank in ('S', 'A', 'B'):
            reasons.append(f"éå»ãƒ‡ãƒ¼ã‚¿{base_rank}ãƒ©ãƒ³ã‚¯")
        if store_name and today_weekday:
            best_info = weekday_info.get('best_days', '')
            rating_label = {5: 'é«˜è¨­å®šæŠ•å…¥æ—¥', 4: 'ç‹™ã„ç›®', 3: 'æ™®é€š', 2: 'å¼±ã„æ—¥', 1: 'å›åæ—¥'}.get(today_rating, 'æ™®é€š')
            reasons.append(f"{store_name}ã®{today_weekday}æ›œã¯{rating_label}ï¼ˆåº—èˆ—å‚¾å‘{'ï¼š' + best_info if best_info else ''}ï¼‰")

    # æ ¹æ‹ ã®å„ªå…ˆåº¦ã‚½ãƒ¼ãƒˆï¼ˆãƒ­ãƒ¼ãƒ†ãƒ»å‘¨æœŸãƒ»å‚¾å‘ã‚’å…ˆã«ã€éå»ãƒ©ãƒ³ã‚¯ã¯å¾Œã«ï¼‰
    def _reason_priority(r):
        if 'ğŸ”„' in r and ('ãƒ­ãƒ¼ãƒ†' in r or 'é€£ç¶šä¸èª¿' in r or 'é€£ç¶šå¥½èª¿' in r):
            return 0  # ãƒ­ãƒ¼ãƒ†ãƒ»è¨­å®šå¤‰æ›´ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå°ã”ã¨ã«é•ã†â†’å·®åˆ¥åŒ–ã§ãã‚‹ï¼‰
        if 'ğŸ”' in r:
            return 1  # è¨­å®šå¤‰æ›´å‘¨æœŸ
        if 'ğŸ”¥' in r or 'ğŸ’¡' in r:
            return 2  # æœ¬æ—¥ãƒ‡ãƒ¼ã‚¿ãƒ»æœŸå¾…æ ¹æ‹ 
        if 'ğŸ“ˆ' in r:
            return 3  # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆå°ã”ã¨ã«é•ã†ï¼‰
        if 'ğŸ“…' in r and 'ã“ã®å°ã®' in r:
            return 4  # å°å›ºæœ‰ã®æ›œæ—¥å‚¾å‘
        if 'ğŸ“…' in r:
            return 7  # åº—èˆ—å…¨ä½“ã®æ›œæ—¥å‚¾å‘ï¼ˆå…¨å°å…±é€šâ†’å·®åˆ¥åŒ–ã§ããªã„â†’å¾Œå›ã—ï¼‰
        if 'ğŸ“Š' in r and ('å¥½èª¿ç‡' in r or 'é«˜è¨­å®š' in r):
            return 8  # éå»ãƒ©ãƒ³ã‚¯ï¼ˆå·®åˆ¥åŒ–å¼±ã„â†’æœ€å¾Œï¼‰
        return 5

    reasons.sort(key=_reason_priority)

    # é‡è¤‡é™¤å» + åŒã‚«ãƒ†ã‚´ãƒªé‡è¤‡æ’é™¤ã€ä¸Šä½4ã¤
    seen = set()
    seen_categories = set()
    unique = []
    for r in reasons:
        if r in seen:
            continue
        # åŒã‚«ãƒ†ã‚´ãƒªã®é‡è¤‡ã‚’æ’é™¤ï¼ˆåº—èˆ—å‚¾å‘ãŒ2å›å‡ºã‚‹ã®ã‚’é˜²ãç­‰ï¼‰
        category = None
        if 'åº—èˆ—å‚¾å‘' in r:
            category = 'store_weekday'
        elif 'å¥½èª¿ç¿Œæ—¥' in r:
            category = 'continuation'
        elif 'å¥½èª¿ç‡' in r and 'å°' in r:
            category = 'unit_rate'
        elif 'å¹³å‡ART' in r:
            category = 'avg_prob'
        if category and category in seen_categories:
            continue
        if category:
            seen_categories.add(category)
        seen.add(r)
        unique.append(r)

    # ã€Œæœ¬æ—¥ã€ã€Œå‰æ—¥ã€ã€Œå‰ã€…æ—¥ã€ã‚’æ—¥ä»˜ãƒ©ãƒ™ãƒ«ã«ç½®æ›
    if data_date_label or prev_date_label:
        # å‰ã€…æ—¥ãƒ©ãƒ™ãƒ«ã‚’è¨ˆç®—
        prev_prev_label = None
        if prev_date_label:
            try:
                # prev_date_labelã‹ã‚‰æ—¥ä»˜ã‚’é€†ç®—ã—ã¦å‰ã€…æ—¥ã‚’æ±‚ã‚ã‚‹
                import re as _re
                m = _re.match(r'(\d+)/(\d+)', prev_date_label)
                if m:
                    from datetime import datetime as _dt, timedelta as _td
                    _now = _dt.now()
                    _prev = _now.replace(month=int(m.group(1)), day=int(m.group(2)))
                    _prev2 = _prev - _td(days=1)
                    _weekdays = ['æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ','æ—¥']
                    prev_prev_label = f"{_prev2.month}/{_prev2.day}({_weekdays[_prev2.weekday()]})"
            except:
                prev_prev_label = f'{prev_date_label}ã®å‰æ—¥'

        replaced = []
        for r in unique[:5]:
            # å‰ã€…æ—¥ã‚’å…ˆã«ç½®æ›ï¼ˆã€Œå‰æ—¥ã€ã®å‰ã«å‡¦ç†ã—ãªã„ã¨é‡è¤‡ç½®æ›ã•ã‚Œã‚‹ï¼‰
            if prev_prev_label:
                r = r.replace('å‰ã€…æ—¥', prev_prev_label)
            if data_date_label:
                r = r.replace('æœ¬æ—¥', data_date_label)
            if prev_date_label:
                r = r.replace('å‰æ—¥', prev_date_label)
            replaced.append(r)
        return replaced

    # åº—èˆ—å‚¾å‘ã®æ ¹æ‹ ã‚’æœ«å°¾ã«ç§»å‹•
    # å°å€‹åˆ¥ã®ãƒ‡ãƒ¼ã‚¿æ ¹æ‹ ã‚’å„ªå…ˆã€åº—èˆ—å…¨ä½“ã®å‚¾å‘ã¯è£œåŠ©æƒ…å ±ã¨ã—ã¦æœ€å¾Œ
    store_reasons = []
    other_reasons = []
    for r in unique[:5]:
        # ã€ŒğŸ’¡ â—¯â—¯ã®â—¯æ›œã¯ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ = åº—èˆ—å‚¾å‘
        if r.startswith('ğŸ’¡') and 'æ›œ' in r and 'åº—èˆ—å‚¾å‘' in r:
            store_reasons.append(r)
        # ã€ŒğŸ“… â—¯â—¯ã®â—¯æ›œã¯é«˜è¨­å®šæŠ•å…¥æ—¥ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ = åº—èˆ—å‚¾å‘
        elif r.startswith('ğŸ“…') and 'æ›œ' in r and ('æŠ•å…¥æ—¥' in r or 'ç‹™ã„ç›®' in r):
            store_reasons.append(r)
        else:
            other_reasons.append(r)
    return (other_reasons + store_reasons)[:5]


def generate_store_analysis(store_key: str, daily_data: dict = None) -> dict:
    """åº—èˆ—ã®æ©Ÿç¨®å…¨ä½“åˆ†æã‚’ç”Ÿæˆ

    Returns:
        {
            'store_name': str,
            'machine_name': str,
            'total_units': int,
            'rank_dist': str,         # "S:4å° / A:7å° / B:3å°"
            'high_count': int,
            'high_ratio': float,
            'overall': str,           # å…¨ä½“è©•ä¾¡ãƒ†ã‚­ã‚¹ãƒˆ
            'weekday_info': dict,
            'daily_summary': str,
        }
    """
    store = STORES.get(store_key)
    if not store:
        return {}

    store_name = store.get('short_name', store.get('name', ''))
    machine_key = store.get('machine', 'sbj')
    machine_info = MACHINES.get(machine_key, {})
    units = store.get('units', [])
    total_units = len(units)

    # ãƒ©ãƒ³ã‚¯åˆ†å¸ƒï¼ˆã‚­ãƒ¼ã®ãƒŸã‚¹ãƒãƒƒãƒã‚’è€ƒæ…®ï¼‰
    rankings = RANKINGS.get(store_key, {})
    if not rankings:
        for suffix in ['_sbj', '_hokuto', '_hokuto_tensei2']:
            if store_key.endswith(suffix):
                alt_key = store_key[:-len(suffix)]
                rankings = RANKINGS.get(alt_key, {})
                if rankings:
                    break

    rank_counts = {'S': 0, 'A': 0, 'B': 0, 'C': 0, 'D': 0}
    scores = []
    for uid in units:
        rank_data = rankings.get(uid, {'rank': 'C', 'score': 50})
        rank = rank_data.get('rank', 'C')
        rank_counts[rank] = rank_counts.get(rank, 0) + 1
        scores.append(rank_data.get('score', 50))

    avg_score = sum(scores) / len(scores) if scores else 0
    high_count = rank_counts.get('S', 0) + rank_counts.get('A', 0)
    high_ratio = high_count / total_units * 100 if total_units > 0 else 0

    # ãƒ©ãƒ³ã‚¯åˆ†å¸ƒãƒ†ã‚­ã‚¹ãƒˆ
    rank_parts = []
    for rank in ['S', 'A', 'B', 'C', 'D']:
        count = rank_counts.get(rank, 0)
        if count > 0:
            rank_parts.append(f"{rank}:{count}å°")
    rank_dist_text = " / ".join(rank_parts)

    # å…¨ä½“è©•ä¾¡
    if high_ratio >= 70:
        overall = f"é«˜è¨­å®šå°ãŒéå¸¸ã«å¤šã„ï¼ˆå…¨{total_units}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
    elif high_ratio >= 50:
        overall = f"é«˜è¨­å®šå°ãŒå¤šã‚ï¼ˆå…¨{total_units}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"
    elif high_ratio >= 30:
        overall = f"é«˜è¨­å®šå°ã‚ã‚Šï¼ˆå…¨{total_units}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šã€å°é¸ã³ãŒé‡è¦ï¼‰"
    else:
        overall = f"é«˜è¨­å®šå°ãŒå°‘ãªã„ï¼ˆå…¨{total_units}å°ä¸­{high_count}å°ãŒAä»¥ä¸Šï¼‰"

    # æ›œæ—¥å‚¾å‘
    weekday_info = get_store_weekday_info(store_key)

    # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®åˆ†æ
    daily_summary = ""
    if daily_data:
        data_store_key = STORE_KEY_MAPPING.get(store_key, store_key)
        store_data = None
        for key in [data_store_key, store_key]:
            store_data = daily_data.get('stores', {}).get(key, {})
            if store_data:
                break

        if store_data and store_data.get('units'):
            total_art_all = 0
            total_games_all = 0
            total_days = 0
            for unit in store_data['units']:
                for day in unit.get('days', []):
                    art = day.get('art', 0)
                    games = day.get('total_start', 0)
                    if games > 0:
                        total_art_all += art
                        total_games_all += games
                        total_days += 1

            if total_days > 0:
                avg_art_per_unit_day = total_art_all / total_days
                if total_art_all > 0:
                    overall_prob = total_games_all / total_art_all
                    daily_summary = f"å…¨å°å¹³å‡ART {avg_art_per_unit_day:.0f}å›/æ—¥ï¼ˆç¢ºç‡1/{overall_prob:.0f}ï¼‰"

    return {
        'store_name': store_name,
        'machine_name': machine_info.get('short_name', ''),
        'total_units': total_units,
        'rank_dist': rank_dist_text,
        'rank_counts': rank_counts,
        'high_count': high_count,
        'high_ratio': high_ratio,
        'overall': overall,
        'avg_score': avg_score,
        'weekday_info': weekday_info,
        'daily_summary': daily_summary,
    }


def recommend_units(store_key: str, realtime_data: dict = None, availability: dict = None,
                    data_date_label: str = None, prev_date_label: str = None) -> list:
    """æ¨å¥¨å°ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ

    Args:
        store_key: åº—èˆ—ã‚­ãƒ¼
        realtime_data: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        availability: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç©ºãçŠ¶æ³ {å°ç•ªå·: 'ç©ºã' or 'éŠæŠ€ä¸­'}

    Returns:
        æ¨å¥¨å°ãƒªã‚¹ãƒˆï¼ˆã‚¹ã‚³ã‚¢é †ï¼‰
    """
    store = STORES.get(store_key)
    if not store:
        return []

    store_name = store.get('short_name', store.get('name', ''))
    machine_key = get_machine_from_store_key(store_key)
    machine_info = MACHINES.get(machine_key, {})

    # JSONãƒ‡ãƒ¼ã‚¿å†…ã®åº—èˆ—ã‚­ãƒ¼ã‚’å–å¾—
    data_store_key = STORE_KEY_MAPPING.get(store_key, store_key)

    store_rankings = RANKINGS.get(store_key, {})
    recommendations = []

    # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    daily_data = load_daily_data(machine_key=machine_key)

    # å…¨å°ã®å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ï¼ˆæ¯”è¼ƒç”¨ï¼‰
    all_units_today = []
    if realtime_data and 'units' in realtime_data:
        all_units_today = realtime_data.get('units', [])
    elif daily_data:
        # ãƒ‡ãƒ¼ã‚¿å†…ã®åº—èˆ—ã‚­ãƒ¼ã§æ¤œç´¢ï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œï¼‰
        store_data = None
        for key_to_try in [data_store_key, store_key, f'{store_key}_sbj']:
            store_data = daily_data.get('stores', {}).get(key_to_try, {})
            if store_data:
                break

        if store_data:
            for unit in store_data.get('units', []):
                # å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
                today_str = datetime.now().strftime('%Y-%m-%d')
                for day in unit.get('days', []):
                    if day.get('date') == today_str:
                        all_units_today.append(day)
                        break

    for unit_id in store.get('units', []):
        # åŸºæœ¬ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        ranking = get_unit_ranking(store_key, unit_id)
        base_score = ranking.get('score', 50)
        base_rank = ranking.get('rank', 'C')
        note = ranking.get('note', '')
        has_static_ranking = note != 'æœªè©•ä¾¡'

        # éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        trend_data = {'reasons': []}
        unit_history = None

        # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰éå»å±¥æ­´ã‚’å–å¾—
        if daily_data:
            # ãƒ‡ãƒ¼ã‚¿å†…ã®åº—èˆ—ã‚­ãƒ¼ã§æ¤œç´¢ï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦è¡Œï¼‰
            store_data = None
            for key_to_try in [data_store_key, store_key, f'{store_key}_sbj']:
                store_data = daily_data.get('stores', {}).get(key_to_try, {})
                if store_data:
                    break

            if store_data:
                for unit in store_data.get('units', []):
                    if unit.get('unit_id') == unit_id:
                        unit_history = unit
                        days = unit.get('days', [])
                        trend_data = analyze_trend(days, machine_key)
                        break

        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒç„¡ã„å ´åˆã€æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰base_scoreã‚’å‹•çš„è¨ˆç®—
        if not has_static_ranking and unit_history:
            _days = unit_history.get('days', [])
            # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹æ—¥ã®ã¿ä½¿ç”¨
            _day_probs = []
            for _d in _days:
                _a = _d.get('art', 0)
                _g = _d.get('total_start', 0)
                if _a > 0 and _g > 500:
                    _day_probs.append(_g / _a)
            if len(_day_probs) >= 2:
                _avg = sum(_day_probs) / len(_day_probs)
                _worst = max(_day_probs)  # æœ€æ‚ªæ—¥ï¼ˆç¢ºç‡ãŒé«˜ã„=æ‚ªã„ï¼‰

                # åº—èˆ—å†…ã®å…¨å°ã®å¹³å‡ç¢ºç‡ã‚’è¨ˆç®—ã—ã¦ç›¸å¯¾è©•ä¾¡
                # ã“ã‚Œã«ã‚ˆã‚Šã€ŒåŒ—æ–—ã®å…¨ARTãƒ™ãƒ¼ã‚¹ã§å…¨å°goodåŸŸã«è¦‹ãˆã‚‹ã€å•é¡Œã‚’å›é¿
                _store_probs = []
                if store_data:
                    for _su in store_data.get('units', []):
                        _sd = _su.get('days', [])
                        _sp = []
                        for _dd in _sd:
                            _sa = _dd.get('art', 0); _sg = _dd.get('total_start', 0)
                            if _sa > 0 and _sg > 500:
                                _sp.append(_sg / _sa)
                        if _sp:
                            _store_probs.append(sum(_sp) / len(_sp))

                if len(_store_probs) >= 5:
                    # åº—èˆ—å†…ç›¸å¯¾è©•ä¾¡: ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã§base_scoreã‚’æ±ºå®š
                    _store_probs_sorted = sorted(_store_probs)
                    _rank_pos = sum(1 for p in _store_probs_sorted if p > _avg)  # å°ã•ã„æ–¹ãŒè‰¯ã„
                    _pct = _rank_pos / len(_store_probs_sorted)
                    if _pct >= 0.85:  # ä¸Šä½15%
                        base_score = 70
                    elif _pct >= 0.65:  # ä¸Šä½35%
                        base_score = 60
                    elif _pct >= 0.35:  # ä¸­é–“
                        base_score = 50
                    else:  # ä¸‹ä½35%
                        base_score = 42
                else:
                    # å°æ•°ãŒå°‘ãªã„å ´åˆã¯çµ¶å¯¾è©•ä¾¡
                    _good = get_machine_threshold(machine_key, 'good_prob')
                    _bad = get_machine_threshold(machine_key, 'bad_prob')
                    if _avg <= _good * 0.65 and _worst <= _good and len(_day_probs) >= 4:
                        base_score = 70
                    elif _avg <= _good * 0.85 and _worst <= _bad:
                        base_score = 60
                    elif _avg <= _bad:
                        base_score = 50
                    else:
                        base_score = 42
                base_rank = get_rank(base_score)

        # å½“æ—¥ãƒ‡ãƒ¼ã‚¿åˆ†æ
        today_analysis = {'status': '-', 'today_score_bonus': 0, 'today_reasons': []}

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜æ¤œè¨¼ï¼ˆä»Šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ï¼‰
        realtime_is_today = False
        if realtime_data:
            fetched_at = realtime_data.get('fetched_at', '')
            if fetched_at:
                try:
                    fetch_date = datetime.fromisoformat(fetched_at).strftime('%Y-%m-%d')
                    today_str_check = datetime.now().strftime('%Y-%m-%d')
                    realtime_is_today = (fetch_date == today_str_check)
                except:
                    pass

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã€ã‹ã¤ä»Šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã®ã¿ä½¿ç”¨
        if realtime_data and realtime_is_today:
            units_list = None
            if 'units' in realtime_data:
                units_list = realtime_data.get('units', [])
            elif 'stores' in realtime_data:
                # ãƒ‡ãƒ¼ã‚¿å†…ã®åº—èˆ—ã‚­ãƒ¼ã§æ¤œç´¢
                store_data = None
                for key_to_try in [data_store_key, store_key, f'{store_key}_sbj']:
                    store_data = realtime_data.get('stores', {}).get(key_to_try, {})
                    if store_data:
                        break
                if store_data:
                    units_list = store_data.get('units', [])

            if units_list:
                for unit in units_list:
                    if unit.get('unit_id') == unit_id:
                        today_analysis = analyze_today_data(unit, machine_key=machine_key)
                        break

        # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚‚åˆ†æï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆï¼‰
        if daily_data and today_analysis.get('status') == '-':
            # ãƒ‡ãƒ¼ã‚¿å†…ã®åº—èˆ—ã‚­ãƒ¼ã§æ¤œç´¢
            store_data = None
            for key_to_try in [data_store_key, store_key, f'{store_key}_sbj']:
                store_data = daily_data.get('stores', {}).get(key_to_try, {})
                if store_data:
                    break

            if store_data:
                for unit in store_data.get('units', []):
                    if unit.get('unit_id') == unit_id:
                        today_analysis = analyze_today_data(unit, machine_key=machine_key)
                        break

        # ä»–å°ã¨ã®æ¯”è¼ƒ
        comparison = compare_with_others(store_key, unit_id, all_units_today)

        # === ãƒˆãƒ¬ãƒ³ãƒ‰ã«ã‚ˆã‚‹ã‚¹ã‚³ã‚¢èª¿æ•´ ===
        trend_bonus = 0
        if trend_data.get('consecutive_minus', 0) >= 3:
            trend_bonus += 10  # å‡¹ã¿ç¶šãã¯ä¸Šã’æœŸå¾…
        elif trend_data.get('consecutive_minus', 0) >= 2:
            trend_bonus += 5
        if trend_data.get('yesterday_result') == 'big_minus':
            trend_bonus += 8  # æ˜¨æ—¥å¤§å¹…ãƒã‚¤ãƒŠã‚¹ã¯ç‹™ã„ç›®
        elif trend_data.get('yesterday_result') == 'big_plus':
            trend_bonus -= 5  # æ˜¨æ—¥å¤§å¹…ãƒ—ãƒ©ã‚¹ã¯æ®ãˆç½®ãorä¸‹ã’è­¦æˆ’

        if trend_data.get('consecutive_plus', 0) >= 3:
            trend_bonus += 5  # é€£ç¶šãƒ—ãƒ©ã‚¹ã¯æ®ãˆç½®ãæœŸå¾…
        if trend_data.get('art_trend') == 'improving':
            trend_bonus += 3

        # === ã€æ”¹å–„1ã€‘å°ç•ªå·ã”ã¨ã®çš„ä¸­ç‡ï¼ˆéå»å®Ÿç¸¾ï¼‰ã‚’ã‚¹ã‚³ã‚¢ã«åæ˜  ===
        # è“„ç©DBãŒã‚ã‚Œã°ãã¡ã‚‰ã‚’å„ªå…ˆï¼ˆé•·æœŸãƒ‡ãƒ¼ã‚¿ï¼‰
        from analysis.history_accumulator import (
            load_unit_history as load_accumulated_history,
            get_analysis_phase, analyze_setting_change_cycle,
            analyze_weekday_pattern,
        )
        accumulated = load_accumulated_history(store_key, unit_id)
        analysis_phase = get_analysis_phase(accumulated)
        cycle_analysis = {}
        weekday_pattern = {}

        # è“„ç©ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ã€unit_historyã®daysã‚’ãƒãƒ¼ã‚¸
        if accumulated.get('days') and unit_history:
            # è“„ç©DBã®æ—¥ä»˜ã‚’å„ªå…ˆã€unit_historyã§è£œå®Œ
            acc_dates = {d['date'] for d in accumulated['days']}
            for d in unit_history.get('days', []):
                if d.get('date') and d['date'] not in acc_dates:
                    accumulated['days'].append({
                        'date': d['date'],
                        'art': d.get('art', 0),
                        'games': d.get('total_start', 0),
                        'prob': d.get('total_start', 0) / d.get('art', 1) if d.get('art', 0) > 0 else 0,
                        'is_good': (d.get('total_start', 0) / d.get('art', 1) if d.get('art', 0) > 0 else 999) <= (130 if machine_key == 'sbj' else 330) and d.get('art', 0) >= (20 if machine_key == 'sbj' else 10),
                    })
            accumulated['days'].sort(key=lambda x: x.get('date', ''))
            analysis_phase = get_analysis_phase(accumulated)

        # è“„ç©DBã®æ–¹ãŒdaily JSONã‚ˆã‚Šæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã„ã‚‹å ´åˆã€
        # trend_dataã‚’è“„ç©DBã®daysã§å†è¨ˆç®—ã™ã‚‹
        if accumulated.get('days'):
            acc_days_for_trend = []
            for d in accumulated['days']:
                _games = d.get('total_start', 0) or d.get('games', 0)
                acc_days_for_trend.append({
                    'date': d.get('date', ''),
                    'art': d.get('art', 0),
                    'total_start': _games,
                    'games': _games,
                    'rb': d.get('rb', 0),
                    'prob': d.get('prob', 0),
                    'history': d.get('history', []),
                    'max_rensa': d.get('max_rensa', 0),
                    'max_medals': d.get('max_medals', 0),
                })
            trend_from_acc = analyze_trend(acc_days_for_trend, machine_key)
            # è“„ç©DBã®æ–¹ãŒæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ã€trend_dataã‚’ä¸Šæ›¸ã
            acc_latest = max(d.get('date', '') for d in accumulated['days']) if accumulated['days'] else ''
            trend_latest = trend_data.get('yesterday_date', '')
            if acc_latest > trend_latest:
                trend_data = trend_from_acc

        # Phase 2+: è¨­å®šå¤‰æ›´å‘¨æœŸåˆ†æ
        if analysis_phase >= 2:
            cycle_analysis = analyze_setting_change_cycle(accumulated, machine_key)
        # Phase 3+: æ›œæ—¥åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³
        if analysis_phase >= 3:
            weekday_pattern = analyze_weekday_pattern(accumulated, machine_key)

        # éå»ã®å¥½èª¿ç‡ãŒé«˜ã„å°ã«ãƒœãƒ¼ãƒŠã‚¹ã€ä½ã„å°ã«ãƒšãƒŠãƒ«ãƒ†ã‚£
        historical_bonus = 0
        historical_perf = {}
        perf_days = accumulated.get('days', []) if accumulated.get('days') else (unit_history.get('days', []) if unit_history else [])
        if perf_days:
            historical_perf = calculate_unit_historical_performance(perf_days, machine_key)
            historical_bonus = historical_perf.get('score_bonus', 0)

        # === ã€æ”¹å–„2ã€‘å‰æ—¥ä¸èª¿â†’ç¿Œæ—¥ç‹™ã„ç›®ã®é‡ã¿ä»˜ã‘å¼·åŒ– ===
        # å‰æ—¥ä¸èª¿ï¼ˆ1/150ä»¥ä¸Šï¼‰ã®å°ã¯ã€ç¿Œæ—¥è¨­å®šå¤‰æ›´ã§ä¸ŠãŒã‚‹å¯èƒ½æ€§ãŒ75%
        # 2æ—¥é€£ç¶šä¸èª¿ã®å°ã¯ã•ã‚‰ã«ã‚¹ã‚³ã‚¢ã‚¢ãƒƒãƒ—ï¼ˆè¨­å®šå¤‰æ›´æœŸå¾…ï¼‰
        slump_bonus = 0
        yesterday_prob = trend_data.get('yesterday_prob', 0)
        day_before_prob = trend_data.get('day_before_prob', 0)
        bad_prob_threshold = get_machine_threshold(machine_key, 'bad_prob')

        if yesterday_prob >= bad_prob_threshold:
            slump_bonus += 5  # å‰æ—¥ä¸èª¿ â†’ ç¿Œæ—¥è¨­å®šå¤‰æ›´æœŸå¾…
            if day_before_prob >= bad_prob_threshold:
                slump_bonus += 5  # 2æ—¥é€£ç¶šä¸èª¿ â†’ ã•ã‚‰ã«è¨­å®šå¤‰æ›´æœŸå¾…ï¼ˆåˆè¨ˆ+10ï¼‰

        # === å‡ºç‰ãƒãƒ©ãƒ³ã‚¹åˆ¤å®š ===
        # ARTå›æ•°ãŒå¤šã„ã®ã«æœ€å¤§æšæ•°ãŒå°‘ãªã„ â†’ é€£ãƒãƒ£ãƒ³ãŒå¼±ã„ = ä½è¨­å®šã®å¯èƒ½æ€§
        # åŒ—æ–—ã§50å›å½“ãŸã£ã¦æœ€å¤§2574æšã®ã‚ˆã†ãªã‚±ãƒ¼ã‚¹ã«ãƒšãƒŠãƒ«ãƒ†ã‚£
        medal_balance_penalty = 0
        if realtime_data and realtime_is_today:
            units_list = realtime_data.get('units', [])
            for _unit in units_list:
                if _unit.get('unit_id') == unit_id:
                    _art = _unit.get('art', 0)
                    _max_medals = _unit.get('max_medals', 0)
                    if machine_key == 'sbj':
                        if _art >= 50 and _max_medals > 0 and _max_medals < 5000:
                            medal_balance_penalty = -8  # ART50å›ä»¥ä¸Šã§æœ€å¤§5000æšæœªæº€
                        elif _art >= 30 and _max_medals > 0 and _max_medals < 3000:
                            medal_balance_penalty = -5  # ART30å›ä»¥ä¸Šã§æœ€å¤§3000æšæœªæº€
                    elif machine_key == 'hokuto_tensei2':
                        if _art >= 50 and _max_medals > 0 and _max_medals < 3000:
                            medal_balance_penalty = -10  # AT50å›ä»¥ä¸Šã§æœ€å¤§3000æšæœªæº€
                        elif _art >= 30 and _max_medals > 0 and _max_medals < 3000:
                            medal_balance_penalty = -5  # AT30å›ä»¥ä¸Šã§æœ€å¤§3000æšæœªæº€
                    break

        # === ã€æ”¹å–„4ã€‘ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ ===
        activity_bonus = 0
        activity_data = {}
        if unit_history:
            # ç›´è¿‘æ—¥ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã§ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            sorted_unit_days = sorted(
                unit_history.get('days', []),
                key=lambda x: x.get('date', ''), reverse=True
            )
            for day_item in sorted_unit_days:
                hist_for_activity = day_item.get('history', [])
                if hist_for_activity:
                    activity_data = analyze_activity_pattern(hist_for_activity, day_item)
                    activity_bonus = (
                        activity_data.get('persistence_score', 0)
                        + activity_data.get('abandonment_bonus', 0)
                        + activity_data.get('hyena_penalty', 0)  # ã€æ”¹å–„5ã€‘ãƒã‚¤ã‚¨ãƒŠãƒšãƒŠãƒ«ãƒ†ã‚£
                    )
                    # ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³ãƒœãƒ¼ãƒŠã‚¹ã¯æœ€å¤§Â±10ã«åˆ¶é™
                    activity_bonus = max(-10, min(10, activity_bonus))
                    break

        # === æ›œæ—¥ãƒœãƒ¼ãƒŠã‚¹ ===
        # åº—èˆ—ã®æ›œæ—¥å‚¾å‘ã‚’ã‚¹ã‚³ã‚¢ã«åæ˜ ï¼ˆrating 1-5 â†’ -6 ã€œ +6ï¼‰
        weekday_info = get_store_weekday_info(store_key) if store_key else {}
        _today_rating = weekday_info.get('today_rating', 3)
        weekday_bonus = (_today_rating - 3) * 3  # rating3=0, rating5=+6, rating1=-6

        # === å‰æ—¥å·®æšãƒœãƒ¼ãƒŠã‚¹ ===
        # å‰æ—¥ã«å¤§çˆ†ç™ºã—ãŸå° = é«˜è¨­å®šãŒå…¥ã£ã¦ãŸ = ç¿Œæ—¥æ®ãˆç½®ãæœŸå¾…
        yesterday_diff_bonus = 0
        _yd = trend_data.get('yesterday_diff', 0)
        if _yd >= 5000:
            yesterday_diff_bonus = 8
        elif _yd >= 3000:
            yesterday_diff_bonus = 5
        elif _yd >= 1000:
            yesterday_diff_bonus = 3
        elif _yd <= -3000:
            yesterday_diff_bonus = 3  # å¤§è² ã‘ç¿Œæ—¥ã¯è¨­å®šå¤‰æ›´æœŸå¾…

        # === åº—èˆ—è¨­å®šæŠ•å…¥ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒœãƒ¼ãƒŠã‚¹ ===
        # åº—èˆ—å›ºæœ‰ã®è¨­å®šæŠ•å…¥ç™–ï¼ˆæ®ãˆç½®ãç‡ã€ç‰¹å®šæ—¥å‚¾å‘ã€å°ç•ªå‚¾å‘ç­‰ï¼‰ã‚’è£œæ­£
        # æ—¢å­˜ã® weekday_bonus / slump_bonus ã¯ä¸€èˆ¬çš„ãªå‚¾å‘ã€
        # pattern_bonus ã¯åº—èˆ—å›ºæœ‰ã®ãƒ‡ãƒ¼ã‚¿å®Ÿç¸¾ãƒ™ãƒ¼ã‚¹
        pattern_bonus = 0
        try:
            from analysis.store_pattern import calculate_pattern_bonus
            _target_date = datetime.now().strftime('%Y-%m-%d')
            pattern_bonus = calculate_pattern_bonus(store_key, machine_key, unit_id, _target_date)
        except Exception:
            pass

        # === æœ€çµ‚ã‚¹ã‚³ã‚¢è¨ˆç®— ===
        today_bonus = today_analysis.get('today_score_bonus', 0)
        prediction_bonus = (trend_bonus
                       + historical_bonus   # ã€æ”¹å–„1ã€‘éå»å®Ÿç¸¾ãƒœãƒ¼ãƒŠã‚¹
                       + slump_bonus        # ã€æ”¹å–„2ã€‘ä¸èª¿ç¿Œæ—¥ãƒœãƒ¼ãƒŠã‚¹
                       + activity_bonus     # ã€æ”¹å–„4+5ã€‘ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³+ãƒã‚¤ã‚¨ãƒŠ
                       + medal_balance_penalty  # å‡ºç‰ãƒãƒ©ãƒ³ã‚¹ãƒšãƒŠãƒ«ãƒ†ã‚£
                       + weekday_bonus      # æ›œæ—¥ãƒœãƒ¼ãƒŠã‚¹
                       + yesterday_diff_bonus  # å‰æ—¥å·®æšãƒœãƒ¼ãƒŠã‚¹
                       + pattern_bonus      # åº—èˆ—è¨­å®šæŠ•å…¥ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒœãƒ¼ãƒŠã‚¹
                       )
        # å‰æ—¥äºˆæƒ³ãƒœãƒ¼ãƒŠã‚¹ã¯Â±20ã«ã‚­ãƒ£ãƒƒãƒ—
        prediction_bonus = max(-20, min(20, prediction_bonus))

        # å–¶æ¥­ä¸­ã®å½“æ—¥ãƒ‡ãƒ¼ã‚¿ã¯ã‚­ãƒ£ãƒƒãƒ—å¤–ï¼ˆä¿¡é ¼ã§ãã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã¯é‡ã„ï¼‰
        # é–‰åº—å¾Œã¯today_bonus=0ãªã®ã§å½±éŸ¿ãªã—
        raw_score = base_score + prediction_bonus + today_bonus

        # === ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è£œæ­£ ===
        # éå»ã®ç­”ãˆåˆã‚ã›çµæœã‹ã‚‰å°ãƒ»æ›œæ—¥ã®è£œæ­£ã‚’é©ç”¨
        feedback_bonus = 0
        try:
            from analysis.feedback import calculate_correction_factors
            corrections = calculate_correction_factors(store_key, machine_key)
            if corrections['confidence'] > 0:
                # å°ç•ªå·è£œæ­£
                uid_str = str(unit_id)
                unit_corr = corrections['unit_corrections'].get(uid_str, 0)
                # æ›œæ—¥è£œæ­£
                wd_name = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][datetime.now().weekday()]
                wd_corr = corrections['weekday_corrections'].get(wd_name, 0)
                feedback_bonus = int((unit_corr + wd_corr) * corrections['confidence'])
        except Exception:
            pass

        final_score = raw_score + feedback_bonus
        # ã€æ”¹å–„3ã€‘ãƒ©ãƒ³ã‚¯ã¯å¾Œã§ã¾ã¨ã‚ã¦ç›¸å¯¾è©•ä¾¡ã§æ±ºå®šã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ä»®ãƒ©ãƒ³ã‚¯
        final_rank = get_rank(final_score)

        # æ¨å¥¨ç†ç”±ã‚’ç”Ÿæˆï¼ˆéå»æ—¥ãƒ‡ãƒ¼ã‚¿ã¨å½“æ—¥å±¥æ­´ã‚’æ¸¡ã™ï¼‰
        unit_days = []
        today_history = []
        history_date = ''
        if unit_history:
            unit_days = unit_history.get('days', [])
            # å½“æ—¥ã®å±¥æ­´ã‚’å–å¾—ï¼ˆãªã‘ã‚Œã°ç›´è¿‘æ—¥ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            today_str = datetime.now().strftime('%Y-%m-%d')
            yesterday_str = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
            for day in unit_days:
                if day.get('date') == today_str:
                    today_history = day.get('history', [])
                    history_date = today_str
                    break
            if not today_history:
                # å½“æ—¥ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€ç›´è¿‘ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™ï¼ˆæ—¥ä»˜é™é †ï¼‰
                # ãŸã ã—ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å…ƒã®æ—¥ä»˜ã‚’è¨˜éŒ²ï¼ˆtodayæ‰±ã„ã—ãªã„ï¼‰
                sorted_days = sorted(unit_days, key=lambda x: x.get('date', ''), reverse=True)
                for day in sorted_days:
                    if day.get('history'):
                        today_history = day.get('history', [])
                        history_date = day.get('date', '')
                        break

        # ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜ã‚’å–å¾—ï¼ˆä»Šæ—¥ or æ˜¨æ—¥ï¼‰
        data_date = today_analysis.get('data_date', '')
        is_today_data = data_date == datetime.now().strftime('%Y-%m-%d') if data_date else False

        # ç¾åœ¨ã®ãƒãƒã‚ŠGæ•°ï¼ˆgenerate_reasonsã§é€£ãƒãƒ£ãƒ³ä¸­åˆ¤å®šã«å¿…è¦ï¼‰
        _final_start = 0
        if realtime_data and realtime_is_today:
            for _u in (realtime_data.get('units', [])):
                if _u.get('unit_id') == unit_id:
                    _final_start = _u.get('final_start', 0)
                    break
        current_at_games = 0
        if today_history and _final_start > 0:
            current_at_games = calculate_current_at_games(today_history, _final_start)
        elif _final_start > 0:
            current_at_games = _final_start

        reasons = generate_reasons(
            unit_id, trend_data, today_analysis, comparison, base_rank, final_rank,
            days=unit_days, today_history=today_history, store_key=store_key,
            is_today_data=is_today_data, current_at_games=current_at_games,
            historical_perf=historical_perf, activity_data=activity_data,
            medal_balance_penalty=medal_balance_penalty,
            data_date_label=data_date_label, prev_date_label=prev_date_label,
            cycle_analysis=cycle_analysis, weekday_pattern=weekday_pattern,
            analysis_phase=analysis_phase,
        )

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç©ºãçŠ¶æ³ãŒã‚ã‚‹å ´åˆã¯ä¸Šæ›¸ã
        status = today_analysis.get('status', 'ä¸æ˜')
        is_running = today_analysis.get('is_running', False)
        availability_status = None

        if availability:
            avail = availability.get(unit_id)
            if avail:
                availability_status = avail
                if avail == 'éŠæŠ€ä¸­':
                    is_running = True
                    status = 'éŠæŠ€ä¸­'
                elif avail == 'ç©ºã':
                    is_running = False
                    status = 'ç©ºã'

        # å·®æšè¦‹è¾¼ã¿è¨ˆç®—
        total_games = today_analysis.get('total_games', 0)
        art_count = today_analysis.get('art_count', 0)
        profit_info = calculate_expected_profit(total_games, art_count, machine_key)

        # max_medals, final_start ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ï¼ˆä»Šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
        max_medals = 0
        final_start = 0
        if realtime_data and realtime_is_today:
            units_list = realtime_data.get('units', [])
            for unit in units_list:
                if unit.get('unit_id') == unit_id:
                    max_medals = unit.get('max_medals', 0)
                    final_start = unit.get('final_start', 0)
                    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã«å½“æ—¥å±¥æ­´ãŒã‚ã‚Œã°ãã¡ã‚‰ã‚’ä½¿ã†
                    rt_history = unit.get('today_history')
                    if rt_history and (not today_history or len(rt_history) > len(today_history)):
                        today_history = rt_history
                    break

        # ç¾åœ¨ã®ATé–“Gæ•°ã‚’æ­£ã—ãè¨ˆç®—ï¼ˆæœ€çµ‚å¤§å½“ãŸã‚Šã‹ã‚‰ã®Gæ•°ï¼‰
        # final_startã ã‘ã§ã¯æœ€çµ‚RBå¾Œã®Gæ•°ã—ã‹åˆ†ã‹ã‚‰ãªã„ãŸã‚ã€
        # å±¥æ­´ã‹ã‚‰æœ€çµ‚å¤§å½“ãŸã‚Šä»¥é™ã®å…¨Gæ•°ã‚’åˆç®—ã™ã‚‹
        current_at_games = 0
        if today_history and final_start > 0:
            current_at_games = calculate_current_at_games(today_history, final_start)
        elif final_start > 0:
            current_at_games = final_start  # å±¥æ­´ãŒãªã„å ´åˆã¯final_startã‚’ãã®ã¾ã¾ä½¿ç”¨

        # æœ¬æ—¥ã®ATé–“ãƒ‡ãƒ¼ã‚¿ï¼ˆå±¥æ­´ã‹ã‚‰è¨ˆç®—ï¼‰
        today_at_intervals = calculate_at_intervals(today_history) if today_history else []
        today_deep_hama_count = sum(1 for g in today_at_intervals if g >= 500)  # 500Gä»¥ä¸Šã®ãƒãƒã‚Š
        today_max_at_interval = max(today_at_intervals) if today_at_intervals else 0
        today_max_rensa = calculate_max_rensa(today_history) if today_history else 0

        rec = {
            'unit_id': unit_id,
            'store_key': store_key,
            'store_name': store_name,
            'machine_name': machine_info.get('short_name', ''),
            'base_rank': base_rank,
            'base_score': base_score,
            'final_rank': final_rank,
            'final_score': final_score,
            'status': status,
            'is_running': is_running,
            'availability': availability_status,  # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç©ºãçŠ¶æ³
            'art_count': art_count,
            'bb_count': today_analysis.get('bb_count', 0),
            'rb_count': today_analysis.get('rb_count', 0),
            'total_games': total_games,
            'art_prob': today_analysis.get('art_prob', 0),
            'last_hit_time': today_analysis.get('last_hit_time'),
            'first_hit_time': today_analysis.get('first_hit_time'),
            'note': note,
            'has_static_ranking': has_static_ranking,
            # ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜æƒ…å ±
            'data_date': data_date,
            'is_today_data': is_today_data,
            # è©³ç´°åˆ†æãƒ‡ãƒ¼ã‚¿
            'trend': trend_data,
            'comparison': comparison,
            'reasons': reasons,
            # ã‚µãƒãƒªãƒ¼
            'yesterday_diff': trend_data.get('yesterday_diff', 0),
            'yesterday_art': trend_data.get('yesterday_art', 0),
            'yesterday_rb': trend_data.get('yesterday_rb', 0),
            'yesterday_games': trend_data.get('yesterday_games', 0),
            'yesterday_date': trend_data.get('yesterday_date', ''),
            'yesterday_prob': trend_data.get('yesterday_prob', 0),
            'day_before_art': trend_data.get('day_before_art', 0),
            'day_before_rb': trend_data.get('day_before_rb', 0),
            'day_before_games': trend_data.get('day_before_games', 0),
            'day_before_date': trend_data.get('day_before_date', ''),
            'day_before_prob': trend_data.get('day_before_prob', 0),
            'yesterday_max_rensa': trend_data.get('yesterday_max_rensa', 0),
            'yesterday_max_medals': trend_data.get('yesterday_max_medals', 0),
            'max_medals': max_medals,
            # 3æ—¥ç›®ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆè“„ç©DBã‹ã‚‰å–å¾—ï¼‰
            'three_days_ago_art': 0,
            'three_days_ago_rb': 0,
            'three_days_ago_games': 0,
            'three_days_ago_date': '',
            'consecutive_plus': trend_data.get('consecutive_plus', 0),
            'consecutive_minus': trend_data.get('consecutive_minus', 0),
            'avg_art_7days': trend_data.get('avg_art_7days', 0),
            'recent_days': trend_data.get('recent_days', []),
            # ç¾åœ¨ã®ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆæœ€çµ‚å¤§å½“ãŸã‚Šå¾Œã®Gæ•°ã€RBã‚’è·¨ã„ã§æ­£ç¢ºã«è¨ˆç®—ï¼‰
            'current_hama': current_at_games,
            # æœ¬æ—¥ã®ATé–“åˆ†æ
            'today_deep_hama': today_deep_hama_count,  # 500Gä»¥ä¸Šã®ãƒãƒã‚Šå›æ•°
            'today_max_at_interval': today_max_at_interval,  # æœ¬æ—¥æœ€å¤§ATé–“
            'today_max_rensa': today_max_rensa,  # æœ¬æ—¥æœ€å¤§é€£ãƒãƒ£ãƒ³æ•°
            # ã‚¹ã‚³ã‚¢å†…è¨³ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ»åˆ†æç”¨ï¼‰
            'score_breakdown': {
                'base': base_score,
                'today_bonus': today_analysis.get('today_score_bonus', 0),
                'trend_bonus': trend_bonus,
                'historical_bonus': historical_bonus,
                'slump_bonus': slump_bonus,
                'activity_bonus': activity_bonus,
                'medal_balance_penalty': medal_balance_penalty,
            },
            # éå»å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã€æ”¹å–„1ã€‘
            'historical_perf': historical_perf,
            # ç¨¼åƒãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã€æ”¹å–„4+5ã€‘
            'activity_data': activity_data,
            # å·®æšè¦‹è¾¼ã¿ï¼ˆå†…éƒ¨è¨ˆç®—ç”¨ï¼‰
            'current_estimate': profit_info['current_estimate'],
            'closing_estimate': profit_info['closing_estimate'],
            'profit_category': profit_info['profit_category'],
            'estimated_setting': profit_info['setting_info']['estimated_setting'],
            'setting_num': profit_info['setting_info'].get('setting_num', 0),
            'payout_estimate': profit_info['setting_info']['payout_estimate'],
            # å½“æ—¥å±¥æ­´ï¼ˆæ³¢ã‚°ãƒ©ãƒ•ãƒ»å½“ãŸã‚Šä¸€è¦§ç”¨ï¼‰
            'today_history': today_history,
            'history_date': history_date,
        }

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ãŒæ˜¨æ—¥ã®ã‚‚ã®ã ã£ãŸå ´åˆã€å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è£œå®Œ
        if realtime_data and not realtime_is_today and not rec['yesterday_art']:
            fetched_at = realtime_data.get('fetched_at', '')
            if fetched_at:
                try:
                    fetch_date_str = datetime.fromisoformat(fetched_at).strftime('%Y-%m-%d')
                    yesterday_check = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
                    if fetch_date_str == yesterday_check:
                        # æ˜¨æ—¥ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨
                        units_list = realtime_data.get('units', [])
                        for unit in units_list:
                            if unit.get('unit_id') == unit_id:
                                rec['yesterday_art'] = unit.get('art', 0)
                                rec['yesterday_rb'] = unit.get('rb', 0)
                                rec['yesterday_games'] = unit.get('total_start', 0)
                                rec['yesterday_date'] = fetch_date_str
                                break
                except:
                    pass

        # è“„ç©DBã‹ã‚‰3æ—¥ç›®+å„æ—¥ã®æœ€å¤§é€£ãƒãƒ£ãƒ³ãƒ»æœ€å¤§æšæ•°ã‚’å–å¾—
        if accumulated and accumulated.get('days'):
            acc_days = sorted(accumulated['days'], key=lambda x: x.get('date', ''), reverse=True)
            y_date = rec.get('yesterday_date', '')
            db_date = rec.get('day_before_date', '')

            # å„æ—¥ã®æœ€å¤§é€£ãƒãƒ£ãƒ³ãƒ»æœ€å¤§æšæ•°ã‚’è“„ç©DBã‹ã‚‰è£œå®Œ
            for ad in acc_days:
                d = ad.get('date', '')
                if d == y_date:
                    if not rec.get('yesterday_max_rensa'):
                        rec['yesterday_max_rensa'] = ad.get('max_rensa', 0)
                    if not rec.get('yesterday_max_medals'):
                        rec['yesterday_max_medals'] = ad.get('max_medals', 0)
                    if not rec.get('yesterday_history') and ad.get('history'):
                        rec['yesterday_history'] = ad['history']
                elif d == db_date:
                    rec['day_before_max_rensa'] = ad.get('max_rensa', 0)
                    rec['day_before_max_medals'] = ad.get('max_medals', 0)
                    if ad.get('history'):
                        rec['day_before_history'] = ad['history']
                elif d and d < (db_date or y_date or '9999') and not rec.get('three_days_ago_date'):
                    rec['three_days_ago_art'] = ad.get('art', 0)
                    rec['three_days_ago_rb'] = ad.get('rb', 0)
                    rec['three_days_ago_games'] = ad.get('games', 0)
                    rec['three_days_ago_date'] = d
                    rec['three_days_ago_max_rensa'] = ad.get('max_rensa', 0)
                    rec['three_days_ago_max_medals'] = ad.get('max_medals', 0)
                    if ad.get('history'):
                        rec['three_days_ago_history'] = ad['history']
                    _3d_art = ad.get('art', 0)
                    _3d_games = ad.get('games', 0)
                    rec['three_days_ago_prob'] = round(_3d_games / _3d_art) if _3d_art > 0 and _3d_games > 0 else 0

        # é–‰åº—å¾Œ: availabilityã®ãƒ‡ãƒ¼ã‚¿ã‚’è£œå®Œ
        # æ³¨æ„: availabilityã®today_historyã®æ—¥ä»˜ã¨è“„ç©DBã®yesterday_dateãŒç•°ãªã‚‹å ´åˆãŒã‚ã‚‹
        # availability=1/27, yesterday_date=1/26 â†’ availabilityã¯ã€Œå‰æ—¥ã€ã§ãªãã€Œæœ€æ–°æ—¥ã€
        if not realtime_is_today and realtime_data:
            # availabilityã®ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜ã‚’å–å¾—
            rt_fetched = realtime_data.get('fetched_at', '')
            rt_date = ''
            if rt_fetched:
                try:
                    rt_date = datetime.fromisoformat(rt_fetched.replace('Z', '+00:00')).strftime('%Y-%m-%d')
                except:
                    pass

            y_date = rec.get('yesterday_date', '')
            # availabilityã®ãƒ‡ãƒ¼ã‚¿ãŒyesterday_dateã‚ˆã‚Šæ–°ã—ã„å ´åˆã€
            # yesterdayãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä¸Šã«ãšã‚‰ã—ã¦ã€availabilityãƒ‡ãƒ¼ã‚¿ã‚’yesterdayã«å…¥ã‚Œã‚‹
            is_newer = rt_date and y_date and rt_date > y_date

            units_list = realtime_data.get('units', [])
            for _unit in units_list:
                if _unit.get('unit_id') == unit_id:
                    rt_hist = _unit.get('today_history', [])
                    _rt_art = _unit.get('art', 0)
                    _rt_total = _unit.get('total_start', 0)
                    _rt_rb = _unit.get('rb', 0)
                    rt_max = _unit.get('max_medals', 0)

                    if is_newer and _rt_art > 0:
                        # availabilityãŒæœ€æ–°æ—¥ â†’ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’1æ—¥ãšã¤ãšã‚‰ã™
                        if rec.get('yesterday_art'):
                            # day_before â†’ three_days_ago
                            rec['three_days_ago_art'] = rec.get('day_before_art', 0)
                            rec['three_days_ago_rb'] = rec.get('day_before_rb', 0)
                            rec['three_days_ago_games'] = rec.get('day_before_games', 0)
                            rec['three_days_ago_date'] = rec.get('day_before_date', '')
                            rec['three_days_ago_diff_medals'] = rec.get('day_before_diff_medals')
                            rec['three_days_ago_max_rensa'] = rec.get('day_before_max_rensa', 0)
                            rec['three_days_ago_max_medals'] = rec.get('day_before_max_medals', 0)
                            rec['three_days_ago_prob'] = rec.get('day_before_prob', 0)

                            # yesterday â†’ day_before
                            rec['day_before_art'] = rec.get('yesterday_art', 0)
                            rec['day_before_rb'] = rec.get('yesterday_rb', 0)
                            rec['day_before_games'] = rec.get('yesterday_games', 0)
                            rec['day_before_date'] = rec.get('yesterday_date', '')
                            rec['day_before_diff_medals'] = rec.get('yesterday_diff_medals')
                            rec['day_before_max_rensa'] = rec.get('yesterday_max_rensa', 0)
                            rec['day_before_max_medals'] = rec.get('yesterday_max_medals', 0)
                            rec['day_before_prob'] = rec.get('yesterday_prob', 0)

                        # availabilityãƒ‡ãƒ¼ã‚¿ã‚’yesterdayã«è¨­å®š
                        rec['yesterday_art'] = _rt_art
                        rec['yesterday_rb'] = _rt_rb
                        rec['yesterday_games'] = _rt_total
                        rec['yesterday_date'] = rt_date
                        rec['yesterday_prob'] = round(_rt_total / _rt_art) if _rt_art > 0 else 0
                        rec['today_history'] = rt_hist

                        # é€£ãƒãƒ£ãƒ³ãƒ»æœ€å¤§æšæ•°
                        if rt_hist:
                            from analysis.history_accumulator import _calc_history_stats
                            calc_rensa, calc_medals = _calc_history_stats(rt_hist)
                            rec['yesterday_max_rensa'] = calc_rensa
                            rec['yesterday_max_medals'] = rt_max if rt_max > 0 else calc_medals
                        else:
                            rec['yesterday_max_rensa'] = 0
                            rec['yesterday_max_medals'] = rt_max

                        # å·®æšã¯generate_static.pyã®calculate_expected_profitã§è¨ˆç®—ã™ã‚‹
                        # today_historyã‹ã‚‰ã®è¨ˆç®—ã¯ä¸æ­£ç¢ºï¼ˆmedalsã¯ARTä¸­æ‰•ã„å‡ºã—ã®ã¿ï¼‰
                        rec['yesterday_diff_medals'] = None
                    else:
                        # åŒã˜æ—¥ä»˜ or æ—¥ä»˜ä¸æ˜ â†’ æ—¢å­˜yesterdayã‚’è£œå®Œã™ã‚‹ã ã‘
                        if rt_hist and not rec.get('yesterday_max_rensa'):
                            from analysis.history_accumulator import _calc_history_stats
                            calc_rensa, calc_medals = _calc_history_stats(rt_hist)
                            if calc_rensa > 0:
                                rec['yesterday_max_rensa'] = calc_rensa
                            if rt_max > 0:
                                rec['yesterday_max_medals'] = rt_max
                            elif calc_medals > 0:
                                rec['yesterday_max_medals'] = calc_medals
                            rec['today_history'] = rt_hist
                        if not rec.get('yesterday_prob') and _rt_art > 0 and _rt_total > 0:
                            rec['yesterday_prob'] = round(_rt_total / _rt_art)
                        # å·®æšã¯generate_static.pyã§è¨ˆç®—ï¼ˆhistoryè¨ˆç®—ã¯ä¸æ­£ç¢ºï¼‰
                        if not rec.get('yesterday_rb') and _rt_rb > 0:
                            rec['yesterday_rb'] = _rt_rb
                    break

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¾Œã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ­ãƒ¼ãƒ†å‚¾å‘ã‚’å†è¨ˆç®—
        # ï¼ˆè“„ç©DBã®daysã«availabilityã®æœ€æ–°æ—¥ãŒå«ã¾ã‚Œãªã„å•é¡Œã‚’ä¿®æ­£ï¼‰
        if rec.get('yesterday_art') and rec.get('yesterday_games'):
            _rot_days = []
            for prefix, date_key in [('yesterday', 'yesterday_date'),
                                      ('day_before', 'day_before_date'),
                                      ('three_days_ago', 'three_days_ago_date')]:
                _a = rec.get(f'{prefix}_art', 0)
                _g = rec.get(f'{prefix}_games', 0)
                if _a > 0 and _g > 0:
                    _rot_days.append({'art': _a, 'total_start': _g, 'date': rec.get(date_key, '')})
            # è“„ç©ãƒ‡ãƒ¼ã‚¿ã®æ®‹ã‚Šã‚’è¿½åŠ ï¼ˆ3æ—¥é–“ä»¥é™ï¼‰
            if unit_days:
                _existing_dates = {d.get('date', '') for d in _rot_days}
                for ud in unit_days:
                    if ud.get('date', '') not in _existing_dates:
                        _rot_days.append(ud)
            if len(_rot_days) >= 5:
                _new_rot = analyze_rotation_pattern(_rot_days, machine_key=machine_key)
                # reasonsã®ãƒ­ãƒ¼ãƒ†è¡Œã‚’å·®ã—æ›¿ãˆ
                _hour = datetime.now().hour
                _ndl = 'æœ¬æ—¥' if _hour < 10 else 'ç¿Œæ—¥'
                _old_rot_prefix = 'ğŸ”„ ãƒ­ãƒ¼ãƒ†å‚¾å‘:'
                rec['reasons'] = [r for r in rec['reasons'] if not r.startswith(_old_rot_prefix)]
                if _new_rot['has_pattern'] and _new_rot['next_high_chance']:
                    rec['reasons'].insert(1, f"ğŸ”„ ãƒ­ãƒ¼ãƒ†å‚¾å‘: {_new_rot['description']} â†’ {_ndl}ä¸Šã’æœŸå¾…")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¾Œã®é€£ç¶šä¸èª¿åˆ¤å®šï¼ˆtrendã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‰ãªã®ã§recå€¤ã§å†åˆ¤å®šï¼‰
        _yp = rec.get('yesterday_prob', 0)
        _dbp = rec.get('day_before_prob', 0)
        _has_2day_bad = any('ç›´è¿‘2æ—¥ã¨ã‚‚ä¸èª¿' in r for r in rec['reasons'])
        _bad_th = get_machine_threshold(machine_key, 'bad_prob')
        if _yp >= _bad_th and _dbp >= _bad_th and not _has_2day_bad:
            _hour = datetime.now().hour
            _ndl = 'æœ¬æ—¥' if _hour < 10 else 'ç¿Œæ—¥'
            _mk = machine_info.get('key', 'sbj') if machine_info else 'sbj'
            _mr = get_machine_recovery_stats(_mk)
            _rs = _mr.get(2, {})
            _r_note = f"ï¼ˆSBJå…¨åº—èˆ—å®Ÿç¸¾: {_rs['recovered']}/{_rs['total']}å›={_rs['rate']:.0%}ã§ç¿Œæ—¥å›å¾©ï¼‰" if _rs.get('total', 0) >= 3 else ""
            rec['reasons'].insert(1, f"ğŸ”„ ç›´è¿‘2æ—¥ã¨ã‚‚ä¸èª¿ï¼ˆ1/{_dbp:.0f}â†’1/{_yp:.0f}ï¼‰â†’ {_ndl}è¨­å®šå¤‰æ›´æœŸå¾…å¤§{_r_note}")

        recommendations.append(rec)

    # === ã€æ”¹å–„3ã€‘ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è©•ä¾¡ï¼ˆçµ¶å¯¾ã‚¹ã‚³ã‚¢ + ç›¸å¯¾ä½ç½®è£œæ­£ï¼‰===
    # ã¾ãšçµ¶å¯¾ã‚¹ã‚³ã‚¢ã§ãƒ©ãƒ³ã‚¯ã‚’æ±ºå®šã—ã€ç›¸å¯¾ä½ç½®ã§Â±1æ®µéšã ã‘è£œæ­£
    if len(recommendations) >= 3:
        sorted_by_score = sorted(recommendations, key=lambda r: -r['final_score'])
        n = len(sorted_by_score)

        for i, rec in enumerate(sorted_by_score):
            # 1. çµ¶å¯¾ã‚¹ã‚³ã‚¢ã§ãƒ©ãƒ³ã‚¯æ±ºå®š
            absolute_rank = get_rank(rec['final_score'])

            # 2. ç›¸å¯¾ä½ç½®ã§Â±1æ®µéšè£œæ­£
            percentile = i / n  # 0.0 = ãƒˆãƒƒãƒ—, 1.0 = æœ€ä¸‹ä½
            has_ranking = rec.get('has_static_ranking', False)
            if percentile < 0.15 and absolute_rank != 'S':
                # åº—èˆ—å†…TOP15%: 1æ®µéšã‚¢ãƒƒãƒ—
                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚ã‚Šã®å ´åˆ: ã‚¹ã‚³ã‚¢60ä»¥ä¸Šã§OK
                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãªã—ã®å ´åˆ: ã‚¹ã‚³ã‚¢70ä»¥ä¸Šï¼ˆã‚ˆã‚Šå³ã—ãï¼‰
                min_score = 60 if has_ranking else 70
                if rec['final_score'] >= min_score:
                    absolute_rank = rank_up(absolute_rank)
            elif percentile > 0.85 and absolute_rank not in ('C', 'D'):
                # åº—èˆ—å†…ãƒ¯ãƒ¼ã‚¹ãƒˆ15%: 1æ®µéšãƒ€ã‚¦ãƒ³
                absolute_rank = rank_down(absolute_rank)

            # 3. ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒç„¡ã„å°ã¯Säºˆæ¸¬ã‚’åˆ¶é™ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³æ™‚ã®éä¿¡é˜²æ­¢ï¼‰
            if not has_ranking and absolute_rank == 'S':
                absolute_rank = 'A'

            rec['final_rank'] = absolute_rank

        # 4. S/Aå°æ•°ã®ä¸Šé™åˆ¶é™ï¼ˆå…¨å°Sã«ãªã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ï¼‰
        # å³¶ã®50%ä»¥ä¸ŠãŒS/Aã«ãªã‚‹ã®ã¯éç¾å®Ÿçš„
        max_sa_ratio = 0.5  # S+Aã¯æœ€å¤§50%
        max_sa_count = max(3, int(n * max_sa_ratio))  # æœ€ä½3å°ã¯è¨±å¯
        sa_count = 0
        for rec in sorted_by_score:
            if rec['final_rank'] in ('S', 'A'):
                sa_count += 1
                if sa_count > max_sa_count:
                    # ä¸Šé™è¶…éåˆ†ã¯Bã«é™æ ¼
                    rec['final_rank'] = 'B'

    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆï¼ˆç¨¼åƒä¸­ã®å°ã¯å°‘ã—ä¸‹ã’ã‚‹ï¼‰
    def sort_key(r):
        score = r['final_score']
        if r['is_running']:
            score -= 20  # ç¨¼åƒä¸­ã¯ä¸‹ã’ã‚‹
        return -score

    recommendations.sort(key=sort_key)

    # ã€Œæœ¬æ—¥ã€ã‚’æ—¥ä»˜ãƒ©ãƒ™ãƒ«ã«ç½®æ›ï¼ˆtoday_reasons, comparison_noteç­‰ï¼‰
    if data_date_label:
        for rec in recommendations:
            if rec.get('today_reasons'):
                rec['today_reasons'] = [r.replace('æœ¬æ—¥', data_date_label) for r in rec['today_reasons']]
            if rec.get('comparison_note'):
                rec['comparison_note'] = rec['comparison_note'].replace('æœ¬æ—¥', data_date_label)

    # === ç¨¼åƒç‡ã®æ³¨è¨˜ï¼ˆä½ç¨¼åƒæ—¥ã¯ç¢ºç‡ã®ãƒ–ãƒ¬ãŒå¤§ãã„ï¼‰ ===
    # åº—èˆ—Ã—æ©Ÿç¨®ã®å¹³å‡Gæ•°ã§åˆ¤å®šï¼ˆå°æ•°ãŒå°‘ãªã„å ´åˆã¯æœ€ä½åŸºæº–ã‚‚é©ç”¨ï¼‰
    y_games_all = [r.get('yesterday_games', 0) for r in recommendations if r.get('yesterday_games', 0) > 0]
    avg_games = sum(y_games_all) / len(y_games_all) if y_games_all else 0
    # å°æ•°ãŒå°‘ãªã„ï¼ˆ5å°æœªæº€ï¼‰å ´åˆã€æ©Ÿç¨®ã®ä¸€èˆ¬çš„ãªç¨¼åƒåŸºæº–ã‚‚è€ƒæ…®
    if len(y_games_all) < 5:
        # SBJã®ä¸€èˆ¬çš„ãª1æ—¥å¹³å‡ã¯6000-7000Gå‰å¾Œ
        machine_typical_avg = get_machine_threshold(machine_key, 'typical_daily_games')
        avg_games = max(avg_games, machine_typical_avg * 0.8)
    low_games_threshold = avg_games * 0.6 if avg_games > 0 else 3000
    for rec in recommendations:
        rec['store_avg_games'] = int(avg_games)
        for prefix in ['yesterday', 'day_before', 'three_days_ago']:
            g = rec.get(f'{prefix}_games', 0)
            if g > 0 and g < low_games_threshold:
                rec[f'{prefix}_low_activity'] = True

    # === å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã®ç›¸å¯¾è©•ä¾¡ï¼ˆåº—èˆ—å†…æ¯”è¼ƒï¼‰ ===
    # å‰æ—¥ã®æˆç¸¾ãŒåº—èˆ—å¹³å‡ã‚ˆã‚Šå¼±ã„å ´åˆã¯æ³¨æ„ã‚’è¿½åŠ 
    y_arts = [r.get('yesterday_art', 0) for r in recommendations if r.get('yesterday_art', 0) > 0]
    y_rensas = [r.get('yesterday_max_rensa', 0) for r in recommendations if r.get('yesterday_max_rensa', 0) > 0]
    y_probs = [r.get('yesterday_prob', 0) for r in recommendations if r.get('yesterday_prob') and r.get('yesterday_prob', 0) > 0]
    if len(y_arts) >= 5:
        avg_y_art = sum(y_arts) / len(y_arts)
        avg_y_rensa = sum(y_rensas) / len(y_rensas) if y_rensas else 0
        median_y_prob = sorted(y_probs)[len(y_probs)//2] if y_probs else 0
        for rec in recommendations:
            ya = rec.get('yesterday_art', 0)
            ymr = rec.get('yesterday_max_rensa', 0)
            yp = rec.get('yesterday_prob', 0)
            # å¼±ã„æŒ‡æ¨™ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            weak_count = 0
            if ya > 0 and ya < avg_y_art * 0.75:
                weak_count += 1
            if ymr > 0 and avg_y_rensa > 0 and ymr < avg_y_rensa * 0.5:
                weak_count += 1
            if yp > 0 and median_y_prob > 0 and yp > median_y_prob * 1.5:
                weak_count += 1

            if weak_count > 0:
                good_rate = rec.get('historical_perf', {}).get('good_day_rate', 0) if isinstance(rec.get('historical_perf'), dict) else 0
                yg = rec.get('yesterday_games', 0)
                is_low_activity = rec.get('yesterday_low_activity', False)

                # åŸå› æ¨å®š: äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã§ã‚·ãƒ³ãƒ—ãƒ«ã«
                if is_low_activity and yp <= 150:
                    msg = f"ğŸš¨ å‰æ—¥ã¯{yg:,}Gæ¶ˆåŒ–ã§ä½ç¨¼åƒ â†’ é«˜è¨­å®šã§ã‚‚æ•°å­—ãŒä¼¸ã³ã«ãã„ç¨¼åƒé‡"
                elif yp > 180:
                    msg = f"ğŸš¨ å‰æ—¥ã¯ARTç¢ºç‡1/{yp:.0f}ã§ä½è¨­å®šæ¿ƒåšï¼ˆå…¨å°ä¸­å¤®å€¤1/{median_y_prob:.0f}ï¼‰"
                elif yp > 150:
                    msg = f"ğŸš¨ å‰æ—¥ã¯ARTç¢ºç‡1/{yp:.0f}ã§ã‚„ã‚„ä¸èª¿ï¼ˆå…¨å°ä¸­å¤®å€¤1/{median_y_prob:.0f}ï¼‰"
                else:
                    # ç¢ºç‡OK+çˆ†ç™ºãªã—ã®ç¿Œæ—¥çµ±è¨ˆã‚’è¿½åŠ 
                    _ne_stats = get_no_explosion_stats(machine_key)
                    msg = f"ğŸš¨ å‰æ—¥ã¯ARTç¢ºç‡1/{yp:.0f}ã¨æ‚ªããªã„ãŒã€æœ€å¤§{ymr}é€£ã¨çˆ†ç™ºãªã—"
                    if _ne_stats['total'] >= 3:
                        msg += f" â†’ éå»ã«åŒãƒ‘ã‚¿ãƒ¼ãƒ³â†’ç¿Œæ—¥å¥½èª¿: {_ne_stats['next_good']}/{_ne_stats['total']}å›={_ne_stats['rate']:.0%}"

                if good_rate >= 0.7:
                    msg += f"ï¼ˆå¥½èª¿ç‡{good_rate:.0%}ã®ãŸã‚æœ¬æ—¥ã‚‚æœŸå¾…ï¼‰"

                rec['reasons'].append(msg)

    # === å·®æšæ¦‚ç®—ï¼ˆå…¨recã€å…¨æ—¥ï¼‰ ===
    # ã©ã®ãƒšãƒ¼ã‚¸ã‹ã‚‰å‘¼ã°ã‚Œã¦ã‚‚å·®æšãŒå…¥ã£ã¦ã‚‹çŠ¶æ…‹ã«ã™ã‚‹
    for rec in recommendations:
        for prefix in ['yesterday', 'day_before', 'three_days_ago']:
            _art = rec.get(f'{prefix}_art', 0)
            _games = rec.get(f'{prefix}_games', 0)
            if _art and _art > 0 and _games and _games > 0 and not rec.get(f'{prefix}_diff_medals'):
                _p = calculate_expected_profit(_games, _art, machine_key)
                rec[f'{prefix}_diff_medals'] = _p.get('current_estimate', 0)

    return recommendations


def format_recommendations(recommendations: list, store_name: str, machine_name: str = 'SBJ') -> str:
    """æ¨å¥¨çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§å‡ºåŠ›

    Args:
        recommendations: æ¨å¥¨å°ãƒªã‚¹ãƒˆ
        store_name: åº—èˆ—å
        machine_name: æ©Ÿç¨®åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: SBJï¼‰
    """
    lines = []
    lines.append(f"=== {store_name} {machine_name} æ¨å¥¨å° ===")
    lines.append(f"æ›´æ–°: {datetime.now().strftime('%H:%M')}")
    lines.append("")

    # S/Aãƒ©ãƒ³ã‚¯ã‚’æ¨å¥¨å°ã¨ã—ã¦è¡¨ç¤º
    top_recs = [r for r in recommendations if r['final_rank'] in ('S', 'A') and not r['is_running']]

    if top_recs:
        lines.append("[æ¨å¥¨]")
        for rec in top_recs[:5]:
            status = rec['status']
            art_info = f" æœ¬æ—¥AT{rec['art_count']}å›" if rec['art_count'] > 0 else ""
            lines.append(f"  {rec['unit_id']} [{rec['final_rank']}] {status}{art_info}")
            for reason in rec.get('reasons', [])[:3]:
                lines.append(f"    - {reason}")
    else:
        lines.append("[æ¨å¥¨å°ãªã— - å…¨å°ç¨¼åƒä¸­ã®å¯èƒ½æ€§]")

    lines.append("")
    lines.append("[å…¨å°çŠ¶æ³]")
    for rec in recommendations:
        mark = "*" if rec['is_running'] else " "
        status = rec['status']
        lines.append(f" {mark}{rec['unit_id']} [{rec['final_rank']}] {status}")

    return "\n".join(lines)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('--store', '-s', default='island_akihabara',
                        help='åº—èˆ—ã‚­ãƒ¼ (island_akihabara, shibuya_espass, shibuya_espass_hokuto, etc.)')
    args = parser.parse_args()

    store = STORES.get(args.store)
    if not store:
        print(f"Unknown store: {args.store}")
        # åˆ©ç”¨å¯èƒ½ãªåº—èˆ—ã‚­ãƒ¼ã‚’æ©Ÿç¨®åˆ¥ã«è¡¨ç¤º
        print("\nAvailable stores:")
        for key, s in STORES.items():
            if key in ('island_akihabara', 'shibuya_espass'):  # æ—§å½¢å¼ã¯é™¤å¤–
                continue
            machine = s.get('machine', 'sbj')
            machine_info = MACHINES.get(machine, {})
            print(f"  {key}: {s['name']} ({machine_info.get('short_name', machine)})")
        sys.exit(1)

    # æ©Ÿç¨®æƒ…å ±ã‚’å–å¾—
    machine_key = get_machine_from_store_key(args.store)
    machine_info = MACHINES.get(machine_key, {'short_name': 'SBJ'})

    recommendations = recommend_units(args.store)
    output = format_recommendations(recommendations, store['name'], machine_info.get('short_name', 'SBJ'))
    print(output)

    print("\n" + "=" * 50)
    print("è©³ç´°åˆ†æ:")
    for rec in recommendations[:5]:
        print(f"\nã€{rec['unit_id']}ã€‘{rec['final_rank']} (ã‚¹ã‚³ã‚¢: {rec['final_score']:.1f})")
        print(f"  æ˜¨æ—¥æ¨å®šå·®æš: {rec['yesterday_diff']:+,}æš")
        print(f"  7æ—¥å¹³å‡AT: {rec['avg_art_7days']:.1f}å›")
        if rec['consecutive_plus']:
            print(f"  é€£ç¶šãƒ—ãƒ©ã‚¹: {rec['consecutive_plus']}æ—¥")
        if rec['consecutive_minus']:
            print(f"  é€£ç¶šãƒã‚¤ãƒŠã‚¹: {rec['consecutive_minus']}æ—¥")
        print("  ç†ç”±:")
        for reason in rec.get('reasons', []):
            print(f"    - {reason}")
